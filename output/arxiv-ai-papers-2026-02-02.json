{
  "timestamp": "2026-02-02T06:24:47.621Z",
  "count": 116,
  "papers": [
    {
      "id": "http://arxiv.org/abs/2601.23286v1",
      "title": "VideoGPA: Distilling Geometry Priors for 3D-Consistent Video Generation",
      "originalTitle": "VideoGPA: Distilling Geometry Priors for 3D-Consistent Video Generation",
      "summary": "While recent video diffusion models (VDMs) produce visually impressive results, they fundamentally struggle to maintain 3D structural consistency, often resulting in object deformation or spatial drift. We hypothesize that these failures arise because standard denoising objectives lack explicit incentives for geometric coherence. To address this, we introduce VideoGPA (Video Geometric Preference A...",
      "plainSummary": "While recent video diffusion models (VDMs) produce visually impressive results, they fundamentally struggle to maintain 3D structural consistency, often resulting in object deformation or spatial drift. We hypothesize that these failures arise because standard denoising objectives lack explicit incentives for geometric coherence. To address this, we introduce VideoGPA (Video Geometric Preference Alignment), a data-高效的（速度快、资源消耗少） self-supervised 框架（提供结构的基础代码库） that leverages a geometry foundation model to automatically derive dense preference signals that guide VDMs via Direct Preference 优化（寻找最佳参数或解决方案的过程） (DPO). This approach effectively steers the generative distribution toward inherent 3D consistency without requiring human annotations. VideoGPA significantly enhances temporal stability, physical plausibility, and motion coherence using minimal preference pairs, consistently outperforming 最先进（当前最好的、领先的方法） baselines in 大量实验.",
      "oneSentenceSummary": "【cs.CV】Hongyang Du等VideoGPA，使用To address this, we introduce ...，在cs.CV取得新进展。",
      "authors": [
        {
          "original": "Hongyang Du",
          "chinese": null
        },
        {
          "original": "Junjie Ye",
          "chinese": null
        },
        {
          "original": "Xiaoyan Cong",
          "chinese": null
        },
        {
          "original": "Runhao Li",
          "chinese": null
        },
        {
          "original": "Jingcheng Ni",
          "chinese": null
        },
        {
          "original": "Aman Agarwal",
          "chinese": null
        },
        {
          "original": "Zeqi Zhou",
          "chinese": null
        },
        {
          "original": "Zekun Li",
          "chinese": null
        },
        {
          "original": "Randall Balestriero",
          "chinese": null
        },
        {
          "original": "Yue Wang",
          "chinese": null
        }
      ],
      "published": "2026-01-30T18:59:57Z",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primaryCategory": "cs.CV",
      "pdfUrl": "https://arxiv.org/pdf/2601.23286v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23286v1",
      "keyInfo": {
        "contributions": [
          "To address this, we introduce VideoGPA (Video Geometric Preference Alignment), a data-高效的（速度快、资源消耗少） self-supervised 框架（提供结构的基础代码库） that leverages a geometry foundation model to automatically derive dense preference signals that guide VDMs via Direct Preference 优化（寻找最佳参数或解决方案的过程） (DPO)"
        ],
        "methods": [
          "To address this, we introduce VideoGPA (Video Geometric Preference Alignment), a data-高效的（速度快、资源消耗少） self-supervised 框架（提供结构的基础代码库） that leverages a geometry foundation model to automatically derive dense preference signals that guide VDMs via Direct Preference 优化（寻找最佳参数或解决方案的过程） (DPO)",
          "VideoGPA significantly enhances temporal stability, physical plausibility, and motion coherence using minimal preference pairs, consistently outperforming 最先进（当前最好的、领先的方法） baselines in extensive experiments"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23285v1",
      "title": "End-to-end 优化（寻找最佳参数或解决方案的过程） of Belief and Policy Learning in Shared Autonomy Paradigms",
      "originalTitle": "End-to-end Optimization of Belief and Policy Learning in Shared Autonomy Paradigms",
      "summary": "Shared autonomy systems require principled methods for inferring user intent and determining appropriate assistance levels. This is a central challenge in human-robot interaction, where systems must be successful while being mindful of user agency. Previous approaches relied on static blending ratios or separated goal inference from assistance arbitration, leading to suboptimal performance in unst...",
      "plainSummary": "Shared autonomy systems require principled methods for inferring user intent and determining appropriate assistance levels. This is a central challenge in human-robot interaction, where systems must be successful while being mindful of user agency. Previous approaches relied on static blending ratios or separated goal inference from assistance arbitration, leading to suboptimal performance in unstructured environments. We introduce BRACE (Bayesian Reinforcement Assistance with Context Encoding), a 新颖的（创新的、前人未做过的） 框架（提供结构的基础代码库） that fine-tunes Bayesian intent inference and context-adaptive assistance through an architecture enabling end-to-end gradient flow between intent inference and assistance arbitration. Our 流程（数据处理或模型训练的完整流程） conditions collaborative control policies on environmental context and complete goal probability distributions. We provide analysis showing (1) optimal assistance levels should decrease with goal uncertainty and increase with environmental constraint severity, and (2) integrating belief information into policy learning yields a quadratic expected regret advantage over sequential approaches. We validated our algorithm against SOTA methods (IDA, DQN) using a three-part evaluation progressively isolating distinct challenges of end-effector control: (1) core human-interaction dynamics in a 2D human-in-the-loop cursor task, (2) non-linear dynamics of a robotic arm, and (3) integrated manipulation under goal ambiguity and environmental constraints. We demonstrate improvements over SOTA, achieving 6.3% higher success rates and 41% increased path efficiency, and 36.3% success rate and 87% path efficiency improvement over unassisted control. Our results confirmed that integrated 优化（寻找最佳参数或解决方案的过程） is most beneficial in complex, goal-ambiguous scenarios, and is 可泛化的（能够适用于新场景） across robotic domains requiring goal-directed assistance, advancing the SOTA for adaptive shared autonomy.",
      "oneSentenceSummary": "【cs.RO】MH Farhadi等End-to-end Optimization of Belief and Policy Learning in Shared Autonomy Paradigms，使用We validated our algorithm aga...，在cs.RO取得新进展。",
      "authors": [
        {
          "original": "MH Farhadi",
          "chinese": null
        },
        {
          "original": "Ali Rabiee",
          "chinese": null
        },
        {
          "original": "Sima Ghafoori",
          "chinese": null
        },
        {
          "original": "Anna Cetera",
          "chinese": null
        },
        {
          "original": "Andrew Fisher",
          "chinese": null
        },
        {
          "original": "Reza Abiri",
          "chinese": null
        }
      ],
      "published": "2026-01-30T18:59:16Z",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primaryCategory": "cs.RO",
      "pdfUrl": "https://arxiv.org/pdf/2601.23285v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23285v1",
      "keyInfo": {
        "contributions": [
          "We introduce BRACE (Bayesian Reinforcement Assistance with Context Encoding), a 新颖的（创新的、前人未做过的） 框架（提供结构的基础代码库） that fine-tunes Bayesian intent inference and context-adaptive assistance through an architecture enabling end-to-end gradient flow between intent inference and assistance arbitration"
        ],
        "methods": [
          "We validated our algorithm against SOTA methods (IDA, DQN) using a three-part evaluation progressively isolating distinct challenges of end-effector control: (1) core human-interaction dynamics in a 2D human-in-the-loop cursor task, (2) non-linear dynamics of a robotic arm, and (3) integrated manipulation under goal ambiguity and environmental constraints"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23281v1",
      "title": "User Prompting Strategies and Prompt Enhancement Methods for Open-Set 目标检测（在图像中识别和定位特定物体） in XR Environments",
      "originalTitle": "User Prompting Strategies and Prompt Enhancement Methods for Open-Set Object Detection in XR Environments",
      "summary": "Open-set 目标检测（在图像中识别和定位特定物体） (OSOD) localizes objects while identifying and rejecting unknown classes at inference. While recent OSOD models perform well on benchmarks, their behavior under realistic user prompting remains underexplored. In interactive XR settings, user-generated prompts are often ambiguous, underspecified, or overly detailed. To study prompt-conditioned robustness, we evaluate tw...",
      "plainSummary": "Open-set 目标检测（在图像中识别和定位特定物体） (OSOD) localizes objects while identifying and rejecting unknown classes at inference. While recent OSOD models perform well on benchmarks, their behavior under realistic user prompting remains underexplored. In interactive XR settings, user-generated prompts are often ambiguous, underspecified, or overly detailed. To study prompt-conditioned robustness, we evaluate two OSOD models, GroundingDINO and YOLO-E, on real-world XR images and simulate diverse user prompting behaviors using vision-language models. We consider four prompt types: standard, underdetailed, overdetailed, and pragmatically ambiguous, and examine the impact of two enhancement strategies on these prompts. Results show that both models exhibit stable performance under underdetailed and standard prompts, while they suffer degradation under ambiguous prompts. Overdetailed prompts primarily affect GroundingDINO. Prompt enhancement substantially improves robustness under ambiguity, yielding gains exceeding 55% mIoU and 41% average confidence. Based on the findings, 我们提出 several prompting strategies and prompt enhancement methods for OSOD models in XR environments.",
      "oneSentenceSummary": "【cs.CV】Junfeng Lin等User Prompting Strategies and Prompt Enhancement Methods for Open-Set Object Detection in XR Environments，使用To study prompt-conditioned ro...，在cs.CV取得新进展。",
      "authors": [
        {
          "original": "Junfeng Lin",
          "chinese": null
        },
        {
          "original": "Yanming Xiu",
          "chinese": null
        },
        {
          "original": "Maria Gorlatova",
          "chinese": null
        }
      ],
      "published": "2026-01-30T18:55:38Z",
      "categories": [
        "cs.CV"
      ],
      "primaryCategory": "cs.CV",
      "pdfUrl": "https://arxiv.org/pdf/2601.23281v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23281v1",
      "keyInfo": {
        "contributions": [
          "Based on the findings, we propose several prompting strategies and prompt enhancement methods for OSOD models in XR environments"
        ],
        "methods": [
          "To study prompt-conditioned robustness, we evaluate two OSOD models, GroundingDINO and YOLO-E, on real-world XR images and simulate diverse user prompting behaviors using vision-language models",
          "Based on the findings, we propose several prompting strategies and prompt enhancement methods for OSOD models in XR environments"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23280v1",
      "title": "Decoupled Diffusion Sampling for Inverse Problems on Function Spaces",
      "originalTitle": "Decoupled Diffusion Sampling for Inverse Problems on Function Spaces",
      "summary": "We propose a data-高效的（速度快、资源消耗少）, physics-aware generative 框架（提供结构的基础代码库） in function space for inverse PDE problems. Existing plug-and-play diffusion 后验概率（观察到数据后的概率） samplers represent physics implicitly through joint coefficient-solution modeling, requiring substantial paired supervision. In contrast, our Decoupled Diffusion Inverse Solver (DDIS) employs a decoupled design: an unconditional diff...",
      "plainSummary": "我们提出 a data-高效的（速度快、资源消耗少）, physics-aware generative 框架（提供结构的基础代码库） in function space for inverse PDE problems. Existing plug-and-play diffusion 后验概率（观察到数据后的概率） samplers represent physics implicitly through joint coefficient-solution modeling, requiring substantial paired supervision. In contrast, our Decoupled Diffusion Inverse Solver (DDIS) employs a decoupled design: an unconditional diffusion learns the coefficient 先验概率（观察到数据前的概率）, while a neural operator explicitly models the forward PDE for guidance. This decoupling enables superior data efficiency and effective physics-informed learning, while naturally supporting Decoupled Annealing 后验概率（观察到数据后的概率） Sampling (DAPS) to avoid over-smoothing in Diffusion 后验概率（观察到数据后的概率） Sampling (DPS). Theoretically, we prove that DDIS avoids the guidance attenuation failure of joint models when training data is scarce. Empirically, DDIS achieves 最先进（当前最好的、领先的方法） performance under sparse observation, improving error by 11% and spectral error by 54% on average; when data is limited to 1%, DDIS maintains 准确率（正确预测占总预测的比例） with 40% advantage in error compared to joint models.",
      "oneSentenceSummary": "【cs.LG】Thomas Y. L. Lin等Decoupled Diffusion Sampling for Inverse Problems on Function Spaces，使用In contrast, our Decoupled Dif...，在cs.LG取得新进展。",
      "authors": [
        {
          "original": "Thomas Y. L. Lin",
          "chinese": null
        },
        {
          "original": "Jiachen Yao",
          "chinese": null
        },
        {
          "original": "Lufang Chiang",
          "chinese": null
        },
        {
          "original": "Julius Berner",
          "chinese": null
        },
        {
          "original": "Anima Anandkumar",
          "chinese": null
        }
      ],
      "published": "2026-01-30T18:54:49Z",
      "categories": [
        "cs.LG",
        "math.NA"
      ],
      "primaryCategory": "cs.LG",
      "pdfUrl": "https://arxiv.org/pdf/2601.23280v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23280v1",
      "keyInfo": {
        "contributions": [
          "We propose a data-高效的（速度快、资源消耗少）, physics-aware generative 框架（提供结构的基础代码库） in function space for inverse PDE problems",
          "Existing plug-and-play diffusion 后验概率（观察到数据后的概率） samplers represent physics implicitly through joint coefficient-solution modeling, requiring substantial paired supervision"
        ],
        "methods": [
          "In contrast, our Decoupled Diffusion Inverse Solver (DDIS) employs a decoupled design: an unconditional diffusion learns the coefficient 先验概率（观察到数据前的概率）, while a neural operator explicitly models the forward PDE for guidance"
        ],
        "applications": [
          "This decoupling enables superior data efficiency and effective physics-informed learning, while naturally supporting Decoupled Annealing 后验概率（观察到数据后的概率） Sampling (DAPS) to avoid over-smoothing in Diffusion 后验概率（观察到数据后的概率） Sampling (DPS)"
        ]
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23278v1",
      "title": "FOCUS: DLLMs Know How to Tame Their Compute Bound",
      "originalTitle": "FOCUS: DLLMs Know How to Tame Their Compute Bound",
      "summary": "Diffusion Large Language Models (DLLMs) offer a compelling alternative to Auto-Regressive models, but their deployment is constrained by high decoding cost. In this work, we identify a key inefficiency in DLLM decoding: while computation is parallelized over token blocks, only a small subset of tokens is decodable at each diffusion step, causing most compute to be wasted on non-decodable tokens. W...",
      "plainSummary": "Diffusion Large Language Models (DLLMs) offer a compelling alternative to Auto-Regressive models, but their deployment is constrained by high decoding cost. In this work, we identify a key inefficiency in DLLM decoding: while computation is parallelized over token blocks, only a small subset of tokens is decodable at each diffusion step, causing most compute to be wasted on non-decodable tokens. We further observe a strong correlation between attention-derived token importance and token-wise decoding probability. Based on this insight, 我们提出 FOCUS -- an inference system designed for DLLMs. By dynamically focusing computation on decodable tokens and evicting non-decodable ones on-the-fly, FOCUS increases the effective batch size, alleviating compute limitations and enabling 可扩展的（能够处理更大规模数据） throughput. 经验性的（基于实验和观察的） evaluations demonstrate that FOCUS achieves up to 3.52 throughput improvement over the production-grade engine LMDeploy, while preserving or improving generation quality across multiple benchmarks. The FOCUS system is publicly available on GitHub: https://github.com/sands-lab/FOCUS.",
      "oneSentenceSummary": "【cs.LG】Kaihua Liang等FOCUS，使用In this work, we identify a ke...，在cs.LG取得新进展。",
      "authors": [
        {
          "original": "Kaihua Liang",
          "chinese": null
        },
        {
          "original": "Xin Tan",
          "chinese": null
        },
        {
          "original": "An Zhong",
          "chinese": null
        },
        {
          "original": "Hong Xu",
          "chinese": null
        },
        {
          "original": "Marco Canini",
          "chinese": null
        }
      ],
      "published": "2026-01-30T18:52:06Z",
      "categories": [
        "cs.LG",
        "cs.AR",
        "cs.CL"
      ],
      "primaryCategory": "cs.LG",
      "pdfUrl": "https://arxiv.org/pdf/2601.23278v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23278v1",
      "keyInfo": {
        "contributions": [
          "Based on this insight, we propose FOCUS -- an inference system designed for DLLMs"
        ],
        "methods": [
          "In this work, we identify a key inefficiency in DLLM decoding: while computation is parallelized over token blocks, only a small subset of tokens is decodable at each diffusion step, causing most compute to be wasted on non-decodable tokens",
          "Based on this insight, we propose FOCUS -- an inference system designed for DLLMs"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23276v1",
      "title": "Denoising the Deep Sky: Physics-Based CCD Noise Formation for Astronomical Imaging",
      "originalTitle": "Denoising the Deep Sky: Physics-Based CCD Noise Formation for Astronomical Imaging",
      "summary": "Astronomical imaging remains noise-limited under practical observing constraints, while standard calibration pipelines mainly remove structured artifacts and leave stochastic noise largely unresolved. Learning-based denoising is promising, yet progress is hindered by scarce paired training data and the need for physically 可解释的（能够解释其决策过程） and reproducible models in scientific workflows. We propose ...",
      "plainSummary": "Astronomical imaging remains noise-limited under practical observing constraints, while standard calibration pipelines mainly remove structured artifacts and leave stochastic noise largely unresolved. Learning-based denoising is promising, yet progress is hindered by scarce paired training data and the need for physically 可解释的（能够解释其决策过程） and reproducible models in scientific workflows. 我们提出 a physics-based noise synthesis 框架（提供结构的基础代码库） tailored to CCD noise formation. The 流程（数据处理或模型训练的完整流程） models photon shot noise, photo-response non-uniformity, dark-current noise, readout effects, and localized outliers arising from cosmic-ray hits and hot pixels. To obtain low-noise inputs for synthesis, we average multiple unregistered exposures to produce high-SNR bases. Realistic noisy counterparts synthesized from these bases using our noise model enable the construction of abundant paired datasets for 监督学习（使用标注数据训练模型）. We further introduce a real-world dataset across multi-bands acquired with two twin ground-based telescopes, providing paired raw frames and instrument-流程（数据处理或模型训练的完整流程） calibrated frames, together with calibration data and stacked high-SNR bases for real-world evaluation.",
      "oneSentenceSummary": "【astro-ph.IM】Shuhong Liu等Denoising the Deep Sky，使用Realistic noisy counterparts s...，在astro-ph.IM取得新进展。",
      "authors": [
        {
          "original": "Shuhong Liu",
          "chinese": null
        },
        {
          "original": "Xining Ge",
          "chinese": null
        },
        {
          "original": "Ziying Gu",
          "chinese": null
        },
        {
          "original": "Lin Gu",
          "chinese": null
        },
        {
          "original": "Ziteng Cui",
          "chinese": null
        },
        {
          "original": "Xuangeng Chu",
          "chinese": null
        },
        {
          "original": "Jun Liu",
          "chinese": null
        },
        {
          "original": "Dong Li",
          "chinese": null
        },
        {
          "original": "Tatsuya Harada",
          "chinese": null
        }
      ],
      "published": "2026-01-30T18:47:54Z",
      "categories": [
        "astro-ph.IM",
        "cs.CV",
        "cs.LG"
      ],
      "primaryCategory": "astro-ph.IM",
      "pdfUrl": "https://arxiv.org/pdf/2601.23276v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23276v1",
      "keyInfo": {
        "contributions": [
          "We propose a physics-based noise synthesis 框架（提供结构的基础代码库） tailored to CCD noise formation",
          "We further introduce a real-world dataset across multi-bands acquired with two twin ground-based telescopes, providing paired raw frames and instrument-流程（数据处理或模型训练的完整流程） calibrated frames, together with calibration data and stacked high-SNR bases for real-world evaluation"
        ],
        "methods": [
          "Realistic noisy counterparts synthesized from these bases using our noise model enable the construction of abundant paired datasets for 监督学习（使用标注数据训练模型）"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23273v1",
      "title": "UPA: Unsupervised Prompt Agent via Tree-Based Search and Selection",
      "originalTitle": "UPA: Unsupervised Prompt Agent via Tree-Based Search and Selection",
      "summary": "Prompt agents have recently emerged as a promising paradigm for automated prompt 优化（寻找最佳参数或解决方案的过程）, framing refinement as a sequential decision-making problem over a structured prompt space. While this formulation enables the use of advanced planning algorithms, these methods typically assume access to supervised reward signals, which are often unavailable in practical scenarios. In this work, we...",
      "plainSummary": "Prompt agents have recently emerged as a promising paradigm for automated prompt 优化（寻找最佳参数或解决方案的过程）, framing refinement as a sequential decision-making problem over a structured prompt space. While this formulation enables the use of advanced planning algorithms, these methods typically assume access to supervised reward signals, which are often unavailable in practical scenarios. In this work, 我们提出 UPA, an Unsupervised Prompt Agent that realizes structured search and selection without relying on supervised feedback. Specifically, during search, UPA iteratively constructs an evolving tree structure to navigate the prompt space, guided by fine-grained and order-invariant pairwise comparisons from Large Language Models (LLMs). Crucially, as these local comparisons do not inherently yield a consistent global scale, we decouple systematic prompt exploration from final selection, introducing a two-stage 框架（提供结构的基础代码库） grounded in the Bradley-Terry-Luce (BTL) model. This 框架（提供结构的基础代码库） first performs path-wise Bayesian aggregation of local comparisons to filter candidates under uncertainty, followed by global tournament-style comparisons to infer latent prompt quality and identify the optimal prompt. Experiments across multiple tasks demonstrate that UPA consistently outperforms existing prompt 优化（寻找最佳参数或解决方案的过程） methods, showing that agent-style 优化（寻找最佳参数或解决方案的过程） remains highly effective even in fully unsupervised settings.",
      "oneSentenceSummary": "【cs.CL】Siran Peng等UPA，在cs.CL取得新进展。",
      "authors": [
        {
          "original": "Siran Peng",
          "chinese": null
        },
        {
          "original": "Weisong Zhao",
          "chinese": null
        },
        {
          "original": "Tianyu Fu",
          "chinese": null
        },
        {
          "original": "Chenxu Zhao",
          "chinese": null
        },
        {
          "original": "Tianshuo Zhang",
          "chinese": null
        },
        {
          "original": "Haoyuan Zhang",
          "chinese": null
        },
        {
          "original": "Xiangyu Zhu",
          "chinese": null
        },
        {
          "original": "Minghui Wu",
          "chinese": null
        },
        {
          "original": "Zhen Lei",
          "chinese": null
        }
      ],
      "published": "2026-01-30T18:39:09Z",
      "categories": [
        "cs.CL"
      ],
      "primaryCategory": "cs.CL",
      "pdfUrl": "https://arxiv.org/pdf/2601.23273v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23273v1",
      "keyInfo": {
        "contributions": [
          "In this work, we propose UPA, an Unsupervised Prompt Agent that realizes structured search and selection without relying on supervised feedback"
        ],
        "methods": [],
        "applications": [
          "While this formulation enables the use of advanced planning algorithms, these methods typically assume access to supervised reward signals, which are often unavailable in practical scenarios"
        ]
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23266v1",
      "title": "IRL-DAL: Safe and Adaptive Trajectory Planning for Autonomous Driving via Energy-Guided Diffusion Models",
      "originalTitle": "IRL-DAL: Safe and Adaptive Trajectory Planning for Autonomous Driving via Energy-Guided Diffusion Models",
      "summary": "This paper proposes a 新颖的（创新的、前人未做过的） inverse 强化学习（通过试错学习最佳策略的机器学习方法） 框架（提供结构的基础代码库） using a diffusion-based adaptive lookahead planner (IRL-DAL) for autonomous vehicles. Training begins with imitation from an expert finite state machine (FSM) controller to provide a stable initialization. Environment terms are combined with an IRL discriminator signal to align with expert goals. 强化学习（通过试错学习最佳策略的机...",
      "plainSummary": "This paper proposes a 新颖的（创新的、前人未做过的） inverse 强化学习（通过试错学习最佳策略的机器学习方法） 框架（提供结构的基础代码库） using a diffusion-based adaptive lookahead planner (IRL-DAL) for autonomous vehicles. Training begins with imitation from an expert finite state machine (FSM) controller to provide a stable initialization. Environment terms are combined with an IRL discriminator signal to align with expert goals. 强化学习（通过试错学习最佳策略的机器学习方法） (RL) is then performed with a hybrid reward that combines diffuse environmental feedback and targeted IRL rewards. A conditional diffusion model, which acts as a safety supervisor, plans safe paths. It stays in its lane, avoids obstacles, and moves smoothly. Then, a learnable adaptive mask (LAM) improves perception. It shifts visual attention based on vehicle speed and nearby hazards. After FSM-based imitation, the policy is fine-tuned with Proximal Policy 优化（寻找最佳参数或解决方案的过程） (PPO). Training is run in the Webots simulator with a two-stage curriculum. A 96\\% success rate is reached, and collisions are reduced to 0.05 per 1k steps, marking a new 基准（用于比较性能的标准数据集或方法） for safe navigation. By applying the proposed approach, the agent not only drives in lane but also handles unsafe conditions at an expert level, increasing robustness.We make our code publicly available.",
      "oneSentenceSummary": "【cs.RO】Seyed Ahmad Hosseini Miangoleh等IRL-DAL，使用This paper proposes a 新颖的（创新的、...，在cs.RO取得新进展。",
      "authors": [
        {
          "original": "Seyed Ahmad Hosseini Miangoleh",
          "chinese": null
        },
        {
          "original": "Amin Jalal Aghdasian",
          "chinese": null
        },
        {
          "original": "Farzaneh Abdollahi",
          "chinese": null
        }
      ],
      "published": "2026-01-30T18:34:10Z",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primaryCategory": "cs.RO",
      "pdfUrl": "https://arxiv.org/pdf/2601.23266v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23266v1",
      "keyInfo": {
        "contributions": [
          "This paper proposes a 新颖的（创新的、前人未做过的） inverse 强化学习（通过试错学习最佳策略的机器学习方法） 框架（提供结构的基础代码库） using a diffusion-based adaptive lookahead planner (IRL-DAL) for autonomous vehicles",
          "By applying the proposed approach, the agent not only drives in lane but also handles unsafe conditions at an expert level, increasing robustness"
        ],
        "methods": [
          "This paper proposes a 新颖的（创新的、前人未做过的） inverse 强化学习（通过试错学习最佳策略的机器学习方法） 框架（提供结构的基础代码库） using a diffusion-based adaptive lookahead planner (IRL-DAL) for autonomous vehicles",
          "It shifts visual attention based on vehicle speed and nearby hazards"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23265v1",
      "title": "PaperBanana: Automating Academic Illustration for AI Scientists",
      "originalTitle": "PaperBanana: Automating Academic Illustration for AI Scientists",
      "summary": "Despite rapid advances in autonomous AI scientists powered by language models, generating publication-ready illustrations remains a labor-intensive bottleneck in the research workflow. To lift this burden, we introduce PaperBanana, an agentic 框架（提供结构的基础代码库） for automated generation of publication-ready academic illustrations. Powered by 最先进（当前最好的、领先的方法） VLMs and image generation models, PaperBanan...",
      "plainSummary": "Despite rapid advances in autonomous AI scientists powered by language models, generating publication-ready illustrations remains a labor-intensive bottleneck in the research workflow. To lift this burden, we introduce PaperBanana, an agentic 框架（提供结构的基础代码库） for automated generation of publication-ready academic illustrations. Powered by 最先进（当前最好的、领先的方法） VLMs and image generation models, PaperBanana orchestrates specialized agents to retrieve references, plan content and style, render images, and iteratively refine via self-critique. To rigorously evaluate our 框架（提供结构的基础代码库）, we introduce PaperBananaBench, comprising 292 test cases for methodology diagrams curated from NeurIPS 2025 publications, covering diverse research domains and illustration styles. 全面的（覆盖广泛的、详细的） experiments demonstrate that PaperBanana consistently outperforms leading baselines in faithfulness, conciseness, readability, and aesthetics. We further show that 我们的方法 effectively extends to the generation of high-quality statistical plots. Collectively, PaperBanana paves the way for the automated generation of publication-ready illustrations.",
      "oneSentenceSummary": "【cs.CL】Dawei Zhu等PaperBanana，在cs.CL取得新进展。",
      "authors": [
        {
          "original": "Dawei Zhu",
          "chinese": null
        },
        {
          "original": "Rui Meng",
          "chinese": null
        },
        {
          "original": "Yale Song",
          "chinese": null
        },
        {
          "original": "Xiyu Wei",
          "chinese": null
        },
        {
          "original": "Sujian Li",
          "chinese": null
        },
        {
          "original": "Tomas Pfister",
          "chinese": null
        },
        {
          "original": "Jinsung Yoon",
          "chinese": null
        }
      ],
      "published": "2026-01-30T18:33:37Z",
      "categories": [
        "cs.CL",
        "cs.CV"
      ],
      "primaryCategory": "cs.CL",
      "pdfUrl": "https://arxiv.org/pdf/2601.23265v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23265v1",
      "keyInfo": {
        "contributions": [
          "To lift this burden, we introduce PaperBanana, an agentic 框架（提供结构的基础代码库） for automated generation of publication-ready academic illustrations",
          "To rigorously evaluate our 框架（提供结构的基础代码库）, we introduce PaperBananaBench, comprising 292 test cases for methodology diagrams curated from NeurIPS 2025 publications, covering diverse research domains and illustration styles"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23262v1",
      "title": "Particle-Guided Diffusion Models for Partial Differential Equations",
      "originalTitle": "Particle-Guided Diffusion Models for Partial Differential Equations",
      "summary": "We introduce a guided stochastic sampling method that augments sampling from diffusion models with physics-based guidance derived from partial differential equation (PDE) residuals and observational constraints, ensuring generated samples remain physically admissible. We embed this sampling procedure within a new Sequential Monte Carlo (SMC) 框架（提供结构的基础代码库）, yielding a 可扩展的（能够处理更大规模数据） generative P...",
      "plainSummary": "We introduce a guided stochastic sampling method that augments sampling from diffusion models with physics-based guidance derived from partial differential equation (PDE) residuals and observational constraints, ensuring generated samples remain physically admissible. We embed this sampling procedure within a new Sequential Monte Carlo (SMC) 框架（提供结构的基础代码库）, yielding a 可扩展的（能够处理更大规模数据） generative PDE solver. Across multiple 基准（用于比较性能的标准数据集或方法） PDE systems as well as multiphysics and interacting PDE systems, 我们的方法 produces solution fields with lower numerical error than existing 最先进（当前最好的、领先的方法） generative methods.",
      "oneSentenceSummary": "【cs.LG】Andrew Millard等Particle-Guided Diffusion Models for Partial Differential Equations，在cs.LG取得新进展。",
      "authors": [
        {
          "original": "Andrew Millard",
          "chinese": null
        },
        {
          "original": "Fredrik Lindsten",
          "chinese": null
        },
        {
          "original": "Zheng Zhao",
          "chinese": null
        }
      ],
      "published": "2026-01-30T18:30:24Z",
      "categories": [
        "cs.LG"
      ],
      "primaryCategory": "cs.LG",
      "pdfUrl": "https://arxiv.org/pdf/2601.23262v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23262v1",
      "keyInfo": {
        "contributions": [
          "We introduce a guided stochastic sampling method that augments sampling from diffusion models with physics-based guidance derived from partial differential equation (PDE) residuals and observational constraints, ensuring generated samples remain physically admissible"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23261v1",
      "title": "TEON: Tensorized Orthonormalization Beyond Layer-Wise Muon for 大语言模型（基于海量文本训练的语言模型，如GPT） Pre-Training",
      "originalTitle": "TEON: Tensorized Orthonormalization Beyond Layer-Wise Muon for Large Language Model Pre-Training",
      "summary": "The Muon optimizer has demonstrated strong 经验性的（基于实验和观察的） performance in pre-training large language models by performing matrix-level gradient (or momentum) orthogonalization in each layer independently. In this work, we propose TEON, a principled generalization of Muon that extends orthogonalization beyond individual layers by modeling the gradients of a 神经网络（一种受人脑启发的计算模型，由许多互相连接的节点组成） as a stru...",
      "plainSummary": "The Muon optimizer has demonstrated strong 经验性的（基于实验和观察的） performance in pre-training large language models by performing matrix-level gradient (or momentum) orthogonalization in each layer independently. In this work, 我们提出 TEON, a principled generalization of Muon that extends orthogonalization beyond individual layers by modeling the gradients of a 神经网络（一种受人脑启发的计算模型，由许多互相连接的节点组成） as a structured higher-order tensor. We present TEON's improved convergence guarantee over layer-wise Muon, and further develop a practical instantiation of TEON based on the 理论性的（基于数学推导的） analysis with corresponding ablation. We evaluate our approach on two widely adopted architectures: GPT-style models, ranging from 130M to 774M parameters, and LLaMA-style models, ranging from 60M to 1B parameters. 实验结果表明 that TEON consistently improves training and validation 困惑度（语言模型预测能力的度量，越低越好） across model scales and exhibits strong robustness under various approximate SVD schemes.",
      "oneSentenceSummary": "【cs.LG】Ruijie Zhang等TEON，使用We present TEON's improved con...，在cs.LG取得新进展。",
      "authors": [
        {
          "original": "Ruijie Zhang",
          "chinese": null
        },
        {
          "original": "Yequan Zhao",
          "chinese": null
        },
        {
          "original": "Ziyue Liu",
          "chinese": null
        },
        {
          "original": "Zhengyang Wang",
          "chinese": null
        },
        {
          "original": "Dongyang Li",
          "chinese": null
        },
        {
          "original": "Yupeng Su",
          "chinese": null
        },
        {
          "original": "Sijia Liu",
          "chinese": null
        },
        {
          "original": "Zheng Zhang",
          "chinese": null
        }
      ],
      "published": "2026-01-30T18:30:12Z",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primaryCategory": "cs.LG",
      "pdfUrl": "https://arxiv.org/pdf/2601.23261v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23261v1",
      "keyInfo": {
        "contributions": [
          "In this work, we propose TEON, a principled generalization of Muon that extends orthogonalization beyond individual layers by modeling the gradients of a 神经网络（一种受人脑启发的计算模型，由许多互相连接的节点组成） as a structured higher-order tensor",
          "We present TEON's improved convergence guarantee over layer-wise Muon, and further develop a practical instantiation of TEON based on the 理论性的（基于数学推导的） analysis with corresponding ablation"
        ],
        "methods": [
          "We present TEON's improved convergence guarantee over layer-wise Muon, and further develop a practical instantiation of TEON based on the 理论性的（基于数学推导的） analysis with corresponding ablation"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23258v1",
      "title": "Agnostic Language Identification and Generation",
      "originalTitle": "Agnostic Language Identification and Generation",
      "summary": "Recent works on language identification and generation have established tight statistical rates at which these tasks can be achieved. These works typically operate under a strong realizability assumption: that the input data is drawn from an unknown distribution necessarily supported on some language in a given collection. In this work, we relax this assumption of realizability entirely, and impos...",
      "plainSummary": "Recent works on language identification and generation have established tight statistical rates at which these tasks can be achieved. These works typically operate under a strong realizability assumption: that the input data is drawn from an unknown distribution necessarily supported on some language in a given collection. In this work, we relax this assumption of realizability entirely, and impose no restrictions on the distribution of the input data. 我们提出 objectives to study both language identification and generation in this more general \"agnostic\" setup. Across both problems, we obtain 新颖的（创新的、前人未做过的） interesting characterizations and nearly tight rates.",
      "oneSentenceSummary": "【cs.LG】Mikael Møller Høgsgaard等Agnostic Language Identification and Generation，在cs.LG取得新进展。",
      "authors": [
        {
          "original": "Mikael Møller Høgsgaard",
          "chinese": null
        },
        {
          "original": "Chirag Pabbaraju",
          "chinese": null
        }
      ],
      "published": "2026-01-30T18:26:28Z",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primaryCategory": "cs.LG",
      "pdfUrl": "https://arxiv.org/pdf/2601.23258v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23258v1",
      "keyInfo": {
        "contributions": [
          "We propose objectives to study both language identification and generation in this more general \"agnostic\" setup"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23255v1",
      "title": "Now You Hear Me: Audio Narrative Attacks Against Large Audio-Language Models",
      "originalTitle": "Now You Hear Me: Audio Narrative Attacks Against Large Audio-Language Models",
      "summary": "Large audio-language models increasingly operate on raw speech inputs, enabling more seamless integration across domains such as voice assistants, education, and clinical triage. This transition, however, introduces a distinct class of vulnerabilities that remain largely uncharacterized. We examine the security implications of this modality shift by designing a text-to-audio jailbreak that embeds ...",
      "plainSummary": "Large audio-language models increasingly operate on raw speech inputs, enabling more seamless integration across domains such as voice assistants, education, and clinical triage. This transition, however, introduces a distinct class of vulnerabilities that remain largely uncharacterized. We examine the security implications of this modality shift by designing a text-to-audio jailbreak that embeds disallowed directives within a narrative-style audio stream. The attack leverages an advanced instruction-following text-to-speech (TTS) model to exploit structural and acoustic properties, thereby circumventing safety mechanisms primarily calibrated for text. When delivered through synthetic speech, the narrative format elicits restricted outputs from 最先进（当前最好的、领先的方法） models, including Gemini 2.0 Flash, achieving a 98.26% success rate that substantially exceeds text-only baselines. These results highlight the need for safety frameworks that jointly reason over linguistic and paralinguistic representations, particularly as speech-based interfaces become more prevalent.",
      "oneSentenceSummary": "【cs.CL】Ye Yu等Now You Hear Me，使用The attack leverages an advanc...，在cs.CL取得新进展。",
      "authors": [
        {
          "original": "Ye Yu",
          "chinese": null
        },
        {
          "original": "Haibo Jin",
          "chinese": null
        },
        {
          "original": "Yaoning Yu",
          "chinese": null
        },
        {
          "original": "Jun Zhuang",
          "chinese": null
        },
        {
          "original": "Haohan Wang",
          "chinese": null
        }
      ],
      "published": "2026-01-30T18:23:02Z",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primaryCategory": "cs.CL",
      "pdfUrl": "https://arxiv.org/pdf/2601.23255v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23255v1",
      "keyInfo": {
        "contributions": [
          "This transition, however, introduces a distinct class of vulnerabilities that remain largely uncharacterized",
          "We examine the security implications of this modality shift by designing a text-to-audio jailbreak that embeds disallowed directives within a narrative-style audio stream"
        ],
        "methods": [
          "The attack leverages an advanced instruction-following text-to-speech (TTS) model to exploit structural and acoustic properties, thereby circumventing safety mechanisms primarily calibrated for text"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23253v1",
      "title": "Training-Free Test-Time Adaptation with Brownian Distance Covariance in Vision-Language Models",
      "originalTitle": "Training-Free Test-Time Adaptation with Brownian Distance Covariance in Vision-Language Models",
      "summary": "Vision-language models suffer performance degradation under domain shift, limiting real-world applicability. Existing test-time adaptation methods are computationally intensive, rely on back-propagation, and often focus on single modalities. To address these issues, we propose Training-free Test-Time Adaptation with Brownian Distance Covariance (TaTa). TaTa leverages Brownian Distance Covariance-a...",
      "plainSummary": "Vision-language models suffer performance degradation under domain shift, limiting real-world applicability. Existing test-time adaptation methods are computationally intensive, rely on back-propagation, and often focus on single modalities. To address these issues, 我们提出 Training-free Test-Time Adaptation with Brownian Distance Covariance (TaTa). TaTa leverages Brownian Distance Covariance-a powerful statistical measure that captures both linear and nonlinear dependencies via pairwise distances-to dynamically adapt VLMs to new domains without training or back-propagation. This not only improves efficiency but also enhances stability by avoiding disruptive weight updates. TaTa further integrates attribute-enhanced prompting to improve vision-language inference with descriptive visual cues. Combined with dynamic clustering and pseudo-label refinement, it effectively recalibrates the model for 新颖的（创新的、前人未做过的） visual contexts. Experiments across diverse datasets show that TaTa significantly reduces computational cost while achieving 最先进（当前最好的、领先的方法） performance in domain and cross-dataset generalization.",
      "oneSentenceSummary": "【cs.CV】Yi Zhang等Training-Free Test-Time Adaptation with Brownian Distance Covariance in Vision-Language Models，使用TaTa leverages Brownian Distan...，在cs.CV取得新进展。",
      "authors": [
        {
          "original": "Yi Zhang",
          "chinese": null
        },
        {
          "original": "Chun-Wun Cheng",
          "chinese": null
        },
        {
          "original": "Angelica I. Aviles-Rivero",
          "chinese": null
        },
        {
          "original": "Zhihai He",
          "chinese": null
        },
        {
          "original": "Liang-Jie Zhang",
          "chinese": null
        }
      ],
      "published": "2026-01-30T18:21:45Z",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primaryCategory": "cs.CV",
      "pdfUrl": "https://arxiv.org/pdf/2601.23253v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23253v1",
      "keyInfo": {
        "contributions": [
          "To address these issues, we propose Training-free Test-Time Adaptation with Brownian Distance Covariance (TaTa)"
        ],
        "methods": [
          "TaTa leverages Brownian Distance Covariance-a powerful statistical measure that captures both linear and nonlinear dependencies via pairwise distances-to dynamically adapt VLMs to new domains without training or back-propagation"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23252v1",
      "title": "Nested Slice Sampling: Vectorized Nested Sampling for GPU-Accelerated Inference",
      "originalTitle": "Nested Slice Sampling: Vectorized Nested Sampling for GPU-Accelerated Inference",
      "summary": "Model comparison and calibrated uncertainty quantification often require integrating over parameters, but 可扩展的（能够处理更大规模数据） inference can be challenging for complex, multimodal targets. Nested Sampling is a 鲁棒的（对噪声和扰动不敏感） alternative to standard MCMC, yet its typically sequential structure and hard constraints make 高效的（速度快、资源消耗少） accelerator implementations difficult. This paper introduces Nested S...",
      "plainSummary": "Model comparison and calibrated uncertainty quantification often require integrating over parameters, but 可扩展的（能够处理更大规模数据） inference can be challenging for complex, multimodal targets. Nested Sampling is a 鲁棒的（对噪声和扰动不敏感） alternative to standard MCMC, yet its typically sequential structure and hard constraints make 高效的（速度快、资源消耗少） accelerator implementations difficult. This paper introduces Nested Slice Sampling (NSS), a GPU-friendly, vectorized formulation of Nested Sampling that uses Hit-and-Run Slice Sampling for constrained updates. A tuning analysis yields a simple near-optimal rule for setting the slice width, improving high-dimensional behavior and making per-step compute more predictable for parallel execution. Experiments on challenging synthetic targets, high dimensional Bayesian inference, and Gaussian process hyperparameter marginalization show that NSS maintains accurate evidence estimates and high-quality 后验概率（观察到数据后的概率） samples, and is particularly 鲁棒的（对噪声和扰动不敏感） on difficult multimodal problems where current 最先进（当前最好的、领先的方法） methods such as tempered SMC baselines can struggle. An open-source implementation is released to facilitate adoption and reproducibility.",
      "oneSentenceSummary": "【stat.CO】David Yallup等Nested Slice Sampling，在stat.CO取得新进展。",
      "authors": [
        {
          "original": "David Yallup",
          "chinese": null
        },
        {
          "original": "Namu Kroupa",
          "chinese": null
        },
        {
          "original": "Will Handley",
          "chinese": null
        }
      ],
      "published": "2026-01-30T18:20:32Z",
      "categories": [
        "stat.CO",
        "cs.LG",
        "stat.ML"
      ],
      "primaryCategory": "stat.CO",
      "pdfUrl": "https://arxiv.org/pdf/2601.23252v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23252v1",
      "keyInfo": {
        "contributions": [
          "This paper introduces Nested Slice Sampling (NSS), a GPU-friendly, vectorized formulation of Nested Sampling that uses Hit-and-Run Slice Sampling for constrained updates"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23251v1",
      "title": "Structured Over Scale: Learning Spatial Reasoning from Educational Video",
      "originalTitle": "Structured Over Scale: Learning Spatial Reasoning from Educational Video",
      "summary": "Vision-language models (VLMs) demonstrate impressive performance on standard video understanding benchmarks yet fail systematically on simple reasoning tasks that preschool children can solve, including counting, spatial reasoning, and compositional understanding. We hypothesize that the pedagogically-structured content of educational videos provides an ideal training signal for improving these ca...",
      "plainSummary": "Vision-language models (VLMs) demonstrate impressive performance on standard video understanding benchmarks yet fail systematically on simple reasoning tasks that preschool children can solve, including counting, spatial reasoning, and compositional understanding. We hypothesize that the pedagogically-structured content of educational videos provides an ideal training signal for improving these capabilities. We introduce DoraVQA, a dataset of 5,344 question-answer pairs automatically extracted from 8 seasons of Dora the Explorer with precise timestamp alignment. Each episode follows a consistent \\textit{context-question-pause-answer} structure that creates a self-contained learning environment analogous to interactive tutoring. We fine-tune both Qwen2 and Qwen3 using Group Relative Policy 优化（寻找最佳参数或解决方案的过程） (GRPO), leveraging the clear correctness signals and structured reasoning traces inherent in educational content. Despite training exclusively on 38 hours of children's educational videos, our approach achieves improvements of 8-14 points on DoraVQA and 最先进（当前最好的、领先的方法） 86.16\\% on CVBench, with strong transfer to Video-MME and NExT-QA, demonstrating effective generalization from narrow pedagogical content to broad multimodal understanding. Through cross-domain benchmarks, we show that VLMs can perform tasks that require 鲁棒的（对噪声和扰动不敏感） reasoning learned from structured educational content, suggesting that content structure matters as much as content scale.",
      "oneSentenceSummary": "【cs.CV】Bishoy Galoaa等Structured Over Scale，使用We fine-tune both Qwen2 and Qw...，在cs.CV取得新进展。",
      "authors": [
        {
          "original": "Bishoy Galoaa",
          "chinese": null
        },
        {
          "original": "Xiangyu Bai",
          "chinese": null
        },
        {
          "original": "Sarah Ostadabbas",
          "chinese": null
        }
      ],
      "published": "2026-01-30T18:20:23Z",
      "categories": [
        "cs.CV"
      ],
      "primaryCategory": "cs.CV",
      "pdfUrl": "https://arxiv.org/pdf/2601.23251v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23251v1",
      "keyInfo": {
        "contributions": [
          "We introduce DoraVQA, a dataset of 5,344 question-answer pairs automatically extracted from 8 seasons of Dora the Explorer with precise timestamp alignment",
          "Each episode follows a consistent \\textit{context-question-pause-answer} structure that creates a self-contained learning environment analogous to interactive tutoring"
        ],
        "methods": [
          "We fine-tune both Qwen2 and Qwen3 using Group Relative Policy 优化（寻找最佳参数或解决方案的过程） (GRPO), leveraging the clear correctness signals and structured reasoning traces inherent in educational content"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23239v1",
      "title": "Graph Attention Network for Node Regression on Random Geometric Graphs with Erdős--Rényi contamination",
      "originalTitle": "Graph Attention Network for Node Regression on Random Geometric Graphs with Erdős--Rényi contamination",
      "summary": "Graph attention networks (GATs) are widely used and often appear 鲁棒的（对噪声和扰动不敏感） to noise in node covariates and edges, yet rigorous statistical guarantees demonstrating a provable advantage of GATs over non-attention graph neural networks~(GNNs) are scarce. We partially address this gap for node regression with graph-based errors-in-variables models under simultaneous covariate and edge corruption...",
      "plainSummary": "Graph attention networks (GATs) are widely used and often appear 鲁棒的（对噪声和扰动不敏感） to noise in node covariates and edges, yet rigorous statistical guarantees demonstrating a provable advantage of GATs over non-attention graph neural networks~(GNNs) are scarce. We partially address this gap for node regression with graph-based errors-in-variables models under simultaneous covariate and edge corruption: responses are generated from latent node-level covariates, but only noise-perturbed versions of the latent covariates are observed; and the sample graph is a random geometric graph created from the node covariates but contaminated by independent Erdős--Rényi edges. 我们提出 and analyze a carefully designed, task-specific GAT that constructs denoised proxy features for regression. We prove that regressing the response variables on the proxies achieves lower error asymptotically in (a) estimating the regression coefficient compared to the ordinary least squares (OLS) estimator on the noisy node covariates, and (b) predicting the response for an unlabelled node compared to a vanilla graph convolutional network~(GCN) -- under mild growth conditions. Our analysis leverages high-dimensional geometric tail bounds and concentration for neighbourhood counts and sample covariances. We verify our 理论性的（基于数学推导的） findings through experiments on synthetically generated data. We also perform experiments on real-world graphs and demonstrate the effectiveness of the 注意力机制（让模型关注输入中最相关部分的技术） in several node regression tasks.",
      "oneSentenceSummary": "【stat.ML】Somak Laha等Graph Attention Network for Node Regression on Random Geometric Graphs with Erdős--Rényi contamination，使用Our analysis leverages high-di...，在stat.ML取得新进展。",
      "authors": [
        {
          "original": "Somak Laha",
          "chinese": null
        },
        {
          "original": "Suqi Liu",
          "chinese": null
        },
        {
          "original": "Morgane Austern",
          "chinese": null
        }
      ],
      "published": "2026-01-30T18:09:03Z",
      "categories": [
        "stat.ML",
        "cs.IT",
        "cs.LG",
        "cs.SI",
        "math.ST"
      ],
      "primaryCategory": "stat.ML",
      "pdfUrl": "https://arxiv.org/pdf/2601.23239v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23239v1",
      "keyInfo": {
        "contributions": [
          "We partially address this gap for node regression with graph-based errors-in-variables models under simultaneous covariate and edge corruption: responses are generated from latent node-level covariates, but only noise-perturbed versions of the latent covariates are observed; and the sample graph is a random geometric graph created from the node covariates but contaminated by independent Erdős--Rényi edges",
          "We propose and analyze a carefully designed, task-specific GAT that constructs denoised proxy features for regression"
        ],
        "methods": [
          "Our analysis leverages high-dimensional geometric tail bounds and concentration for neighbourhood counts and sample covariances"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23238v1",
      "title": "How well do generative models solve inverse problems? A 基准（用于比较性能的标准数据集或方法） study",
      "originalTitle": "How well do generative models solve inverse problems? A benchmark study",
      "summary": "Generative learning generates high dimensional data based on low dimensional conditions, also called prompts. Therefore, generative learning algorithms are eligible for solving (Bayesian) inverse problems. In this article we compare a traditional Bayesian inverse approach based on a forward regression model and a 先验概率（观察到数据前的概率） sampled with the Markov Chain Monte Carlo method with three state of ...",
      "plainSummary": "Generative learning generates high dimensional data based on low dimensional conditions, also called prompts. Therefore, generative learning algorithms are eligible for solving (Bayesian) inverse problems. In this article we compare a traditional Bayesian inverse approach based on a forward regression model and a 先验概率（观察到数据前的概率） sampled with the Markov Chain Monte Carlo method with three 最先进 generative learning models, namely conditional Generative Adversarial Networks, Invertible Neural Networks and Conditional Flow Matching. We apply them to a problem of gas turbine combustor design where we map six independent design parameters to three performance labels. 我们提出 several metrics for the evaluation of this inverse design approaches and measure the 准确率（正确预测占总预测的比例） of the labels of the generated designs along with the diversity. We also study the performance as a function of the training dataset size. Our 基准（用于比较性能的标准数据集或方法） has a clear winner, as Conditional Flow Matching consistently outperforms all competing approaches.",
      "oneSentenceSummary": "【cs.LG】Patrick Krüger等How well do generative models solve inverse problems? A benchmark study，使用Generative learning generates ...，在cs.LG取得新进展。",
      "authors": [
        {
          "original": "Patrick Krüger",
          "chinese": null
        },
        {
          "original": "Patrick Materne",
          "chinese": null
        },
        {
          "original": "Werner Krebs",
          "chinese": null
        },
        {
          "original": "Hanno Gottschalk",
          "chinese": null
        }
      ],
      "published": "2026-01-30T18:06:50Z",
      "categories": [
        "cs.LG"
      ],
      "primaryCategory": "cs.LG",
      "pdfUrl": "https://arxiv.org/pdf/2601.23238v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23238v1",
      "keyInfo": {
        "contributions": [
          "We apply them to a problem of gas turbine combustor design where we map six independent design parameters to three performance labels",
          "We propose several metrics for the evaluation of this inverse design approaches and measure the 准确率（正确预测占总预测的比例） of the labels of the generated designs along with the diversity"
        ],
        "methods": [
          "Generative learning generates high dimensional data based on low dimensional conditions, also called prompts",
          "In this article we compare a traditional Bayesian inverse approach based on a forward regression model and a 先验概率（观察到数据前的概率） sampled with the Markov Chain Monte Carlo method with three state of the art generative learning models, namely conditional Generative Adversarial Networks, Invertible Neural Networks and Conditional Flow Matching"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23236v1",
      "title": "YuriiFormer: A Suite of Nesterov-Accelerated Transformers",
      "originalTitle": "YuriiFormer: A Suite of Nesterov-Accelerated Transformers",
      "summary": "We propose a variational 框架（提供结构的基础代码库） that interprets Transformer模型（一种处理序列数据的神经网络架构，特别擅长处理语言） layers as iterations of an 优化（寻找最佳参数或解决方案的过程） algorithm acting on token embeddings. In this view, self-attention implements a gradient step of an interaction energy, while MLP layers correspond to gradient updates of a potential energy. Standard GPT-style transformers emerge as vanilla 梯度下降（通过计算梯度来最小化损失...",
      "plainSummary": "我们提出 a variational 框架（提供结构的基础代码库） that interprets Transformer模型（一种处理序列数据的神经网络架构，特别擅长处理语言） layers as iterations of an 优化（寻找最佳参数或解决方案的过程） algorithm acting on token embeddings. In this view, self-attention implements a gradient step of an interaction energy, while MLP layers correspond to gradient updates of a potential energy. Standard GPT-style transformers emerge as vanilla 梯度下降（通过计算梯度来最小化损失函数的优化方法） on the resulting composite objective, implemented via Lie--Trotter splitting between these two energy functionals. This perspective enables principled architectural design using classical 优化（寻找最佳参数或解决方案的过程） ideas. As a proof of concept, we introduce a Nesterov-style accelerated Transformer模型（一种处理序列数据的神经网络架构，特别擅长处理语言） that preserves the same attention and MLP oracles. The resulting architecture consistently outperforms a nanoGPT 基线（用于对比的基准方法） on TinyStories and OpenWebText, demonstrating that 优化（寻找最佳参数或解决方案的过程）-theoretic insights can translate into practical gains.",
      "oneSentenceSummary": "【cs.LG】Aleksandr Zimin等YuriiFormer，使用This perspective enables princ...，在cs.LG取得新进展。",
      "authors": [
        {
          "original": "Aleksandr Zimin",
          "chinese": null
        },
        {
          "original": "Yury Polyanskiy",
          "chinese": null
        },
        {
          "original": "Philippe Rigollet",
          "chinese": null
        }
      ],
      "published": "2026-01-30T18:06:21Z",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML"
      ],
      "primaryCategory": "cs.LG",
      "pdfUrl": "https://arxiv.org/pdf/2601.23236v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23236v1",
      "keyInfo": {
        "contributions": [
          "We propose a variational 框架（提供结构的基础代码库） that interprets Transformer模型（一种处理序列数据的神经网络架构，特别擅长处理语言） layers as iterations of an 优化（寻找最佳参数或解决方案的过程） algorithm acting on token embeddings",
          "This perspective enables principled architectural design using classical 优化（寻找最佳参数或解决方案的过程） ideas"
        ],
        "methods": [
          "This perspective enables principled architectural design using classical 优化（寻找最佳参数或解决方案的过程） ideas"
        ],
        "applications": [
          "This perspective enables principled architectural design using classical 优化（寻找最佳参数或解决方案的过程） ideas"
        ]
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23233v1",
      "title": "Sequence Diffusion Model for Temporal Link Prediction in Continuous-Time Dynamic Graph",
      "originalTitle": "Sequence Diffusion Model for Temporal Link Prediction in Continuous-Time Dynamic Graph",
      "summary": "Temporal link prediction in dynamic graphs is a fundamental problem in many real-world systems. Existing temporal graph neural networks mainly focus on learning representations of historical interactions. Despite their strong performance, these models are still purely discriminative, producing point estimates for future links and lacking an explicit mechanism to capture the uncertainty and sequent...",
      "plainSummary": "Temporal link prediction in dynamic graphs is a fundamental problem in many real-world systems. Existing temporal graph neural networks mainly focus on learning representations of historical interactions. Despite their strong performance, these models are still purely discriminative, producing point estimates for future links and lacking an explicit mechanism to capture the uncertainty and sequential structure of future temporal interactions. In this paper, 我们提出 SDG, a 新颖的（创新的、前人未做过的） sequence-level diffusion 框架（提供结构的基础代码库） that unifies dynamic graph learning with generative denoising. Specifically, SDG injects noise into the entire historical interaction sequence and jointly reconstructs all interaction embeddings through a conditional denoising process, thereby enabling the model to capture more 全面的（覆盖广泛的、详细的） interaction distributions. To align the generative process with temporal link prediction, we employ a cross-attention denoising decoder to guide the reconstruction of the destination sequence and optimize the model in an end-to-end manner. 大量实验 on various temporal graph benchmarks show that SDG consistently achieves 最先进（当前最好的、领先的方法） performance in the temporal link prediction task.",
      "oneSentenceSummary": "【cs.LG】Nguyen Minh Duc等Sequence Diffusion Model for Temporal Link Prediction in Continuous-Time Dynamic Graph，在cs.LG取得新进展。",
      "authors": [
        {
          "original": "Nguyen Minh Duc",
          "chinese": null
        },
        {
          "original": "Viet Cuong Ta",
          "chinese": null
        }
      ],
      "published": "2026-01-30T18:02:12Z",
      "categories": [
        "cs.LG"
      ],
      "primaryCategory": "cs.LG",
      "pdfUrl": "https://arxiv.org/pdf/2601.23233v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23233v1",
      "keyInfo": {
        "contributions": [
          "Existing temporal graph neural networks mainly focus on learning representations of historical interactions",
          "In this paper, we propose SDG, a 新颖的（创新的、前人未做过的） sequence-level diffusion 框架（提供结构的基础代码库） that unifies dynamic graph learning with generative denoising"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23232v1",
      "title": "ShotFinder: Imagination-Driven Open-Domain Video Shot Retrieval via Web Search",
      "originalTitle": "ShotFinder: Imagination-Driven Open-Domain Video Shot Retrieval via Web Search",
      "summary": "In recent years, large language models (LLMs) have made rapid progress in information retrieval, yet existing research has mainly focused on text or static multimodal settings. Open-domain video shot retrieval, which involves richer temporal structure and more complex semantics, still lacks systematic benchmarks and analysis. To fill this gap, we introduce ShotFinder, a 基准（用于比较性能的标准数据集或方法） that fo...",
      "plainSummary": "In recent years, large language models (LLMs) have made rapid progress in information retrieval, yet existing research has mainly focused on text or static multimodal settings. Open-domain video shot retrieval, which involves richer temporal structure and more complex semantics, still lacks systematic benchmarks and analysis. To fill this gap, we introduce ShotFinder, a 基准（用于比较性能的标准数据集或方法） that formalizes editing requirements as keyframe-oriented shot descriptions and introduces five types of controllable single-factor constraints: Temporal order, Color, Visual style, Audio, and Resolution. We curate 1,210 high-quality samples from YouTube across 20 thematic categories, using large models for generation with human verification. Based on the 基准（用于比较性能的标准数据集或方法）, 我们提出 ShotFinder, a text-driven three-stage retrieval and localization 流程（数据处理或模型训练的完整流程）: (1) query expansion via video imagination, (2) candidate video retrieval with a search engine, and (3) description-guided temporal localization. Experiments on multiple closed-source and open-source models reveal a significant gap to human performance, with clear imbalance across constraints: temporal localization is relatively tractable, while color and visual style remain major challenges. These results reveal that open-domain video shot retrieval is still a critical capability that multimodal large models have yet to overcome.",
      "oneSentenceSummary": "【cs.CV】Tao Yu等ShotFinder，使用We curate 1,210 high-quality s...，在cs.CV取得新进展。",
      "authors": [
        {
          "original": "Tao Yu",
          "chinese": null
        },
        {
          "original": "Haopeng Jin",
          "chinese": null
        },
        {
          "original": "Hao Wang",
          "chinese": null
        },
        {
          "original": "Shenghua Chai",
          "chinese": null
        },
        {
          "original": "Yujia Yang",
          "chinese": null
        },
        {
          "original": "Junhao Gong",
          "chinese": null
        },
        {
          "original": "Jiaming Guo",
          "chinese": null
        },
        {
          "original": "Minghui Zhang",
          "chinese": null
        },
        {
          "original": "Xinlong Chen",
          "chinese": null
        },
        {
          "original": "Zhenghao Zhang",
          "chinese": null
        },
        {
          "original": "Yuxuan Zhou",
          "chinese": null
        },
        {
          "original": "Yanpei Gong",
          "chinese": null
        },
        {
          "original": "YuanCheng Liu",
          "chinese": null
        },
        {
          "original": "Yiming Ding",
          "chinese": null
        },
        {
          "original": "Kangwei Zeng",
          "chinese": null
        },
        {
          "original": "Pengfei Yang",
          "chinese": null
        },
        {
          "original": "Zhongtian Luo",
          "chinese": null
        },
        {
          "original": "Yufei Xiong",
          "chinese": null
        },
        {
          "original": "Shanbin Zhang",
          "chinese": null
        },
        {
          "original": "Shaoxiong Cheng",
          "chinese": null
        },
        {
          "original": "Huang Ruilin",
          "chinese": null
        },
        {
          "original": "Li Shuo",
          "chinese": null
        },
        {
          "original": "Yuxi Niu",
          "chinese": null
        },
        {
          "original": "Xinyuan Zhang",
          "chinese": null
        },
        {
          "original": "Yueya Xu",
          "chinese": null
        },
        {
          "original": "Jie Mao",
          "chinese": null
        },
        {
          "original": "Ruixuan Ji",
          "chinese": null
        },
        {
          "original": "Yaru Zhao",
          "chinese": null
        },
        {
          "original": "Mingchen Zhang",
          "chinese": null
        },
        {
          "original": "Jiabing Yang",
          "chinese": null
        },
        {
          "original": "Jiaqi Liu",
          "chinese": null
        },
        {
          "original": "YiFan Zhang",
          "chinese": null
        },
        {
          "original": "Hongzhu Yi",
          "chinese": null
        },
        {
          "original": "Xinming Wang",
          "chinese": null
        },
        {
          "original": "Cheng Zhong",
          "chinese": null
        },
        {
          "original": "Xiao Ma",
          "chinese": null
        },
        {
          "original": "Zhang Zhang",
          "chinese": null
        },
        {
          "original": "Yan Huang",
          "chinese": null
        },
        {
          "original": "Liang Wang",
          "chinese": null
        }
      ],
      "published": "2026-01-30T18:01:17Z",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primaryCategory": "cs.CV",
      "pdfUrl": "https://arxiv.org/pdf/2601.23232v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23232v1",
      "keyInfo": {
        "contributions": [
          "To fill this gap, we introduce ShotFinder, a 基准（用于比较性能的标准数据集或方法） that formalizes editing requirements as keyframe-oriented shot descriptions and introduces five types of controllable single-factor constraints: Temporal order, Color, Visual style, Audio, and Resolution",
          "Based on the 基准（用于比较性能的标准数据集或方法）, we propose ShotFinder, a text-driven three-stage retrieval and localization 流程（数据处理或模型训练的完整流程）: (1) query expansion via video imagination, (2) candidate video retrieval with a search engine, and (3) description-guided temporal localization"
        ],
        "methods": [
          "We curate 1,210 high-quality samples from YouTube across 20 thematic categories, using large models for generation with human verification",
          "Based on the 基准（用于比较性能的标准数据集或方法）, we propose ShotFinder, a text-driven three-stage retrieval and localization 流程（数据处理或模型训练的完整流程）: (1) query expansion via video imagination, (2) candidate video retrieval with a search engine, and (3) description-guided temporal localization"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23231v1",
      "title": "Solving Inverse Problems with Flow-based Models via Model Predictive Control",
      "originalTitle": "Solving Inverse Problems with Flow-based Models via Model Predictive Control",
      "summary": "Flow-based generative models provide strong unconditional priors for inverse problems, but guiding their dynamics for conditional generation remains challenging. Recent work casts training-free conditional generation in flow models as an optimal control problem; however, solving the resulting trajectory optimisation is computationally and memory intensive, requiring differentiation through the flo...",
      "plainSummary": "Flow-based generative models provide strong unconditional priors for inverse problems, but guiding their dynamics for conditional generation remains challenging. Recent work casts training-free conditional generation in flow models as an optimal control problem; however, solving the resulting trajectory optimisation is computationally and memory intensive, requiring differentiation through the flow dynamics or adjoint solves. 我们提出 MPC-Flow, a model predictive control 框架（提供结构的基础代码库） that formulates inverse problem solving with flow-based generative models as a sequence of control sub-problems, enabling practical optimal control-based guidance at inference time. We provide 理论性的（基于数学推导的） guarantees linking MPC-Flow to the underlying optimal control objective and show how different algorithmic choices yield a spectrum of guidance algorithms, including regimes that avoid 反向传播（训练神经网络时计算梯度的算法） through the 生成模型（能够创建新数据的AI模型） trajectory. We evaluate MPC-Flow on 基准（用于比较性能的标准数据集或方法） image restoration tasks, spanning linear and non-linear settings such as in-painting, deblurring, and super-resolution, and demonstrate strong performance and scalability to massive 最先进（当前最好的、领先的方法） architectures via training-free guidance of FLUX.2 (32B) in a quantised setting on consumer hardware.",
      "oneSentenceSummary": "【eess.IV】George Webber等Solving Inverse Problems with Flow-based Models via Model Predictive Control，在eess.IV取得新进展。",
      "authors": [
        {
          "original": "George Webber",
          "chinese": null
        },
        {
          "original": "Alexander Denker",
          "chinese": null
        },
        {
          "original": "Riccardo Barbano",
          "chinese": null
        },
        {
          "original": "Andrew J Reader",
          "chinese": null
        }
      ],
      "published": "2026-01-30T17:59:09Z",
      "categories": [
        "eess.IV",
        "cs.LG"
      ],
      "primaryCategory": "eess.IV",
      "pdfUrl": "https://arxiv.org/pdf/2601.23231v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23231v1",
      "keyInfo": {
        "contributions": [
          "We propose MPC-Flow, a model predictive control 框架（提供结构的基础代码库） that formulates inverse problem solving with flow-based generative models as a sequence of control sub-problems, enabling practical optimal control-based guidance at inference time"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23229v1",
      "title": "Strongly Polynomial Time Complexity of Policy Iteration for $L_\\infty$ 鲁棒的（对噪声和扰动不敏感） MDPs",
      "originalTitle": "Strongly Polynomial Time Complexity of Policy Iteration for $L_\\infty$ Robust MDPs",
      "summary": "Markov decision processes (MDPs) are a fundamental model in sequential decision making. 鲁棒的（对噪声和扰动不敏感） MDPs (RMDPs) extend this 框架（提供结构的基础代码库） by allowing uncertainty in transition probabilities and optimizing against the worst-case realization of that uncertainty. In particular, -rectangular RMDPs with uncertainty sets form a fundamental and expressive model: they subsume classical MDPs and turn-...",
      "plainSummary": "Markov decision processes (MDPs) are a fundamental model in sequential decision making. 鲁棒的（对噪声和扰动不敏感） MDPs (RMDPs) extend this 框架（提供结构的基础代码库） by allowing uncertainty in transition probabilities and optimizing against the worst-case realization of that uncertainty. In particular, -rectangular RMDPs with uncertainty sets form a fundamental and expressive model: they subsume classical MDPs and turn-based stochastic games. We consider this model with discounted payoffs. The existence of polynomial and strongly-polynomial time algorithms is a fundamental problem for these 优化（寻找最佳参数或解决方案的过程） models. For MDPs, linear programming yields polynomial-time algorithms for any arbitrary discount factor, and the seminal work of Ye established strongly--polynomial time for a fixed discount factor. The generalization of such results to RMDPs has remained an important open problem. In this work, we show that a 鲁棒的（对噪声和扰动不敏感） policy iteration algorithm runs in strongly-polynomial time for -rectangular RMDPs with a constant (fixed) discount factor, resolving an important algorithmic question.",
      "oneSentenceSummary": "【cs.AI】Ali Asadi等Strongly Polynomial Time Complexity of Policy Iteration for $L_\\infty$ Robust MDPs，在cs.AI取得新进展。",
      "authors": [
        {
          "original": "Ali Asadi",
          "chinese": null
        },
        {
          "original": "Krishnendu Chatterjee",
          "chinese": null
        },
        {
          "original": "Ehsan Goharshady",
          "chinese": null
        },
        {
          "original": "Mehrdad Karrabi",
          "chinese": null
        },
        {
          "original": "Alipasha Montaseri",
          "chinese": null
        },
        {
          "original": "Carlo Pagano",
          "chinese": null
        }
      ],
      "published": "2026-01-30T17:57:07Z",
      "categories": [
        "cs.AI",
        "cs.CC"
      ],
      "primaryCategory": "cs.AI",
      "pdfUrl": "https://arxiv.org/pdf/2601.23229v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23229v1",
      "keyInfo": {
        "contributions": [],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23228v1",
      "title": "Scaling Multiagent Systems with Process Rewards",
      "originalTitle": "Scaling Multiagent Systems with Process Rewards",
      "summary": "While multiagent systems have shown promise for tackling complex tasks via specialization, finetuning multiple agents simultaneously faces two key challenges: (1) credit assignment across agents, and (2) sample efficiency of expensive multiagent rollouts. In this work, we propose finetuning multiagent systems with per-action process rewards from AI feedback (MAPPA) to address both. Through assigni...",
      "plainSummary": "While multiagent systems have shown promise for tackling complex tasks via specialization, finetuning multiple agents simultaneously faces two key challenges: (1) credit assignment across agents, and (2) sample efficiency of expensive multiagent rollouts. In this work, 我们提出 finetuning multiagent systems with per-action process rewards from AI feedback (MAPPA) to address both. Through assigning credit to individual agent actions rather than only at task completion, MAPPA enables fine-grained supervision without ground truth labels while extracting maximal training signal from each rollout. We demonstrate our approach on competition math problems and tool-augmented data analysis tasks. On unseen math problems, MAPPA achieves +5.0--17.5pp on AIME and +7.8--17.2pp on AMC. For data analysis tasks, 我们的方法 improves success rate by +12.5pp while quality metrics improve by up to 30%, validating that per-action supervision can lead to improvements across different multiagent system on various domains. By addressing these challenges, our work takes a first step toward scaling multiagent systems for complex, long-horizon tasks with minimal human supervision.",
      "oneSentenceSummary": "【cs.AI】Ed Li等Scaling Multiagent Systems with Process Rewards，在cs.AI取得新进展。",
      "authors": [
        {
          "original": "Ed Li",
          "chinese": null
        },
        {
          "original": "Junyu Ren",
          "chinese": null
        },
        {
          "original": "Cat Yan",
          "chinese": null
        }
      ],
      "published": "2026-01-30T17:55:27Z",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.ET",
        "cs.MA"
      ],
      "primaryCategory": "cs.AI",
      "pdfUrl": "https://arxiv.org/pdf/2601.23228v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23228v1",
      "keyInfo": {
        "contributions": [
          "In this work, we propose finetuning multiagent systems with per-action process rewards from AI feedback (MAPPA) to address both"
        ],
        "methods": [],
        "applications": [
          "Through assigning credit to individual agent actions rather than only at task completion, MAPPA enables fine-grained supervision without ground truth labels while extracting maximal training signal from each rollout"
        ]
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23225v1",
      "title": "Agile 强化学习（通过试错学习最佳策略的机器学习方法） through Separable Neural Architecture",
      "originalTitle": "Agile Reinforcement Learning through Separable Neural Architecture",
      "summary": "Deep 强化学习（通过试错学习最佳策略的机器学习方法） (RL) is increasingly deployed in resource-constrained environments, yet the go-to function approximators - multilayer perceptrons (MLPs) - are often parameter-inefficient due to an imperfect inductive bias for the smooth structure of many value functions. This mismatch can also hinder sample efficiency and slow policy learning in this capacity-limited regime. Although ...",
      "plainSummary": "Deep 强化学习（通过试错学习最佳策略的机器学习方法） (RL) is increasingly deployed in resource-constrained environments, yet the go-to function approximators - multilayer perceptrons (MLPs) - are often parameter-inefficient due to an imperfect inductive bias for the smooth structure of many value functions. This mismatch can also hinder sample efficiency and slow policy learning in this capacity-limited regime. Although model compression techniques exist, they operate post-hoc and do not improve learning efficiency. Recent spline-based separable architectures - such as Kolmogorov-Arnold Networks (KANs) - have been shown to offer parameter efficiency but are widely reported to exhibit significant computational overhead, especially at scale. In seeking to address these limitations, this work introduces SPAN (SPline-based Adaptive Networks), a 新颖的（创新的、前人未做过的） function approximation approach to RL. SPAN adapts the low rank KHRONOS 框架（提供结构的基础代码库） by integrating a learnable preprocessing layer with a separable tensor product B-spline basis. SPAN is evaluated across discrete (PPO) and high-dimensional continuous (SAC) control tasks, as well as offline settings (Minari/D4RL). 经验性的（基于实验和观察的） results demonstrate that SPAN achieves a 30-50% improvement in sample efficiency and 1.3-9 times higher success rates across benchmarks compared to MLP baselines. Furthermore, SPAN demonstrates superior anytime performance and robustness to hyperparameter variations, suggesting it as a viable, high performance alternative for learning intrinsically 高效的（速度快、资源消耗少） policies in resource-limited settings.",
      "oneSentenceSummary": "【cs.LG】Rajib Mostakim等Agile Reinforcement Learning through Separable Neural Architecture，在cs.LG取得新进展。",
      "authors": [
        {
          "original": "Rajib Mostakim",
          "chinese": null
        },
        {
          "original": "Reza T. Batley",
          "chinese": null
        },
        {
          "original": "Sourav Saha",
          "chinese": null
        }
      ],
      "published": "2026-01-30T17:47:36Z",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primaryCategory": "cs.LG",
      "pdfUrl": "https://arxiv.org/pdf/2601.23225v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23225v1",
      "keyInfo": {
        "contributions": [
          "In seeking to address these limitations, this work introduces SPAN (SPline-based Adaptive Networks), a 新颖的（创新的、前人未做过的） function approximation approach to RL"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23224v1",
      "title": "Video-o3: Native Interleaved Clue Seeking for Long Video Multi-Hop Reasoning",
      "originalTitle": "Video-o3: Native Interleaved Clue Seeking for Long Video Multi-Hop Reasoning",
      "summary": "Existing multimodal large language models for long-video understanding predominantly rely on uniform sampling and single-turn inference, limiting their ability to identify sparse yet critical evidence amid extensive redundancy. We introduce Video-o3, a 新颖的（创新的、前人未做过的） 框架（提供结构的基础代码库） that supports iterative discovery of salient visual clues, fine-grained inspection of key segments, and adaptive ter...",
      "plainSummary": "Existing multimodal large language models for long-video understanding predominantly rely on uniform sampling and single-turn inference, limiting their ability to identify sparse yet critical evidence amid extensive redundancy. We introduce Video-o3, a 新颖的（创新的、前人未做过的） 框架（提供结构的基础代码库） that supports iterative discovery of salient visual clues, fine-grained inspection of key segments, and adaptive termination once sufficient evidence is acquired. Technically, we address two core challenges in interleaved tool invocation. First, to mitigate attention dispersion induced by the heterogeneity of reasoning and tool-calling, 我们提出 Task-Decoupled Attention Masking, which isolates per-step concentration while preserving shared global context. Second, to control context length growth in multi-turn interactions, we introduce a Verifiable Trajectory-Guided Reward that balances exploration coverage with reasoning efficiency. To support training at scale, we further develop a data synthesis 流程（数据处理或模型训练的完整流程） and construct Seeker-173K, comprising 173K high-quality tool-interaction trajectories for effective supervised and 强化学习（通过试错学习最佳策略的机器学习方法）. 大量实验 show that Video-o3 substantially outperforms 最先进（当前最好的、领先的方法） methods, achieving 72.1% 准确率（正确预测占总预测的比例） on MLVU and 46.5% on Video-Holmes. These results demonstrate Video-o3's strong multi-hop evidence-seeking and reasoning capabilities, and validate the effectiveness of native tool invocation in long-video scenarios.",
      "oneSentenceSummary": "【cs.CV】Xiangyu Zeng等Video-o3，在cs.CV取得新进展。",
      "authors": [
        {
          "original": "Xiangyu Zeng",
          "chinese": null
        },
        {
          "original": "Zhiqiu Zhang",
          "chinese": null
        },
        {
          "original": "Yuhan Zhu",
          "chinese": null
        },
        {
          "original": "Xinhao Li",
          "chinese": null
        },
        {
          "original": "Zikang Wang",
          "chinese": null
        },
        {
          "original": "Changlian Ma",
          "chinese": null
        },
        {
          "original": "Qingyu Zhang",
          "chinese": null
        },
        {
          "original": "Zizheng Huang",
          "chinese": null
        },
        {
          "original": "Kun Ouyang",
          "chinese": null
        },
        {
          "original": "Tianxiang Jiang",
          "chinese": null
        },
        {
          "original": "Ziang Yan",
          "chinese": null
        },
        {
          "original": "Yi Wang",
          "chinese": null
        },
        {
          "original": "Hongjie Zhang",
          "chinese": null
        },
        {
          "original": "Yali Wang",
          "chinese": null
        },
        {
          "original": "Limin Wang",
          "chinese": null
        }
      ],
      "published": "2026-01-30T17:47:30Z",
      "categories": [
        "cs.CV"
      ],
      "primaryCategory": "cs.CV",
      "pdfUrl": "https://arxiv.org/pdf/2601.23224v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23224v1",
      "keyInfo": {
        "contributions": [
          "We introduce Video-o3, a 新颖的（创新的、前人未做过的） 框架（提供结构的基础代码库） that supports iterative discovery of salient visual clues, fine-grained inspection of key segments, and adaptive termination once sufficient evidence is acquired",
          "First, to mitigate attention dispersion induced by the heterogeneity of reasoning and tool-calling, we propose Task-Decoupled Attention Masking, which isolates per-step concentration while preserving shared global context"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23223v1",
      "title": "Are you going to finish that? A Practical Study of the Tokenization Boundary Problem",
      "originalTitle": "Are you going to finish that? A Practical Study of the Tokenization Boundary Problem",
      "summary": "Language models (LMs) are trained over sequences of tokens, whereas users interact with LMs via text. This mismatch gives rise to the partial token problem, which occurs when a user ends their prompt in the middle of the expected next-token, leading to distorted next-token predictions. Although this issue has been studied using arbitrary character prefixes, its prevalence and severity in realistic...",
      "plainSummary": "Language models (LMs) are trained over sequences of tokens, whereas users interact with LMs via text. This mismatch gives rise to the partial token problem, which occurs when a user ends their prompt in the middle of the expected next-token, leading to distorted next-token predictions. Although this issue has been studied using arbitrary character prefixes, its prevalence and severity in realistic prompts respecting word boundaries remains underexplored. In this work, we identify three domains where token and \"word\" boundaries often do not line up: languages that do not use whitespace, highly compounding languages, and code. In Chinese, for example, up to 25% of word boundaries do not line up with token boundaries, making even natural, word-complete prompts susceptible to this problem. We systematically construct semantically natural prompts ending with a partial tokens; in experiments, we find that they comprise a serious failure mode: frontier LMs consistently place three orders of magnitude less probability on the correct continuation compared to when the prompt is \"backed-off\" to be token-aligned. This degradation does not diminish with scale and often worsens for larger models. Finally, we evaluate inference-time mitigations to the partial token problem and validate the effectiveness of recent exact solutions. Overall, we demonstrate the scale and severity of probability distortion caused by tokenization in realistic use cases, and provide practical recommentions for model inference providers.",
      "oneSentenceSummary": "【cs.CL】Hao Xu等Are you going to finish that? A Practical Study of the Tokenization Boundary Problem，使用Although this issue has been s...，在cs.CL取得新进展。",
      "authors": [
        {
          "original": "Hao Xu",
          "chinese": null
        },
        {
          "original": "Alisa Liu",
          "chinese": null
        },
        {
          "original": "Jonathan Hayase",
          "chinese": null
        },
        {
          "original": "Yejin Choi",
          "chinese": null
        },
        {
          "original": "Noah A. Smith",
          "chinese": null
        }
      ],
      "published": "2026-01-30T17:47:16Z",
      "categories": [
        "cs.CL"
      ],
      "primaryCategory": "cs.CL",
      "pdfUrl": "https://arxiv.org/pdf/2601.23223v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23223v1",
      "keyInfo": {
        "contributions": [],
        "methods": [
          "Although this issue has been studied using arbitrary character prefixes, its prevalence and severity in realistic prompts respecting word boundaries remains underexplored"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23222v1",
      "title": "Region-Normalized DPO for Medical 图像分割（将图像划分为不同区域或对象） under Noisy Judges",
      "originalTitle": "Region-Normalized DPO for Medical Image Segmentation under Noisy Judges",
      "summary": "While dense pixel-wise annotations remain the gold standard for medical 图像分割（将图像划分为不同区域或对象）, they are costly to obtain and limit scalability. In contrast, many deployed systems already produce inexpensive automatic quality-control (QC) signals like model agreement, uncertainty measures, or learned mask-quality scores which can be used for further model training without additional ground-truth anno...",
      "plainSummary": "While dense pixel-wise annotations remain the gold standard for medical 图像分割（将图像划分为不同区域或对象）, they are costly to obtain and limit scalability. In contrast, many deployed systems already produce inexpensive automatic quality-control (QC) signals like model agreement, uncertainty measures, or learned mask-quality scores which can be used for further model training without additional ground-truth annotation. However, these signals can be noisy and biased, making preference-based 微调（在预训练模型基础上进行小幅调整） susceptible to harmful updates. We study Direct Preference 优化（寻找最佳参数或解决方案的过程） (DPO) for segmentation from such noisy judges using proposals generated by a supervised base segmenter trained on a small labeled set. We find that outcomes depend strongly on how preference pairs are mined: selecting the judge's top-ranked proposal can improve peak performance when the judge is reliable, but can amplify harmful errors under weaker judges. 我们提出 Region-Normalized DPO (RN-DPO), a segmentation-aware objective which normalizes preference updates by the size of the disagreement region between masks, reducing the leverage of harmful comparisons and improving 优化（寻找最佳参数或解决方案的过程） stability. Across two medical datasets and multiple regimes, RN-DPO improves sustained performance and stabilizes preference-based 微调（在预训练模型基础上进行小幅调整）, outperforming standard DPO and strong baselines without requiring additional pixel annotations.",
      "oneSentenceSummary": "【cs.CV】Hamza Kalisch等Region-Normalized DPO for Medical Image Segmentation under Noisy Judges，使用We study Direct Preference 优化（...，在cs.CV取得新进展。",
      "authors": [
        {
          "original": "Hamza Kalisch",
          "chinese": null
        },
        {
          "original": "Constantin Seibold",
          "chinese": null
        },
        {
          "original": "Jens Kleesiek",
          "chinese": null
        },
        {
          "original": "Ken Herrmann",
          "chinese": null
        },
        {
          "original": "Frederic Jonske",
          "chinese": null
        }
      ],
      "published": "2026-01-30T17:45:53Z",
      "categories": [
        "cs.CV"
      ],
      "primaryCategory": "cs.CV",
      "pdfUrl": "https://arxiv.org/pdf/2601.23222v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23222v1",
      "keyInfo": {
        "contributions": [
          "We propose Region-Normalized DPO (RN-DPO), a segmentation-aware objective which normalizes preference updates by the size of the disagreement region between masks, reducing the leverage of harmful comparisons and improving 优化（寻找最佳参数或解决方案的过程） stability"
        ],
        "methods": [
          "We study Direct Preference 优化（寻找最佳参数或解决方案的过程） (DPO) for segmentation from such noisy judges using proposals generated by a supervised base segmenter trained on a small labeled set"
        ],
        "applications": [
          "In contrast, many deployed systems already produce inexpensive automatic quality-control (QC) signals like model agreement, uncertainty measures, or learned mask-quality scores which can be used for further model training without additional ground-truth annotation"
        ]
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23221v1",
      "title": "Optimal Fair Aggregation of Crowdsourced Noisy Labels using Demographic Parity Constraints",
      "originalTitle": "Optimal Fair Aggregation of Crowdsourced Noisy Labels using Demographic Parity Constraints",
      "summary": "As acquiring reliable ground-truth labels is usually costly, or infeasible, crowdsourcing and aggregation of noisy human annotations is the typical resort. Aggregating subjective labels, though, may amplify individual biases, particularly regarding sensitive features, raising fairness concerns. Nonetheless, fairness in crowdsourced aggregation remains largely unexplored, with no existing convergen...",
      "plainSummary": "As acquiring reliable ground-truth labels is usually costly, or infeasible, crowdsourcing and aggregation of noisy human annotations is the typical resort. Aggregating subjective labels, though, may amplify individual biases, particularly regarding sensitive features, raising fairness concerns. Nonetheless, fairness in crowdsourced aggregation remains largely unexplored, with no existing convergence guarantees and only limited post-processing approaches for enforcing -fairness under demographic parity. We address this gap by analyzing the fairness s of crowdsourced aggregation methods within the -fairness 框架（提供结构的基础代码库）, for Majority Vote and Optimal Bayesian aggregation. In the small-crowd regime, we derive an upper bound on the fairness gap of Majority Vote in terms of the fairness gaps of the individual annotators. We further show that the fairness gap of the aggregated consensus converges exponentially fast to that of the ground-truth under 可解释的（能够解释其决策过程） conditions. Since ground-truth itself may still be unfair, we generalize a 最先进（当前最好的、领先的方法） multiclass fairness post-processing algorithm from the continuous to the discrete setting, which enforces strict demographic parity constraints to any aggregation rule. Experiments on synthetic and real datasets demonstrate the effectiveness of our approach and corroborate the 理论性的（基于数学推导的） insights.",
      "oneSentenceSummary": "【cs.LG】Gabriel Singer等Optimal Fair Aggregation of Crowdsourced Noisy Labels using Demographic Parity Constraints，在cs.LG取得新进展。",
      "authors": [
        {
          "original": "Gabriel Singer",
          "chinese": null
        },
        {
          "original": "Samuel Gruffaz",
          "chinese": null
        },
        {
          "original": "Olivier Vo Van",
          "chinese": null
        },
        {
          "original": "Nicolas Vayatis",
          "chinese": null
        },
        {
          "original": "Argyris Kalogeratos",
          "chinese": null
        }
      ],
      "published": "2026-01-30T17:45:32Z",
      "categories": [
        "cs.LG"
      ],
      "primaryCategory": "cs.LG",
      "pdfUrl": "https://arxiv.org/pdf/2601.23221v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23221v1",
      "keyInfo": {
        "contributions": [],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23220v1",
      "title": "Med-Scout: Curing MLLMs' Geometric Blindness in Medical Perception via Geometry-Aware RL Post-Training",
      "originalTitle": "Med-Scout: Curing MLLMs' Geometric Blindness in Medical Perception via Geometry-Aware RL Post-Training",
      "summary": "Despite recent Multimodal Large Language Models (MLLMs)' linguistic prowess in medical diagnosis, we find even 最先进（当前最好的、领先的方法） MLLMs suffer from a critical perceptual deficit: geometric blindness. This failure to ground outputs in objective geometric constraints leads to plausible yet factually incorrect hallucinations, rooted in training paradigms that prioritize linguistic fluency over geometri...",
      "plainSummary": "Despite recent Multimodal Large Language Models (MLLMs)' linguistic prowess in medical diagnosis, we find even 最先进（当前最好的、领先的方法） MLLMs suffer from a critical perceptual deficit: geometric blindness. This failure to ground outputs in objective geometric constraints leads to plausible yet factually incorrect hallucinations, rooted in training paradigms that prioritize linguistic fluency over geometric fidelity. This paper introduces Med-Scout, a 新颖的（创新的、前人未做过的） 框架（提供结构的基础代码库） that \"cures\" this blindness via 强化学习（通过试错学习最佳策略的机器学习方法） (RL) that leverages the intrinsic geometric logic latent within unlabeled medical images. Instead of relying on costly expert annotations, Med-Scout derives verifiable supervision signals through three strategic proxy tasks: Hierarchical Scale Localization, Topological Jigsaw Reconstruction, and Anomaly Consistency Detection. To rigorously quantify this deficit, we present Med-Scout-Bench, a new 基准（用于比较性能的标准数据集或方法） specifically designed to evaluate geometric perception. Extensive evaluations show that Med-Scout significantly mitigates geometric blindness, outperforming leading proprietary and open-source MLLMs by over 40% on our 基准（用于比较性能的标准数据集或方法）. Furthermore, this enhanced geometric perception generalizes to broader medical understanding, achieving superior results on radiological and 全面的（覆盖广泛的、详细的） medical VQA tasks.",
      "oneSentenceSummary": "【cs.CV】Anglin Liu等Med-Scout，使用This paper introduces Med-Scou...，在cs.CV取得新进展。",
      "authors": [
        {
          "original": "Anglin Liu",
          "chinese": null
        },
        {
          "original": "Ruichao Chen",
          "chinese": null
        },
        {
          "original": "Yi Lu",
          "chinese": null
        },
        {
          "original": "Hongxia Xu",
          "chinese": null
        },
        {
          "original": "Jintai Chen",
          "chinese": null
        }
      ],
      "published": "2026-01-30T17:45:10Z",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primaryCategory": "cs.CV",
      "pdfUrl": "https://arxiv.org/pdf/2601.23220v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23220v1",
      "keyInfo": {
        "contributions": [
          "This paper introduces Med-Scout, a 新颖的（创新的、前人未做过的） 框架（提供结构的基础代码库） that \"cures\" this blindness via 强化学习（通过试错学习最佳策略的机器学习方法） (RL) that leverages the intrinsic geometric logic latent within unlabeled medical images",
          "To rigorously quantify this deficit, we present Med-Scout-Bench, a new 基准（用于比较性能的标准数据集或方法） specifically designed to evaluate geometric perception"
        ],
        "methods": [
          "This paper introduces Med-Scout, a 新颖的（创新的、前人未做过的） 框架（提供结构的基础代码库） that \"cures\" this blindness via 强化学习（通过试错学习最佳策略的机器学习方法） (RL) that leverages the intrinsic geometric logic latent within unlabeled medical images"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23219v1",
      "title": "MonoScale: Scaling Multi-Agent System with Monotonic Improvement",
      "originalTitle": "MonoScale: Scaling Multi-Agent System with Monotonic Improvement",
      "summary": "In recent years, LLM-based multi-agent systems (MAS) have advanced rapidly, using a router to decompose tasks and delegate subtasks to specialized agents. A natural way to expand capability is to scale up the agent pool by continually integrating new functional agents or tool interfaces, but naive expansion can trigger performance collapse when the router cold-starts on newly added, heterogeneous,...",
      "plainSummary": "In recent years, LLM-based multi-agent systems (MAS) have advanced rapidly, using a router to decompose tasks and delegate subtasks to specialized agents. A natural way to expand capability is to scale up the agent pool by continually integrating new functional agents or tool interfaces, but naive expansion can trigger performance collapse when the router cold-starts on newly added, heterogeneous, and unreliable agents. 我们提出 MonoScale, an expansion-aware update 框架（提供结构的基础代码库） that proactively generates a small set of agent-conditioned familiarization tasks, harvests evidence from both successful and failed interactions, and distills it into auditable natural-language memory to guide future routing. We formalize sequential augmentation as a contextual bandit and perform trust-region memory updates, yielding a monotonic non-decreasing performance guarantee across onboarding rounds. Experiments on GAIA and Humanity's Last Exam show stable gains as the agent pool grows, outperforming naive scale-up and strong-router fixed-pool baselines.",
      "oneSentenceSummary": "【cs.MA】Shuai Shao等MonoScale，使用In recent years, LLM-based mul...，在cs.MA取得新进展。",
      "authors": [
        {
          "original": "Shuai Shao",
          "chinese": null
        },
        {
          "original": "Yixiang Liu",
          "chinese": null
        },
        {
          "original": "Bingwei Lu",
          "chinese": null
        },
        {
          "original": "Weinan Zhang",
          "chinese": null
        }
      ],
      "published": "2026-01-30T17:44:49Z",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primaryCategory": "cs.MA",
      "pdfUrl": "https://arxiv.org/pdf/2601.23219v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23219v1",
      "keyInfo": {
        "contributions": [
          "We propose MonoScale, an expansion-aware update 框架（提供结构的基础代码库） that proactively generates a small set of agent-conditioned familiarization tasks, harvests evidence from both successful and failed interactions, and distills it into auditable natural-language memory to guide future routing"
        ],
        "methods": [
          "In recent years, LLM-based multi-agent systems (MAS) have advanced rapidly, using a router to decompose tasks and delegate subtasks to specialized agents"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23215v1",
      "title": "Tackling air quality with SAPIENS",
      "originalTitle": "Tackling air quality with SAPIENS",
      "summary": "Air pollution is a chronic problem in large cities worldwide and awareness is rising as the long-term health implications become clearer. Vehicular traffic has been identified as a major contributor to poor air quality. In a lot of cities the publicly available air quality measurements and forecasts are coarse-grained both in space and time. However, in general, real-time traffic intensity data is...",
      "plainSummary": "Air pollution is a chronic problem in large cities worldwide and awareness is rising as the long-term health implications become clearer. Vehicular traffic has been identified as a major contributor to poor air quality. In a lot of cities the publicly available air quality measurements and forecasts are coarse-grained both in space and time. However, in general, real-time traffic intensity data is openly available in various forms and is fine-grained. In this paper, we present an in-depth study of pollution sensor measurements combined with traffic data from Mexico City. We analyse and model the relationship between traffic intensity and air quality with the aim to provide hyper-local, dynamic air quality forecasts. We developed an innovative method to represent traffic intensities by transforming simple colour-coded traffic maps into concentric ring-based descriptions, enabling improved characterisation of traffic conditions. Using Partial Least Squares Regression, we predict pollution levels based on these newly defined traffic intensities. The model was optimised with various training samples to achieve the best predictive performance and gain insights into the relationship between pollutants and traffic. The workflow we have designed is straightforward and adaptable to other contexts, like other cities beyond the specifics of our dataset.",
      "oneSentenceSummary": "【cs.LG】Marcella Bona等Tackling air quality with SAPIENS，使用Using Partial Least Squares Re...，在cs.LG取得新进展。",
      "authors": [
        {
          "original": "Marcella Bona",
          "chinese": null
        },
        {
          "original": "Nathan Heatley",
          "chinese": null
        },
        {
          "original": "Jia-Chen Hua",
          "chinese": null
        },
        {
          "original": "Adriana Lara",
          "chinese": null
        },
        {
          "original": "Valeria Legaria-Santiago",
          "chinese": null
        },
        {
          "original": "Alberto Luviano Juarez",
          "chinese": null
        },
        {
          "original": "Fernando Moreno-Gomez",
          "chinese": null
        },
        {
          "original": "Jocelyn Richardson",
          "chinese": null
        },
        {
          "original": "Natan Vilchis",
          "chinese": null
        },
        {
          "original": "Xiwen Shirley Zheng",
          "chinese": null
        }
      ],
      "published": "2026-01-30T17:41:38Z",
      "categories": [
        "cs.LG"
      ],
      "primaryCategory": "cs.LG",
      "pdfUrl": "https://arxiv.org/pdf/2601.23215v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23215v1",
      "keyInfo": {
        "contributions": [
          "In this paper, we present an in-depth study of pollution sensor measurements combined with traffic data from Mexico City",
          "We developed an innovative method to represent traffic intensities by transforming simple colour-coded traffic maps into concentric ring-based descriptions, enabling improved characterisation of traffic conditions"
        ],
        "methods": [
          "Using Partial Least Squares Regression, we predict pollution levels based on these newly defined traffic intensities"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23212v1",
      "title": "Disentangling multispecific antibody function with graph neural networks",
      "originalTitle": "Disentangling multispecific antibody function with graph neural networks",
      "summary": "Multispecific antibodies offer transformative therapeutic potential by engaging multiple epitopes simultaneously, yet their efficacy is an emergent property governed by complex molecular architectures. Rational design is often bottlenecked by the inability to predict how subtle changes in domain topology influence functional outcomes, a challenge exacerbated by the scarcity of 全面的（覆盖广泛的、详细的） exper...",
      "plainSummary": "Multispecific antibodies offer transformative therapeutic potential by engaging multiple epitopes simultaneously, yet their efficacy is an emergent property governed by complex molecular architectures. Rational design is often bottlenecked by the inability to predict how subtle changes in domain topology influence functional outcomes, a challenge exacerbated by the scarcity of 全面的（覆盖广泛的、详细的） experimental data. Here, we introduce a computational 框架（提供结构的基础代码库） to address part of this gap. First, we present a generative method for creating large-scale, realistic synthetic functional landscapes that capture non-linear interactions where biological activity depends on domain connectivity. Second, 我们提出 a graph 神经网络（一种受人脑启发的计算模型，由许多互相连接的节点组成） architecture that explicitly encodes these topological constraints, distinguishing between format configurations that appear identical to sequence-only models. We demonstrate that this model, trained on synthetic landscapes, recapitulates complex functional properties and, via 迁移学习（将在一个任务学到的知识应用到其他任务）, has the potential to achieve high predictive 准确率（正确预测占总预测的比例） on limited biological datasets. We showcase the model's utility by optimizing trade-offs between efficacy and toxicity in trispecific T-cell engagers and retrieving optimal common light chains. This work provides a 鲁棒的（对噪声和扰动不敏感） benchmarking environment for disentangling the combinatorial complexity of multispecifics, accelerating the design of next-generation therapeutics.",
      "oneSentenceSummary": "【q-bio.BM】Joshua Southern等Disentangling multispecific antibody function with graph neural networks，在q-bio.BM取得新进展。",
      "authors": [
        {
          "original": "Joshua Southern",
          "chinese": null
        },
        {
          "original": "Changpeng Lu",
          "chinese": null
        },
        {
          "original": "Santrupti Nerli",
          "chinese": null
        },
        {
          "original": "Samuel D. Stanton",
          "chinese": null
        },
        {
          "original": "Andrew M. Watkins",
          "chinese": null
        },
        {
          "original": "Franziska Seeger",
          "chinese": null
        },
        {
          "original": "Frédéric A. Dreyer",
          "chinese": null
        }
      ],
      "published": "2026-01-30T17:36:19Z",
      "categories": [
        "q-bio.BM",
        "cs.AI"
      ],
      "primaryCategory": "q-bio.BM",
      "pdfUrl": "https://arxiv.org/pdf/2601.23212v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23212v1",
      "keyInfo": {
        "contributions": [
          "Rational design is often bottlenecked by the inability to predict how subtle changes in domain topology influence functional outcomes, a challenge exacerbated by the scarcity of 全面的（覆盖广泛的、详细的） experimental data",
          "Here, we introduce a computational 框架（提供结构的基础代码库） to address part of this gap"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23208v1",
      "title": "A Random Matrix Theory of Masked Self-Supervised Regression",
      "originalTitle": "A Random Matrix Theory of Masked Self-Supervised Regression",
      "summary": "In the era of Transformer模型（一种处理序列数据的神经网络架构，特别擅长处理语言） models, masked self-监督学习（使用标注数据训练模型） (SSL) has become a foundational training paradigm. A defining feature of masked SSL is that training aggregates predictions across many masking patterns, giving rise to a joint, matrix-valued predictor rather than a single vector-valued estimator. This object encodes how coordinates condition on one another ...",
      "plainSummary": "In the era of Transformer模型（一种处理序列数据的神经网络架构，特别擅长处理语言） models, masked self-监督学习（使用标注数据训练模型） (SSL) has become a foundational training paradigm. A defining feature of masked SSL is that training aggregates predictions across many masking patterns, giving rise to a joint, matrix-valued predictor rather than a single vector-valued estimator. This object encodes how coordinates condition on one another and poses new analytical challenges. We develop a precise high-dimensional analysis of masked modeling objectives in the proportional regime where the number of samples scales with the ambient dimension. Our results provide explicit expressions for the generalization error and characterize the spectral structure of the learned predictor, revealing how masked modeling extracts structure from data. For spiked covariance models, we show that the joint predictor undergoes a Baik--Ben Arous--Péché (BBP)-type phase transition, identifying when masked SSL begins to recover latent signals. Finally, we identify structured regimes in which masked self-监督学习（使用标注数据训练模型） provably outperforms PCA, highlighting potential advantages of SSL objectives over classical unsupervised methods",
      "oneSentenceSummary": "【stat.ML】Arie Wortsman Zurich等A Random Matrix Theory of Masked Self-Supervised Regression，在stat.ML取得新进展。",
      "authors": [
        {
          "original": "Arie Wortsman Zurich",
          "chinese": null
        },
        {
          "original": "Federica Gerace",
          "chinese": null
        },
        {
          "original": "Bruno Loureiro",
          "chinese": null
        },
        {
          "original": "Yue M. Lu",
          "chinese": null
        }
      ],
      "published": "2026-01-30T17:32:33Z",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primaryCategory": "stat.ML",
      "pdfUrl": "https://arxiv.org/pdf/2601.23208v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23208v1",
      "keyInfo": {
        "contributions": [
          "We develop a precise high-dimensional analysis of masked modeling objectives in the proportional regime where the number of samples scales with the ambient dimension"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23207v1",
      "title": "Learning to Execute Graph Algorithms Exactly with Graph Neural Networks",
      "originalTitle": "Learning to Execute Graph Algorithms Exactly with Graph Neural Networks",
      "summary": "Understanding what graph neural networks can learn, especially their ability to learn to execute algorithms, remains a central 理论性的（基于数学推导的） challenge. In this work, we prove exact learnability results for graph algorithms under bounded-degree and finite-精确率（预测为正例中真正正例的比例） constraints. Our approach follows a two-step process. First, we train an ensemble of multi-layer perceptrons (MLPs) to execute...",
      "plainSummary": "Understanding what graph neural networks can learn, especially their ability to learn to execute algorithms, remains a central 理论性的（基于数学推导的） challenge. In this work, we prove exact learnability results for graph algorithms under bounded-degree and finite-精确率（预测为正例中真正正例的比例） constraints. Our approach follows a two-step process. First, we train an ensemble of multi-layer perceptrons (MLPs) to execute the local instructions of a single node. Second, during inference, we use the trained MLP ensemble as the update function within a graph 神经网络（一种受人脑启发的计算模型，由许多互相连接的节点组成） (GNN). Leveraging Neural Tangent Kernel (NTK) theory, we show that local instructions can be learned from a small training set, enabling the complete graph algorithm to be executed during inference without error and with high probability. To illustrate the learning power of our setting, we establish a rigorous learnability result for the LOCAL model of distributed computation. We further demonstrate positive learnability results for widely studied algorithms such as message flooding, breadth-first and depth-first search, and Bellman-Ford.",
      "oneSentenceSummary": "【cs.LG】Muhammad Fetrat Qharabagh等Learning to Execute Graph Algorithms Exactly with Graph Neural Networks，在cs.LG取得新进展。",
      "authors": [
        {
          "original": "Muhammad Fetrat Qharabagh",
          "chinese": null
        },
        {
          "original": "Artur Back de Luca",
          "chinese": null
        },
        {
          "original": "George Giapitzakis",
          "chinese": null
        },
        {
          "original": "Kimon Fountoulakis",
          "chinese": null
        }
      ],
      "published": "2026-01-30T17:31:26Z",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primaryCategory": "cs.LG",
      "pdfUrl": "https://arxiv.org/pdf/2601.23207v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23207v1",
      "keyInfo": {
        "contributions": [],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23206v1",
      "title": "High-quality generation of dynamic game content via small language models: A proof of concept",
      "originalTitle": "High-quality generation of dynamic game content via small language models: A proof of concept",
      "summary": "Large language models (LLMs) offer promise for dynamic game content generation, but they face critical barriers, including narrative incoherence and high operational costs. Due to their large size, they are often accessed in the cloud, limiting their application in offline games. Many of these practical issues are solved by pivoting to small language models (SLMs), but existing studies using SLMs ...",
      "plainSummary": "Large language models (LLMs) offer promise for dynamic game content generation, but they face critical barriers, including narrative incoherence and high operational costs. Due to their large size, they are often accessed in the cloud, limiting their application in offline games. Many of these practical issues are solved by pivoting to small language models (SLMs), but existing studies using SLMs have resulted in poor output quality. 我们提出 a strategy of achieving high-quality SLM generation through aggressive 微调（在预训练模型基础上进行小幅调整） on deliberately scoped tasks with narrow context, constrained structure, or both. In short, more difficult tasks require narrower scope and higher specialization to the training corpus. Training data is synthetically generated via a DAG-based approach, grounding models in the specific game world. Such models can form the basis for agentic networks designed around the narratological 框架（提供结构的基础代码库） at hand, representing a more practical and 鲁棒的（对噪声和扰动不敏感） solution than cloud-dependent LLMs. To validate this approach, we present a proof-of-concept focusing on a single specialized SLM as the fundamental building block. We introduce a minimal RPG loop revolving around rhetorical battles of reputations, powered by this model. We demonstrate that a simple retry-until-success strategy reaches adequate quality (as defined by an LLM-as-a-judge scheme) with predictable latency suitable for real-time generation. While local quality assessment remains an open question, our results demonstrate feasibility for real-time generation under typical game engine constraints.",
      "oneSentenceSummary": "【cs.AI】Morten I. K. Munk等High-quality generation of dynamic game content via small language models，使用Many of these practical issues...，在cs.AI取得新进展。",
      "authors": [
        {
          "original": "Morten I. K. Munk",
          "chinese": null
        },
        {
          "original": "Arturo Valdivia",
          "chinese": null
        },
        {
          "original": "Paolo Burelli",
          "chinese": null
        }
      ],
      "published": "2026-01-30T17:30:59Z",
      "categories": [
        "cs.AI"
      ],
      "primaryCategory": "cs.AI",
      "pdfUrl": "https://arxiv.org/pdf/2601.23206v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23206v1",
      "keyInfo": {
        "contributions": [
          "We propose a strategy of achieving high-quality SLM generation through aggressive 微调（在预训练模型基础上进行小幅调整） on deliberately scoped tasks with narrow context, constrained structure, or both",
          "Such models can form the basis for agentic networks designed around the narratological 框架（提供结构的基础代码库） at hand, representing a more practical and 鲁棒的（对噪声和扰动不敏感） solution than cloud-dependent LLMs"
        ],
        "methods": [
          "Many of these practical issues are solved by pivoting to small language models (SLMs), but existing studies using SLMs have resulted in poor output quality",
          "To validate this approach, we present a proof-of-concept focusing on a single specialized SLM as the fundamental building block"
        ],
        "applications": [
          "We demonstrate that a simple retry-until-success strategy reaches adequate quality (as defined by an LLM-as-a-judge scheme) with predictable latency suitable for real-time generation"
        ]
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23204v1",
      "title": "TSAQA: Time Series Analysis Question And Answering 基准（用于比较性能的标准数据集或方法）",
      "originalTitle": "TSAQA: Time Series Analysis Question And Answering Benchmark",
      "summary": "Time series data are integral to critical applications across domains such as finance, healthcare, transportation, and environmental science. While recent work has begun to explore multi-task time series 问答系统（理解问题并给出答案的AI系统） (QA), current benchmarks remain limited to forecasting and anomaly detection tasks. We introduce TSAQA, a 新颖的（创新的、前人未做过的） unified 基准（用于比较性能的标准数据集或方法） designed to broaden task ...",
      "plainSummary": "Time series data are integral to critical applications across domains such as finance, healthcare, transportation, and environmental science. While recent work has begun to explore multi-task time series 问答系统（理解问题并给出答案的AI系统） (QA), current benchmarks remain limited to forecasting and anomaly detection tasks. We introduce TSAQA, a 新颖的（创新的、前人未做过的） unified 基准（用于比较性能的标准数据集或方法） designed to broaden task coverage and evaluate diverse temporal analysis capabilities. TSAQA integrates six diverse tasks under a single 框架（提供结构的基础代码库） ranging from conventional analysis, including anomaly detection and classification, to advanced analysis, such as characterization, comparison, data transformation, and temporal relationship analysis. Spanning 210k samples across 13 domains, the dataset employs diverse formats, including true-or-false (TF), multiple-choice (MC), and a 新颖的（创新的、前人未做过的） puzzling (PZ), to comprehensively assess time series analysis. Zero-shot evaluation demonstrates that these tasks are challenging for current Large Language Models (LLMs): the best-performing commercial LLM, Gemini-2.5-Flash, achieves an average score of only 65.08. Although instruction tuning boosts open-source performance: the best-performing open-source model, LLaMA-3.1-8B, shows significant room for improvement, highlighting the complexity of temporal analysis for LLMs.",
      "oneSentenceSummary": "【cs.AI】Baoyu Jing等TSAQA，使用Spanning 210k samples across 1...，在cs.AI取得新进展。",
      "authors": [
        {
          "original": "Baoyu Jing",
          "chinese": null
        },
        {
          "original": "Sanhorn Chen",
          "chinese": null
        },
        {
          "original": "Lecheng Zheng",
          "chinese": null
        },
        {
          "original": "Boyu Liu",
          "chinese": null
        },
        {
          "original": "Zihao Li",
          "chinese": null
        },
        {
          "original": "Jiaru Zou",
          "chinese": null
        },
        {
          "original": "Tianxin Wei",
          "chinese": null
        },
        {
          "original": "Zhining Liu",
          "chinese": null
        },
        {
          "original": "Zhichen Zeng",
          "chinese": null
        },
        {
          "original": "Ruizhong Qiu",
          "chinese": null
        },
        {
          "original": "Xiao Lin",
          "chinese": null
        },
        {
          "original": "Yuchen Yan",
          "chinese": null
        },
        {
          "original": "Dongqi Fu",
          "chinese": null
        },
        {
          "original": "Jingchao Ni",
          "chinese": null
        },
        {
          "original": "Jingrui He",
          "chinese": null
        },
        {
          "original": "Hanghang Tong",
          "chinese": null
        }
      ],
      "published": "2026-01-30T17:28:56Z",
      "categories": [
        "cs.AI"
      ],
      "primaryCategory": "cs.AI",
      "pdfUrl": "https://arxiv.org/pdf/2601.23204v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23204v1",
      "keyInfo": {
        "contributions": [
          "We introduce TSAQA, a 新颖的（创新的、前人未做过的） unified 基准（用于比较性能的标准数据集或方法） designed to broaden task coverage and evaluate diverse temporal analysis capabilities"
        ],
        "methods": [
          "Spanning 210k samples across 13 domains, the dataset employs diverse formats, including true-or-false (TF), multiple-choice (MC), and a 新颖的（创新的、前人未做过的） puzzling (PZ), to comprehensively assess time series analysis"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23201v1",
      "title": "Scale-Cascaded Diffusion Models for Super-Resolution in Medical Imaging",
      "originalTitle": "Scale-Cascaded Diffusion Models for Super-Resolution in Medical Imaging",
      "summary": "Diffusion models have been increasingly used as strong generative priors for solving inverse problems such as super-resolution in medical imaging. However, these approaches typically utilize a diffusion 先验概率（观察到数据前的概率） trained at a single scale, ignoring the hierarchical scale structure of image data. In this work, we propose to decompose images into Laplacian pyramid scales and train separate dif...",
      "plainSummary": "Diffusion models have been increasingly used as strong generative priors for solving inverse problems such as super-resolution in medical imaging. However, these approaches typically utilize a diffusion 先验概率（观察到数据前的概率） trained at a single scale, ignoring the hierarchical scale structure of image data. In this work, 我们提出 to decompose images into Laplacian pyramid scales and train separate diffusion priors for each frequency band. We then develop an algorithm to perform super-resolution that utilizes these priors to progressively refine reconstructions across different scales. Evaluated on brain, knee, and prostate MRI data, our approach both improves perceptual quality over baselines and reduces inference time through smaller coarse-scale networks. Our 框架（提供结构的基础代码库） unifies multiscale reconstruction and diffusion priors for medical image super-resolution.",
      "oneSentenceSummary": "【eess.IV】Darshan Thaker等Scale-Cascaded Diffusion Models for Super-Resolution in Medical Imaging，使用We then develop an algorithm t...，在eess.IV取得新进展。",
      "authors": [
        {
          "original": "Darshan Thaker",
          "chinese": null
        },
        {
          "original": "Mahmoud Mostapha",
          "chinese": null
        },
        {
          "original": "Radu Miron",
          "chinese": null
        },
        {
          "original": "Shihan Qiu",
          "chinese": null
        },
        {
          "original": "Mariappan Nadar",
          "chinese": null
        }
      ],
      "published": "2026-01-30T17:24:34Z",
      "categories": [
        "eess.IV",
        "cs.CV",
        "cs.LG"
      ],
      "primaryCategory": "eess.IV",
      "pdfUrl": "https://arxiv.org/pdf/2601.23201v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23201v1",
      "keyInfo": {
        "contributions": [
          "In this work, we propose to decompose images into Laplacian pyramid scales and train separate diffusion priors for each frequency band",
          "We then develop an algorithm to perform super-resolution that utilizes these priors to progressively refine reconstructions across different scales"
        ],
        "methods": [
          "We then develop an algorithm to perform super-resolution that utilizes these priors to progressively refine reconstructions across different scales"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23188v1",
      "title": "Deep Search with Hierarchical Meta-Cognitive Monitoring Inspired by Cognitive Neuroscience",
      "originalTitle": "Deep Search with Hierarchical Meta-Cognitive Monitoring Inspired by Cognitive Neuroscience",
      "summary": "Deep search agents powered by large language models have demonstrated strong capabilities in multi-step retrieval, reasoning, and long-horizon task execution. However, their practical failures often stem from the lack of mechanisms to monitor and regulate reasoning and retrieval states as tasks evolve under uncertainty. Insights from cognitive neuroscience suggest that human metacognition is hiera...",
      "plainSummary": "Deep search agents powered by large language models have demonstrated strong capabilities in multi-step retrieval, reasoning, and long-horizon task execution. However, their practical failures often stem from the lack of mechanisms to monitor and regulate reasoning and retrieval states as tasks evolve under uncertainty. Insights from cognitive neuroscience suggest that human metacognition is hierarchically organized, integrating fast anomaly detection with selectively triggered, experience-driven reflection. In this work, 我们提出 Deep Search with Meta-Cognitive Monitoring (DS-MCM), a deep search 框架（提供结构的基础代码库） augmented with an explicit hierarchical metacognitive monitoring mechanism. DS-MCM integrates a Fast Consistency Monitor, which performs lightweight checks on the alignment between external evidence and internal reasoning confidence, and a Slow Experience-Driven Monitor, which is selectively activated to guide corrective intervention based on experience memory from historical agent trajectories. By 嵌入（将离散数据转换为连续向量表示） monitoring directly into the reasoning-retrieval loop, DS-MCM determines both when intervention is warranted and how corrective actions should be informed by 先验概率（观察到数据前的概率） experience. Experiments across multiple deep search benchmarks and backbone models demonstrate that DS-MCM consistently improves performance and robustness.",
      "oneSentenceSummary": "【cs.CL】Zhongxiang Sun等Deep Search with Hierarchical Meta-Cognitive Monitoring Inspired by Cognitive Neuroscience，使用DS-MCM integrates a Fast Consi...，在cs.CL取得新进展。",
      "authors": [
        {
          "original": "Zhongxiang Sun",
          "chinese": null
        },
        {
          "original": "Qipeng Wang",
          "chinese": null
        },
        {
          "original": "Weijie Yu",
          "chinese": null
        },
        {
          "original": "Jingxuan Yang",
          "chinese": null
        },
        {
          "original": "Haolang Lu",
          "chinese": null
        },
        {
          "original": "Jun Xu",
          "chinese": null
        }
      ],
      "published": "2026-01-30T17:10:48Z",
      "categories": [
        "cs.CL"
      ],
      "primaryCategory": "cs.CL",
      "pdfUrl": "https://arxiv.org/pdf/2601.23188v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23188v1",
      "keyInfo": {
        "contributions": [
          "In this work, we propose Deep Search with Meta-Cognitive Monitoring (DS-MCM), a deep search 框架（提供结构的基础代码库） augmented with an explicit hierarchical metacognitive monitoring mechanism"
        ],
        "methods": [
          "DS-MCM integrates a Fast Consistency Monitor, which performs lightweight checks on the alignment between external evidence and internal reasoning confidence, and a Slow Experience-Driven Monitor, which is selectively activated to guide corrective intervention based on experience memory from historical agent trajectories"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23184v1",
      "title": "ReGuLaR: Variational Latent Reasoning Guided by Rendered Chain-of-Thought",
      "originalTitle": "ReGuLaR: Variational Latent Reasoning Guided by Rendered Chain-of-Thought",
      "summary": "While Chain-of-Thought (CoT) significantly enhances the performance of Large Language Models (LLMs), explicit reasoning chains introduce substantial computational redundancy. Recent latent reasoning methods attempt to mitigate this by compressing reasoning processes into 潜在空间（数据的压缩表示空间）, but often suffer from severe performance degradation due to the lack of appropriate compression guidance. In th...",
      "plainSummary": "While Chain-of-Thought (CoT) significantly enhances the performance of Large Language Models (LLMs), explicit reasoning chains introduce substantial computational redundancy. Recent latent reasoning methods attempt to mitigate this by compressing reasoning processes into 潜在空间（数据的压缩表示空间）, but often suffer from severe performance degradation due to the lack of appropriate compression guidance. In this study, 我们提出 Rendered CoT-Guided variational Latent Reasoning (ReGuLaR), a simple yet 新颖的（创新的、前人未做过的） latent learning paradigm resolving this issue. Fundamentally, we formulate latent reasoning within the Variational Auto-Encoding (VAE) 框架（提供结构的基础代码库）, sampling the current latent reasoning state from the 后验概率（观察到数据后的概率） distribution conditioned on previous ones. Specifically, when learning this variational latent reasoning model, we render explicit reasoning chains as images, from which we extract dense visual-semantic representations to regularize the 后验概率（观察到数据后的概率） distribution, thereby achieving 高效的（速度快、资源消耗少） compression with minimal information loss. 大量实验 demonstrate that ReGuLaR 显著优于 existing latent reasoning methods across both computational efficiency and reasoning effectiveness, and even surpasses CoT through multi-modal reasoning, providing a new and insightful solution to latent reasoning. Code: https://github.com/FanmengWang/ReGuLaR.",
      "oneSentenceSummary": "【cs.CL】Fanmeng Wang等ReGuLaR，在cs.CL取得新进展。",
      "authors": [
        {
          "original": "Fanmeng Wang",
          "chinese": null
        },
        {
          "original": "Haotian Liu",
          "chinese": null
        },
        {
          "original": "Guojiang Zhao",
          "chinese": null
        },
        {
          "original": "Hongteng Xu",
          "chinese": null
        },
        {
          "original": "Zhifeng Gao",
          "chinese": null
        }
      ],
      "published": "2026-01-30T17:08:06Z",
      "categories": [
        "cs.CL"
      ],
      "primaryCategory": "cs.CL",
      "pdfUrl": "https://arxiv.org/pdf/2601.23184v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23184v1",
      "keyInfo": {
        "contributions": [
          "While Chain-of-Thought (CoT) significantly enhances the performance of Large Language Models (LLMs), explicit reasoning chains introduce substantial computational redundancy",
          "In this study, we propose Rendered CoT-Guided variational Latent Reasoning (ReGuLaR), a simple yet 新颖的（创新的、前人未做过的） latent learning paradigm resolving this issue"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23183v1",
      "title": "JobResQA: A 基准（用于比较性能的标准数据集或方法） for LLM Machine Reading Comprehension on Multilingual Résumés and JDs",
      "originalTitle": "JobResQA: A Benchmark for LLM Machine Reading Comprehension on Multilingual Résumés and JDs",
      "summary": "We introduce JobResQA, a multilingual 问答系统（理解问题并给出答案的AI系统） 基准（用于比较性能的标准数据集或方法） for evaluating Machine Reading Comprehension (MRC) capabilities of LLMs on HR-specific tasks involving résumés and job descriptions. The dataset comprises 581 QA pairs across 105 synthetic résumé-job description pairs in five languages (English, Spanish, Italian, German, and Chinese), with questions spanning three compl...",
      "plainSummary": "We introduce JobResQA, a multilingual 问答系统（理解问题并给出答案的AI系统） 基准（用于比较性能的标准数据集或方法） for evaluating Machine Reading Comprehension (MRC) capabilities of LLMs on HR-specific tasks involving résumés and job descriptions. The dataset comprises 581 QA pairs across 105 synthetic résumé-job description pairs in five languages (English, Spanish, Italian, German, and Chinese), with questions spanning three complexity levels from basic factual extraction to complex cross-document reasoning. 我们提出 a data generation 流程（数据处理或模型训练的完整流程） derived from real-world sources through de-identification and data synthesis to ensure both realism and privacy, while controlled demographic and professional attributes (implemented via placeholders) enable systematic bias and fairness studies. We also present a cost-effective, human-in-the-loop translation 流程（数据处理或模型训练的完整流程） based on the TEaR methodology, incorporating MQM error annotations and selective post-editing to ensure an high-quality multi-way parallel 基准（用于比较性能的标准数据集或方法）. We provide a 基线（用于对比的基准方法） evaluations across multiple open-weight LLM families using an LLM-as-judge approach revealing higher performances on English and Spanish but substantial degradation for other languages, highlighting critical gaps in multilingual MRC capabilities for HR applications. JobResQA provides a reproducible 基准（用于比较性能的标准数据集或方法） for advancing fair and reliable LLM-based HR systems. The 基准（用于比较性能的标准数据集或方法） is publicly available at: https://github.com/Avature/jobresqa-基准（用于比较性能的标准数据集或方法）",
      "oneSentenceSummary": "【cs.CL】Casimiro Pio Carrino等JobResQA，使用We also present a cost-effecti...，在cs.CL取得新进展。",
      "authors": [
        {
          "original": "Casimiro Pio Carrino",
          "chinese": null
        },
        {
          "original": "Paula Estrella",
          "chinese": null
        },
        {
          "original": "Rabih Zbib",
          "chinese": null
        },
        {
          "original": "Carlos Escolano",
          "chinese": null
        },
        {
          "original": "José A. R. Fonollosa",
          "chinese": null
        }
      ],
      "published": "2026-01-30T17:06:59Z",
      "categories": [
        "cs.CL"
      ],
      "primaryCategory": "cs.CL",
      "pdfUrl": "https://arxiv.org/pdf/2601.23183v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23183v1",
      "keyInfo": {
        "contributions": [
          "We introduce JobResQA, a multilingual 问答系统（理解问题并给出答案的AI系统） 基准（用于比较性能的标准数据集或方法） for evaluating Machine Reading Comprehension (MRC) capabilities of LLMs on HR-specific tasks involving résumés and job descriptions",
          "We propose a data generation 流程（数据处理或模型训练的完整流程） derived from real-world sources through de-identification and data synthesis to ensure both realism and privacy, while controlled demographic and professional attributes (implemented via placeholders) enable systematic bias and fairness studies"
        ],
        "methods": [
          "We also present a cost-effective, human-in-the-loop translation 流程（数据处理或模型训练的完整流程） based on the TEaR methodology, incorporating MQM error annotations and selective post-editing to ensure an high-quality multi-way parallel 基准（用于比较性能的标准数据集或方法）",
          "We provide a 基线（用于对比的基准方法） evaluations across multiple open-weight LLM families using an LLM-as-judge approach revealing higher performances on English and Spanish but substantial degradation for other languages, highlighting critical gaps in multilingual MRC capabilities for HR applications"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23182v1",
      "title": "FourierSampler: Unlocking Non-Autoregressive Potential in Diffusion Language Models via Frequency-Guided Generation",
      "originalTitle": "FourierSampler: Unlocking Non-Autoregressive Potential in Diffusion Language Models via Frequency-Guided Generation",
      "summary": "Despite the non-autoregressive potential of diffusion language models (dLLMs), existing decoding strategies demonstrate positional bias, failing to fully unlock the potential of arbitrary generation. In this work, we delve into the inherent spectral characteristics of dLLMs and present the first frequency-domain analysis showing that low-frequency components in hidden states primarily encode globa...",
      "plainSummary": "Despite the non-autoregressive potential of diffusion language models (dLLMs), existing decoding strategies demonstrate positional bias, failing to fully unlock the potential of arbitrary generation. In this work, we delve into the inherent spectral characteristics of dLLMs and present the first frequency-domain analysis showing that low-frequency components in hidden states primarily encode global structural information and long-range dependencies, while high-frequency components are responsible for characterizing local details. Based on this observation, 我们提出 FourierSampler, which leverages a frequency-domain sliding window mechanism to dynamically guide the model to achieve a \"structure-to-detail\" generation. FourierSampler outperforms other inference enhancement strategies on LLADA and SDAR, achieving relative improvements of 20.4% on LLaDA1.5-8B and 16.0% on LLaDA-8B-Instruct. It notably surpasses similarly sized autoregressive models like Llama3.1-8B-Instruct.",
      "oneSentenceSummary": "【cs.CL】Siyang He等FourierSampler，使用Based on this observation, we ...，在cs.CL取得新进展。",
      "authors": [
        {
          "original": "Siyang He",
          "chinese": null
        },
        {
          "original": "Qiqi Wang",
          "chinese": null
        },
        {
          "original": "Xiaoran Liu",
          "chinese": null
        },
        {
          "original": "Hongnan Ma",
          "chinese": null
        },
        {
          "original": "Yiwei Shi",
          "chinese": null
        },
        {
          "original": "Yuerong Song",
          "chinese": null
        },
        {
          "original": "Ying Zhu",
          "chinese": null
        },
        {
          "original": "Tianyi Liang",
          "chinese": null
        },
        {
          "original": "Zengfeng Huang",
          "chinese": null
        },
        {
          "original": "Ziwei He",
          "chinese": null
        },
        {
          "original": "Xipeng Qiu",
          "chinese": null
        }
      ],
      "published": "2026-01-30T17:06:41Z",
      "categories": [
        "cs.CL"
      ],
      "primaryCategory": "cs.CL",
      "pdfUrl": "https://arxiv.org/pdf/2601.23182v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23182v1",
      "keyInfo": {
        "contributions": [
          "In this work, we delve into the inherent spectral characteristics of dLLMs and present the first frequency-domain analysis showing that low-frequency components in hidden states primarily encode global structural information and long-range dependencies, while high-frequency components are responsible for characterizing local details",
          "Based on this observation, we propose FourierSampler, which leverages a frequency-domain sliding window mechanism to dynamically guide the model to achieve a \"structure-to-detail\" generation"
        ],
        "methods": [
          "Based on this observation, we propose FourierSampler, which leverages a frequency-domain sliding window mechanism to dynamically guide the model to achieve a \"structure-to-detail\" generation"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23179v1",
      "title": "Make Anything Match Your Target: Universal Adversarial Perturbations against Closed-Source MLLMs via Multi-Crop Routed Meta 优化（寻找最佳参数或解决方案的过程）",
      "originalTitle": "Make Anything Match Your Target: Universal Adversarial Perturbations against Closed-Source MLLMs via Multi-Crop Routed Meta Optimization",
      "summary": "Targeted adversarial attacks on closed-source multimodal large language models (MLLMs) have been increasingly explored under black-box transfer, yet 先验概率（观察到数据前的概率） methods are predominantly sample-specific and offer limited reusability across inputs. We instead study a more stringent setting, Universal Targeted Transferable Adversarial Attacks (UTTAA), where a single perturbation must consistentl...",
      "plainSummary": "Targeted adversarial attacks on closed-source multimodal large language models (MLLMs) have been increasingly explored under black-box transfer, yet 先验概率（观察到数据前的概率） methods are predominantly sample-specific and offer limited reusability across inputs. We instead study a more stringent setting, Universal Targeted Transferable Adversarial Attacks (UTTAA), where a single perturbation must consistently steer arbitrary inputs toward a specified target across unknown commercial MLLMs. Naively adapting existing sample-wise attacks to this universal setting faces three core difficulties: (i) target supervision becomes high-variance due to target-crop randomness, (ii) token-wise matching is unreliable because universality suppresses image-specific cues that would otherwise anchor alignment, and (iii) few-source per-target adaptation is highly initialization-sensitive, which can degrade the attainable performance. In this work, 我们提出 MCRMO-Attack, which stabilizes supervision via Multi-Crop Aggregation with an Attention-Guided Crop, improves token-level reliability through alignability-gated Token Routing, and meta-learns a cross-target perturbation 先验概率（观察到数据前的概率） that yields stronger per-target solutions. Across commercial MLLMs, we boost unseen-image attack success rate by +23.7\\% on GPT-4o and +19.9\\% on Gemini-2.0 over the strongest universal 基线（用于对比的基准方法）.",
      "oneSentenceSummary": "【cs.AI】Hui Lu等Make Anything Match Your Target，在cs.AI取得新进展。",
      "authors": [
        {
          "original": "Hui Lu",
          "chinese": null
        },
        {
          "original": "Yi Yu",
          "chinese": null
        },
        {
          "original": "Yiming Yang",
          "chinese": null
        },
        {
          "original": "Chenyu Yi",
          "chinese": null
        },
        {
          "original": "Xueyi Ke",
          "chinese": null
        },
        {
          "original": "Qixing Zhang",
          "chinese": null
        },
        {
          "original": "Bingquan Shen",
          "chinese": null
        },
        {
          "original": "Alex Kot",
          "chinese": null
        },
        {
          "original": "Xudong Jiang",
          "chinese": null
        }
      ],
      "published": "2026-01-30T17:03:24Z",
      "categories": [
        "cs.AI"
      ],
      "primaryCategory": "cs.AI",
      "pdfUrl": "https://arxiv.org/pdf/2601.23179v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23179v1",
      "keyInfo": {
        "contributions": [
          "In this work, we propose MCRMO-Attack, which stabilizes supervision via Multi-Crop Aggregation with an Attention-Guided Crop, improves token-level reliability through alignability-gated Token Routing, and meta-learns a cross-target perturbation 先验概率（观察到数据前的概率） that yields stronger per-target solutions"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23174v1",
      "title": "Beyond Fixed Frames: Dynamic Character-Aligned Speech Tokenization",
      "originalTitle": "Beyond Fixed Frames: Dynamic Character-Aligned Speech Tokenization",
      "summary": "Neural audio codecs are at the core of modern conversational speech technologies, converting continuous speech into sequences of discrete tokens that can be processed by LLMs. However, existing codecs typically operate at fixed frame rates, allocating tokens uniformly in time and producing unnecessarily long sequences. In this work, we introduce DyCAST, a Dynamic Character-Aligned Speech Tokenizer...",
      "plainSummary": "Neural audio codecs are at the core of modern conversational speech technologies, converting continuous speech into sequences of discrete tokens that can be processed by LLMs. However, existing codecs typically operate at fixed frame rates, allocating tokens uniformly in time and producing unnecessarily long sequences. In this work, we introduce DyCAST, a Dynamic Character-Aligned Speech Tokenizer that enables variable-frame-rate tokenization through soft character-level alignment and explicit duration modeling. DyCAST learns to associate tokens with character-level linguistic units during training and supports alignment-free inference with direct control over token durations at decoding time. To improve speech resynthesis quality at low frame rates, we further introduce a retrieval-augmented decoding mechanism that enhances reconstruction fidelity without increasing bitrate. Experiments show that DyCAST achieves competitive speech resynthesis quality and downstream performance while using significantly fewer tokens than fixed-frame-rate codecs.",
      "oneSentenceSummary": "【cs.LG】Luca Della Libera等Beyond Fixed Frames，使用Experiments show that DyCAST a...，在cs.LG取得新进展。",
      "authors": [
        {
          "original": "Luca Della Libera",
          "chinese": null
        },
        {
          "original": "Cem Subakan",
          "chinese": null
        },
        {
          "original": "Mirco Ravanelli",
          "chinese": null
        }
      ],
      "published": "2026-01-30T16:58:40Z",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SD"
      ],
      "primaryCategory": "cs.LG",
      "pdfUrl": "https://arxiv.org/pdf/2601.23174v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23174v1",
      "keyInfo": {
        "contributions": [
          "In this work, we introduce DyCAST, a Dynamic Character-Aligned Speech Tokenizer that enables variable-frame-rate tokenization through soft character-level alignment and explicit duration modeling",
          "To improve speech resynthesis quality at low frame rates, we further introduce a retrieval-augmented decoding mechanism that enhances reconstruction fidelity without increasing bitrate"
        ],
        "methods": [
          "Experiments show that DyCAST achieves competitive speech resynthesis quality and downstream performance while using significantly fewer tokens than fixed-frame-rate codecs"
        ],
        "applications": [
          "In this work, we introduce DyCAST, a Dynamic Character-Aligned Speech Tokenizer that enables variable-frame-rate tokenization through soft character-level alignment and explicit duration modeling"
        ]
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23167v1",
      "title": "Hi-Light: A Path to high-fidelity, high-resolution video relighting with a 新颖的（创新的、前人未做过的） Evaluation Paradigm",
      "originalTitle": "Hi-Light: A Path to high-fidelity, high-resolution video relighting with a Novel Evaluation Paradigm",
      "summary": "Video relighting offers immense creative potential and commercial value but is hindered by challenges, including the absence of an adequate evaluation metric, severe light flickering, and the degradation of fine-grained details during editing. To overcome these challenges, we introduce Hi-Light, a 新颖的（创新的、前人未做过的）, training-free 框架（提供结构的基础代码库） for high-fidelity, high-resolution, 鲁棒的（对噪声和扰动不敏感） vide...",
      "plainSummary": "Video relighting offers immense creative potential and commercial value but is hindered by challenges, including the absence of an adequate evaluation metric, severe light flickering, and the degradation of fine-grained details during editing. To overcome these challenges, we introduce Hi-Light, a 新颖的（创新的、前人未做过的）, training-free 框架（提供结构的基础代码库） for high-fidelity, high-resolution, 鲁棒的（对噪声和扰动不敏感） video relighting. Our approach introduces three technical innovations: lightness 先验概率（观察到数据前的概率） anchored guided relighting diffusion that stabilises intermediate relit video, a Hybrid Motion-Adaptive Lighting Smoothing Filter that leverages optical flow to ensure temporal stability without introducing motion blur, and a LAB-based Detail Fusion module that preserves high-frequency detail information from the original video. Furthermore, to address the critical gap in evaluation, 我们提出 the Light Stability Score, the first quantitative metric designed to specifically measure lighting consistency. 大量实验 demonstrate that Hi-Light 显著优于 最先进（当前最好的、领先的方法） methods in both qualitative and quantitative comparisons, producing stable, highly detailed relit videos.",
      "oneSentenceSummary": "【cs.CV】Xiangrui Liu等Hi-Light，使用Our approach introduces three ...，在cs.CV取得新进展。",
      "authors": [
        {
          "original": "Xiangrui Liu",
          "chinese": null
        },
        {
          "original": "Haoxiang Li",
          "chinese": null
        },
        {
          "original": "Yezhou Yang",
          "chinese": null
        }
      ],
      "published": "2026-01-30T16:50:55Z",
      "categories": [
        "cs.CV"
      ],
      "primaryCategory": "cs.CV",
      "pdfUrl": "https://arxiv.org/pdf/2601.23167v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23167v1",
      "keyInfo": {
        "contributions": [
          "To overcome these challenges, we introduce Hi-Light, a 新颖的（创新的、前人未做过的）, training-free 框架（提供结构的基础代码库） for high-fidelity, high-resolution, 鲁棒的（对噪声和扰动不敏感） video relighting",
          "Our approach introduces three technical innovations: lightness 先验概率（观察到数据前的概率） anchored guided relighting diffusion that stabilises intermediate relit video, a Hybrid Motion-Adaptive Lighting Smoothing Filter that leverages optical flow to ensure temporal stability without introducing motion blur, and a LAB-based Detail Fusion module that preserves high-frequency detail information from the original video"
        ],
        "methods": [
          "Our approach introduces three technical innovations: lightness 先验概率（观察到数据前的概率） anchored guided relighting diffusion that stabilises intermediate relit video, a Hybrid Motion-Adaptive Lighting Smoothing Filter that leverages optical flow to ensure temporal stability without introducing motion blur, and a LAB-based Detail Fusion module that preserves high-frequency detail information from the original video"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23166v1",
      "title": "Monotonic Reference-Free Refinement for Autoformalization",
      "originalTitle": "Monotonic Reference-Free Refinement for Autoformalization",
      "summary": "While statement autoformalization has advanced rapidly, full-theorem autoformalization remains largely unexplored. Existing iterative refinement methods in statement autoformalization typicall improve isolated aspects of formalization, such as syntactic correctness, but struggle to jointly optimizing multiple quality dimensions, which is critical for full-theorem autoformalization. We introduce a ...",
      "plainSummary": "While statement autoformalization has advanced rapidly, full-theorem autoformalization remains largely unexplored. Existing iterative refinement methods in statement autoformalization typicall improve isolated aspects of formalization, such as syntactic correctness, but struggle to jointly optimizing multiple quality dimensions, which is critical for full-theorem autoformalization. We introduce a reference-free iterative monotonic process for full-theorem autoformalization that leverages complementary feedback from theorem provers and LLM-based judges, without access to ground-truth proofs or existing formalizations at inference time. Our approach optimizes a masked composite objective over Formal Validity, Logical Preservation, Mathematical Consistency, and Formal Quality, guided by a responsiveness map that indicates how different LLMs acting as different roles preferentially improve each dimension. We further propose an acceptance policy that guarantees certified monotonic improvement, and provide conditions ensuring convergence and termination. 经验性的（基于实验和观察的） experiments demonstrate the proposed process enables simultaneous improvement across multiple dimensions, achieving 93.44% formal validity and a 78.22% overall score on miniF2F, and 44.09% formal validity and a 29.79% overall score on ProofNet.",
      "oneSentenceSummary": "【cs.CL】Lan Zhang等Monotonic Reference-Free Refinement for Autoformalization，使用We introduce a reference-free ...，在cs.CL取得新进展。",
      "authors": [
        {
          "original": "Lan Zhang",
          "chinese": null
        },
        {
          "original": "Marco Valentino",
          "chinese": null
        },
        {
          "original": "André Freitas",
          "chinese": null
        }
      ],
      "published": "2026-01-30T16:48:33Z",
      "categories": [
        "cs.CL"
      ],
      "primaryCategory": "cs.CL",
      "pdfUrl": "https://arxiv.org/pdf/2601.23166v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23166v1",
      "keyInfo": {
        "contributions": [
          "We introduce a reference-free iterative monotonic process for full-theorem autoformalization that leverages complementary feedback from theorem provers and LLM-based judges, without access to ground-truth proofs or existing formalizations at inference time",
          "We further propose an acceptance policy that guarantees certified monotonic improvement, and provide conditions ensuring convergence and termination"
        ],
        "methods": [
          "We introduce a reference-free iterative monotonic process for full-theorem autoformalization that leverages complementary feedback from theorem provers and LLM-based judges, without access to ground-truth proofs or existing formalizations at inference time"
        ],
        "applications": [
          "经验性的（基于实验和观察的） experiments demonstrate the proposed process enables simultaneous improvement across multiple dimensions, achieving 93"
        ]
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23163v1",
      "title": "Probing the Trajectories of Reasoning Traces in Large Language Models",
      "originalTitle": "Probing the Trajectories of Reasoning Traces in Large Language Models",
      "summary": "Large language models (LLMs) increasingly solve difficult problems by producing \"reasoning traces\" before emitting a final response. However, it remains unclear how 准确率（正确预测占总预测的比例） and decision commitment evolve along a reasoning trajectory, and whether intermediate trace segments provide answer-relevant information beyond generic length or stylistic effects. Here, we propose a protocol to system...",
      "plainSummary": "Large language models (LLMs) increasingly solve difficult problems by producing \"reasoning traces\" before emitting a final response. However, it remains unclear how 准确率（正确预测占总预测的比例） and decision commitment evolve along a reasoning trajectory, and whether intermediate trace segments provide answer-relevant information beyond generic length or stylistic effects. Here, 我们提出 a protocol to systematically probe the trajectories of reasoning traces in LLMs by 1) generating a model's reasoning trace, 2) truncating it at fixed token-percentiles, and 3) injecting each partial trace back into the model (or a different model) to measure the induced distribution over answer choices via next-token probabilities. We apply this protocol to the open-source Qwen3-4B/-8B/-14B and gpt-oss-20b/-120b models across the multiple-choice GPQA Diamond and MMLU-Pro benchmarks. We find that 准确率（正确预测占总预测的比例） and decision commitment consistently increase as the percentage of provided reasoning tokens grows. These gains are primarily driven by relevant content in the model generation rather than context length or generic \"reasoning style\" effects. Stronger models often backtrack successfully from incorrect partial traces, but immediate answers often remain anchored in the weaker model's incorrect response. More broadly, we show that trajectory probing provides diagnostics for 高效的（速度快、资源消耗少） and safer deployment of reasoning models as the measurements can inform practical trace-handling and monitoring policies that improve reliability without assuming intermediate tokens are inherently faithful explanations.",
      "oneSentenceSummary": "【cs.LG】Marthe Ballon等Probing the Trajectories of Reasoning Traces in Large Language Models，在cs.LG取得新进展。",
      "authors": [
        {
          "original": "Marthe Ballon",
          "chinese": null
        },
        {
          "original": "Brecht Verbeken",
          "chinese": null
        },
        {
          "original": "Vincent Ginis",
          "chinese": null
        },
        {
          "original": "Andres Algaba",
          "chinese": null
        }
      ],
      "published": "2026-01-30T16:45:16Z",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primaryCategory": "cs.LG",
      "pdfUrl": "https://arxiv.org/pdf/2601.23163v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23163v1",
      "keyInfo": {
        "contributions": [
          "Here, we propose a protocol to systematically probe the trajectories of reasoning traces in LLMs by 1) generating a model's reasoning trace, 2) truncating it at fixed token-percentiles, and 3) injecting each partial trace back into the model (or a different model) to measure the induced distribution over answer choices via next-token probabilities"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23161v1",
      "title": "DIFFA-2: A Practical Diffusion 大语言模型（基于海量文本训练的语言模型，如GPT） for General Audio Understanding",
      "originalTitle": "DIFFA-2: A Practical Diffusion Large Language Model for General Audio Understanding",
      "summary": "Autoregressive (AR) large audio language models (LALMs) such as Qwen-2.5-Omni have achieved strong performance on audio understanding and interaction, but scaling them remains costly in data and computation, and strictly sequential decoding limits inference efficiency. Diffusion large language models (dLLMs) have recently been shown to make effective use of limited training data, and 先验概率（观察到数据前的概...",
      "plainSummary": "Autoregressive (AR) large audio language models (LALMs) such as Qwen-2.5-Omni have achieved strong performance on audio understanding and interaction, but scaling them remains costly in data and computation, and strictly sequential decoding limits inference efficiency. Diffusion large language models (dLLMs) have recently been shown to make effective use of limited training data, and 先验概率（观察到数据前的概率） work on DIFFA indicates that replacing an AR backbone with a diffusion counterpart can substantially improve audio understanding under matched settings, albeit at a proof-of-concept scale without large-scale instruction tuning, preference alignment, or practical decoding schemes. We introduce DIFFA-2, a practical diffusion-based LALM for general audio understanding. DIFFA-2 upgrades the speech encoder, employs dual semantic and acoustic adapters, and is trained with a four-stage curriculum that combines semantic and acoustic alignment, large-scale supervised 微调（在预训练模型基础上进行小幅调整）, and variance-reduced preference 优化（寻找最佳参数或解决方案的过程）, using only fully open-source corpora. Experiments on MMSU, MMAU, and MMAR show that DIFFA-2 consistently improves over DIFFA and is competitive to strong AR LALMs under practical training budgets, supporting diffusion-based modeling is a viable backbone for large-scale audio understanding. Our code is available at https://github.com/NKU-HLT/DIFFA.git.",
      "oneSentenceSummary": "【cs.SD】Jiaming Zhou等DIFFA-2，使用DIFFA-2 upgrades the speech en...，在cs.SD取得新进展。",
      "authors": [
        {
          "original": "Jiaming Zhou",
          "chinese": null
        },
        {
          "original": "Xuxin Cheng",
          "chinese": null
        },
        {
          "original": "Shiwan Zhao",
          "chinese": null
        },
        {
          "original": "Yuhang Jia",
          "chinese": null
        },
        {
          "original": "Cao Liu",
          "chinese": null
        },
        {
          "original": "Ke Zeng",
          "chinese": null
        },
        {
          "original": "Xunliang Cai",
          "chinese": null
        },
        {
          "original": "Yong Qin",
          "chinese": null
        }
      ],
      "published": "2026-01-30T16:44:23Z",
      "categories": [
        "cs.SD",
        "cs.CL"
      ],
      "primaryCategory": "cs.SD",
      "pdfUrl": "https://arxiv.org/pdf/2601.23161v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23161v1",
      "keyInfo": {
        "contributions": [
          "We introduce DIFFA-2, a practical diffusion-based LALM for general audio understanding"
        ],
        "methods": [
          "DIFFA-2 upgrades the speech encoder, employs dual semantic and acoustic adapters, and is trained with a four-stage curriculum that combines semantic and acoustic alignment, large-scale supervised 微调（在预训练模型基础上进行小幅调整）, and variance-reduced preference 优化（寻找最佳参数或解决方案的过程）, using only fully open-source corpora"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23159v1",
      "title": "Segment Any Events with Language",
      "originalTitle": "Segment Any Events with Language",
      "summary": "Scene understanding with free-form language has been widely explored within diverse modalities such as images, point clouds, and LiDAR. However, related studies on event sensors are scarce or narrowly centered on semantic-level understanding. We introduce SEAL, the first Semantic-aware Segment Any Events 框架（提供结构的基础代码库） that addresses Open-Vocabulary Event Instance Segmentation (OV-EIS). Given the ...",
      "plainSummary": "Scene understanding with free-form language has been widely explored within diverse modalities such as images, point clouds, and LiDAR. However, related studies on event sensors are scarce or narrowly centered on semantic-level understanding. We introduce SEAL, the first Semantic-aware Segment Any Events 框架（提供结构的基础代码库） that addresses Open-Vocabulary Event Instance Segmentation (OV-EIS). Given the visual prompt, our model presents a unified 框架（提供结构的基础代码库） to support both event segmentation and open-vocabulary mask classification at multiple levels of granularity, including instance-level and part-level. To enable thorough evaluation on OV-EIS, we curate four benchmarks that cover label granularity from coarse to fine class configurations and semantic granularity from instance-level to part-level understanding. 大量实验 show that our SEAL largely outperforms proposed baselines in terms of performance and inference speed with a parameter-高效的（速度快、资源消耗少） architecture. In the Appendix, we further present a simple variant of our SEAL achieving generic spatiotemporal OV-EIS that does not require any visual prompts from users in the inference. Check out our project page in https://0nandon.github.io/SEAL",
      "oneSentenceSummary": "【cs.CV】Seungjun Lee等Segment Any Events with Language，在cs.CV取得新进展。",
      "authors": [
        {
          "original": "Seungjun Lee",
          "chinese": null
        },
        {
          "original": "Gim Hee Lee",
          "chinese": null
        }
      ],
      "published": "2026-01-30T16:42:56Z",
      "categories": [
        "cs.CV"
      ],
      "primaryCategory": "cs.CV",
      "pdfUrl": "https://arxiv.org/pdf/2601.23159v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23159v1",
      "keyInfo": {
        "contributions": [
          "We introduce SEAL, the first Semantic-aware Segment Any Events 框架（提供结构的基础代码库） that addresses Open-Vocabulary Event Instance Segmentation (OV-EIS)",
          "Given the visual prompt, our model presents a unified 框架（提供结构的基础代码库） to support both event segmentation and open-vocabulary mask classification at multiple levels of granularity, including instance-level and part-level"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23129v1",
      "title": "Evaluating the Utility of Grounding Documents with Reference-Free LLM-based Metrics",
      "originalTitle": "Evaluating the Utility of Grounding Documents with Reference-Free LLM-based Metrics",
      "summary": "Retrieval Augmented Generation (RAG)'s success depends on the utility the LLM derives from the content used for grounding. Quantifying content utility does not have a definitive specification and existing metrics ignore model-specific capabilities and/or rely on costly annotations. In this paper, we propose Grounding Generation Utility (GroGU), a model-specific and reference-free metric that defin...",
      "plainSummary": "Retrieval Augmented Generation (RAG)'s success depends on the utility the LLM derives from the content used for grounding. Quantifying content utility does not have a definitive specification and existing metrics ignore model-specific capabilities and/or rely on costly annotations. In this paper, 我们提出 Grounding Generation Utility (GroGU), a model-specific and reference-free metric that defines utility as a function of the downstream LLM's generation confidence based on 熵（信息不确定性的度量）. Despite having no annotation requirements, GroGU is largely faithful in distinguishing ground-truth documents while capturing nuances ignored by LLM-agnostic metrics. We apply GroGU to train a query-rewriter for RAG by identifying high-utility preference data for Direct Preference 优化（寻找最佳参数或解决方案的过程）. Experiments show improvements by up to 18.2 points in Mean Reciprocal Rank and up to 9.4 points in answer 准确率（正确预测占总预测的比例）.",
      "oneSentenceSummary": "【cs.CL】Yilun Hua等Evaluating the Utility of Grounding Documents with Reference-Free LLM-based Metrics，使用In this paper, we propose Grou...，在cs.CL取得新进展。",
      "authors": [
        {
          "original": "Yilun Hua",
          "chinese": null
        },
        {
          "original": "Giuseppe Castellucci",
          "chinese": null
        },
        {
          "original": "Peter Schulam",
          "chinese": null
        },
        {
          "original": "Heba Elfardy",
          "chinese": null
        },
        {
          "original": "Kevin Small",
          "chinese": null
        }
      ],
      "published": "2026-01-30T16:17:07Z",
      "categories": [
        "cs.CL"
      ],
      "primaryCategory": "cs.CL",
      "pdfUrl": "https://arxiv.org/pdf/2601.23129v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23129v1",
      "keyInfo": {
        "contributions": [
          "In this paper, we propose Grounding Generation Utility (GroGU), a model-specific and reference-free metric that defines utility as a function of the downstream LLM's generation confidence based on 熵（信息不确定性的度量）"
        ],
        "methods": [
          "In this paper, we propose Grounding Generation Utility (GroGU), a model-specific and reference-free metric that defines utility as a function of the downstream LLM's generation confidence based on 熵（信息不确定性的度量）"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23107v1",
      "title": "FlowCalib: LiDAR-to-Vehicle Miscalibration Detection using Scene Flows",
      "originalTitle": "FlowCalib: LiDAR-to-Vehicle Miscalibration Detection using Scene Flows",
      "summary": "Accurate sensor-to-vehicle calibration is essential for safe autonomous driving. Angular misalignments of LiDAR sensors can lead to safety-critical issues during autonomous operation. However, current methods primarily focus on correcting sensor-to-sensor errors without considering the miscalibration of individual sensors that cause these errors in the first place. We introduce FlowCalib, the firs...",
      "plainSummary": "Accurate sensor-to-vehicle calibration is essential for safe autonomous driving. Angular misalignments of LiDAR sensors can lead to safety-critical issues during autonomous operation. However, current methods primarily focus on correcting sensor-to-sensor errors without considering the miscalibration of individual sensors that cause these errors in the first place. We introduce FlowCalib, the first 框架（提供结构的基础代码库） that detects LiDAR-to-vehicle miscalibration using motion cues from the scene flow of static objects. Our approach leverages the systematic bias induced by rotational misalignment in the flow field generated from sequential 3D point clouds, eliminating the need for additional sensors. The architecture integrates a neural scene flow 先验概率（观察到数据前的概率） for flow estimation and incorporates a dual-branch detection network that fuses learned global flow features with handcrafted geometric descriptors. These combined representations allow the system to perform two complementary binary classification tasks: a global binary decision indicating whether misalignment is present and separate, axis-specific binary decisions indicating whether each rotational axis is misaligned. Experiments on the nuScenes dataset demonstrate FlowCalib's ability to robustly detect miscalibration, establishing a 基准（用于比较性能的标准数据集或方法） for sensor-to-vehicle miscalibration detection.",
      "oneSentenceSummary": "【cs.CV】Ilir Tahiraj等FlowCalib，使用We introduce FlowCalib, the fi...，在cs.CV取得新进展。",
      "authors": [
        {
          "original": "Ilir Tahiraj",
          "chinese": null
        },
        {
          "original": "Peter Wittal",
          "chinese": null
        },
        {
          "original": "Markus Lienkamp",
          "chinese": null
        }
      ],
      "published": "2026-01-30T15:53:16Z",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "primaryCategory": "cs.CV",
      "pdfUrl": "https://arxiv.org/pdf/2601.23107v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23107v1",
      "keyInfo": {
        "contributions": [
          "We introduce FlowCalib, the first 框架（提供结构的基础代码库） that detects LiDAR-to-vehicle miscalibration using motion cues from the scene flow of static objects",
          "These combined representations allow the system to perform two complementary binary classification tasks: a global binary decision indicating whether misalignment is present and separate, axis-specific binary decisions indicating whether each rotational axis is misaligned"
        ],
        "methods": [
          "We introduce FlowCalib, the first 框架（提供结构的基础代码库） that detects LiDAR-to-vehicle miscalibration using motion cues from the scene flow of static objects",
          "Our approach leverages the systematic bias induced by rotational misalignment in the flow field generated from sequential 3D point clouds, eliminating the need for additional sensors"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23103v1",
      "title": "Vision-Language Controlled Deep Unfolding for Joint Medical Image Restoration and Segmentation",
      "originalTitle": "Vision-Language Controlled Deep Unfolding for Joint Medical Image Restoration and Segmentation",
      "summary": "We propose VL-DUN, a principled 框架（提供结构的基础代码库） for joint All-in-One Medical Image Restoration and Segmentation (AiOMIRS) that bridges the gap between low-level signal recovery and high-level semantic understanding. While standard pipelines treat these tasks in isolation, our core insight is that they are fundamentally synergistic: restoration provides clean anatomical structures to improve segment...",
      "plainSummary": "我们提出 VL-DUN, a principled 框架（提供结构的基础代码库） for joint All-in-One Medical Image Restoration and Segmentation (AiOMIRS) that bridges the gap between low-level signal recovery and high-level semantic understanding. While standard pipelines treat these tasks in isolation, our core insight is that they are fundamentally synergistic: restoration provides clean anatomical structures to improve segmentation, while semantic priors regularize the restoration process. VL-DUN resolves the sub-optimality of sequential processing through two primary innovations. (1) We formulate AiOMIRS as a unified 优化（寻找最佳参数或解决方案的过程） problem, deriving an 可解释的（能够解释其决策过程） joint unfolding mechanism where restoration and segmentation are mathematically coupled for mutual refinement. (2) We introduce a frequency-aware Mamba mechanism to capture long-range dependencies for global segmentation while preserving the high-frequency textures necessary for restoration. This allows for 高效的（速度快、资源消耗少） global context modeling with linear complexity, effectively mitigating the spectral bias of standard architectures. As a pioneering work in the AiOMIRS task, VL-DUN establishes a new 最先进（当前最好的、领先的方法） across multi-modal benchmarks, improving PSNR by 0.92 dB and the Dice coefficient by 9.76\\%. Our results demonstrate that joint collaborative learning offers a superior, more 鲁棒的（对噪声和扰动不敏感） solution for complex clinical workflows compared to isolated task processing. The codes are provided in https://github.com/cipi666/VLDUN.",
      "oneSentenceSummary": "【eess.IV】Ping Chen等Vision-Language Controlled Deep Unfolding for Joint Medical Image Restoration and Segmentation，在eess.IV取得新进展。",
      "authors": [
        {
          "original": "Ping Chen",
          "chinese": null
        },
        {
          "original": "Zicheng Huang",
          "chinese": null
        },
        {
          "original": "Xiangming Wang",
          "chinese": null
        },
        {
          "original": "Yungeng Liu",
          "chinese": null
        },
        {
          "original": "Bingyu Liang",
          "chinese": null
        },
        {
          "original": "Haijin Zeng",
          "chinese": null
        },
        {
          "original": "Yongyong Chen",
          "chinese": null
        }
      ],
      "published": "2026-01-30T15:48:35Z",
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "primaryCategory": "eess.IV",
      "pdfUrl": "https://arxiv.org/pdf/2601.23103v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23103v1",
      "keyInfo": {
        "contributions": [
          "We propose VL-DUN, a principled 框架（提供结构的基础代码库） for joint All-in-One Medical Image Restoration and Segmentation (AiOMIRS) that bridges the gap between low-level signal recovery and high-level semantic understanding",
          "(2) We introduce a frequency-aware Mamba mechanism to capture long-range dependencies for global segmentation while preserving the high-frequency textures necessary for restoration"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23102v1",
      "title": "Rethinking Transferable Adversarial Attacks on Point Clouds from a Compact Subspace Perspective",
      "originalTitle": "Rethinking Transferable Adversarial Attacks on Point Clouds from a Compact Subspace Perspective",
      "summary": "Transferable adversarial attacks on point clouds remain challenging, as existing methods often rely on model-specific gradients or heuristics that limit generalization to unseen architectures. In this paper, we rethink adversarial transferability from a compact subspace perspective and propose CoSA, a transferable attack 框架（提供结构的基础代码库） that operates within a shared low-dimensional semantic space. ...",
      "plainSummary": "Transferable adversarial attacks on point clouds remain challenging, as existing methods often rely on model-specific gradients or heuristics that limit generalization to unseen architectures. In this paper, we rethink adversarial transferability from a compact subspace perspective and propose CoSA, a transferable attack 框架（提供结构的基础代码库） that operates within a shared low-dimensional semantic space. Specifically, each point cloud is represented as a compact combination of class-specific prototypes that capture shared semantic structure, while adversarial perturbations are optimized within a low-rank subspace to induce coherent and architecture-agnostic variations. This design suppresses model-dependent noise and constrains perturbations to semantically meaningful directions, thereby improving cross-model transferability without relying on surrogate-specific artifacts. 大量实验 on multiple datasets and network architectures demonstrate that CoSA consistently outperforms 最先进（当前最好的、领先的方法） transferable attacks, while maintaining competitive imperceptibility and robustness under common defense strategies. Codes will be made public upon paper acceptance.",
      "oneSentenceSummary": "【cs.CV】Keke Tang等Rethinking Transferable Adversarial Attacks on Point Clouds from a Compact Subspace Perspective，在cs.CV取得新进展。",
      "authors": [
        {
          "original": "Keke Tang",
          "chinese": null
        },
        {
          "original": "Xianheng Liu",
          "chinese": null
        },
        {
          "original": "Weilong Peng",
          "chinese": null
        },
        {
          "original": "Xiaofei Wang",
          "chinese": null
        },
        {
          "original": "Daizong Liu",
          "chinese": null
        },
        {
          "original": "Peican Zhu",
          "chinese": null
        },
        {
          "original": "Can Lu",
          "chinese": null
        },
        {
          "original": "Zhihong Tian",
          "chinese": null
        }
      ],
      "published": "2026-01-30T15:48:11Z",
      "categories": [
        "cs.CV"
      ],
      "primaryCategory": "cs.CV",
      "pdfUrl": "https://arxiv.org/pdf/2601.23102v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23102v1",
      "keyInfo": {
        "contributions": [
          "In this paper, we rethink adversarial transferability from a compact subspace perspective and propose CoSA, a transferable attack 框架（提供结构的基础代码库） that operates within a shared low-dimensional semantic space",
          "Specifically, each point cloud is represented as a compact combination of class-specific prototypes that capture shared semantic structure, while adversarial perturbations are optimized within a low-rank subspace to induce coherent and architecture-agnostic variations"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23094v1",
      "title": "Safer Policy Compliance with Dynamic Epistemic Fallback",
      "originalTitle": "Safer Policy Compliance with Dynamic Epistemic Fallback",
      "summary": "Humans develop a series of cognitive defenses, known as epistemic vigilance, to combat risks of deception and misinformation from everyday interactions. Developing safeguards for LLMs inspired by this mechanism might be particularly helpful for their application in high-stakes tasks such as automating compliance with data privacy laws. In this paper, we introduce Dynamic Epistemic Fallback (DEF), ...",
      "plainSummary": "Humans develop a series of cognitive defenses, known as epistemic vigilance, to combat risks of deception and misinformation from everyday interactions. Developing safeguards for LLMs inspired by this mechanism might be particularly helpful for their application in high-stakes tasks such as automating compliance with data privacy laws. In this paper, we introduce Dynamic Epistemic Fallback (DEF), a dynamic safety protocol for improving an LLM's inference-time defenses against deceptive attacks that make use of maliciously perturbed policy texts. Through various levels of one-sentence textual cues, DEF nudges LLMs to flag inconsistencies, refuse compliance, and fallback to their parametric knowledge upon encountering perturbed policy texts. Using globally recognized legal policies such as HIPAA and GDPR, our 经验性的（基于实验和观察的） evaluations report that DEF effectively improves the capability of frontier LLMs to detect and refuse perturbed versions of policies, with DeepSeek-R1 achieving a 100% detection rate in one setting. This work encourages further efforts to develop cognitively inspired defenses to improve LLM robustness against forms of harm and deception that exploit legal artifacts.",
      "oneSentenceSummary": "【cs.CL】Joseph Marvin Imperial等Safer Policy Compliance with Dynamic Epistemic Fallback，使用Using globally recognized lega...，在cs.CL取得新进展。",
      "authors": [
        {
          "original": "Joseph Marvin Imperial",
          "chinese": null
        },
        {
          "original": "Harish Tayyar Madabushi",
          "chinese": null
        }
      ],
      "published": "2026-01-30T15:40:49Z",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "primaryCategory": "cs.CL",
      "pdfUrl": "https://arxiv.org/pdf/2601.23094v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23094v1",
      "keyInfo": {
        "contributions": [
          "Humans develop a series of cognitive defenses, known as epistemic vigilance, to combat risks of deception and misinformation from everyday interactions",
          "Developing safeguards for LLMs inspired by this mechanism might be particularly helpful for their application in high-stakes tasks such as automating compliance with data privacy laws"
        ],
        "methods": [
          "Using globally recognized legal policies such as HIPAA and GDPR, our 经验性的（基于实验和观察的） evaluations report that DEF effectively improves the capability of frontier LLMs to detect and refuse perturbed versions of policies, with DeepSeek-R1 achieving a 100% detection rate in one setting"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23087v1",
      "title": "Temporally Coherent Imitation Learning via Latent Action Flow Matching for Robotic Manipulation",
      "originalTitle": "Temporally Coherent Imitation Learning via Latent Action Flow Matching for Robotic Manipulation",
      "summary": "Learning long-horizon robotic manipulation requires jointly achieving expressive behavior modeling, real-time inference, and stable execution, which remains challenging for existing generative policies. Diffusion-based approaches provide strong modeling capacity but typically incur high inference latency, while flow matching enables fast one-step generation yet often leads to unstable execution wh...",
      "plainSummary": "Learning long-horizon robotic manipulation requires jointly achieving expressive behavior modeling, real-time inference, and stable execution, which remains challenging for existing generative policies. Diffusion-based approaches provide strong modeling capacity but typically incur high inference latency, while flow matching enables fast one-step generation yet often leads to unstable execution when applied directly in the raw action space. 我们提出 LG-Flow Policy, a trajectory-level imitation learning 框架（提供结构的基础代码库） that performs flow matching in a continuous latent action space. By encoding action sequences into temporally regularized latent trajectories and learning an explicit latent-space flow, the proposed approach decouples global motion structure from low-level control noise, resulting in smooth and reliable long-horizon execution. LG-Flow Policy further incorporates geometry-aware point cloud conditioning and execution-time multimodal modulation, with visual cues evaluated as a representative modality in real-world settings. Experimental results in simulation and on physical robot platforms demonstrate that LG-Flow Policy achieves near single-step inference, substantially improves trajectory smoothness and task success over flow-based baselines operating in the raw action space, and remains significantly more 高效的（速度快、资源消耗少） than diffusion-based policies.",
      "oneSentenceSummary": "【cs.RO】Wu Songwei等Temporally Coherent Imitation Learning via Latent Action Flow Matching for Robotic Manipulation，在cs.RO取得新进展。",
      "authors": [
        {
          "original": "Wu Songwei",
          "chinese": null
        },
        {
          "original": "Jiang Zhiduo",
          "chinese": null
        },
        {
          "original": "Xie Guanghu",
          "chinese": null
        },
        {
          "original": "Liu Yang",
          "chinese": null
        },
        {
          "original": "Liu Hong",
          "chinese": null
        }
      ],
      "published": "2026-01-30T15:36:43Z",
      "categories": [
        "cs.RO"
      ],
      "primaryCategory": "cs.RO",
      "pdfUrl": "https://arxiv.org/pdf/2601.23087v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23087v1",
      "keyInfo": {
        "contributions": [
          "We propose LG-Flow Policy, a trajectory-level imitation learning 框架（提供结构的基础代码库） that performs flow matching in a continuous latent action space",
          "By encoding action sequences into temporally regularized latent trajectories and learning an explicit latent-space flow, the proposed approach decouples global motion structure from low-level control noise, resulting in smooth and reliable long-horizon execution"
        ],
        "methods": [],
        "applications": [
          "Diffusion-based approaches provide strong modeling capacity but typically incur high inference latency, while flow matching enables fast one-step generation yet often leads to unstable execution when applied directly in the raw action space"
        ]
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23081v1",
      "title": "Character as a Latent Variable in Large Language Models: A Mechanistic Account of Emergent Misalignment and Conditional Safety Failures",
      "originalTitle": "Character as a Latent Variable in Large Language Models: A Mechanistic Account of Emergent Misalignment and Conditional Safety Failures",
      "summary": "Emergent Misalignment refers to a failure mode in which 微调（在预训练模型基础上进行小幅调整） large language models (LLMs) on narrowly scoped data induces broadly misaligned behavior. 先验概率（观察到数据前的概率） explanations mainly attribute this phenomenon to the generalization of erroneous or unsafe content. In this work, we show that this view is incomplete. Across multiple domains and model families, we find that 微调（在预训练模型...",
      "plainSummary": "Emergent Misalignment refers to a failure mode in which 微调（在预训练模型基础上进行小幅调整） large language models (LLMs) on narrowly scoped data induces broadly misaligned behavior. 先验概率（观察到数据前的概率） explanations mainly attribute this phenomenon to the generalization of erroneous or unsafe content. In this work, we show that this view is incomplete. Across multiple domains and model families, we find that 微调（在预训练模型基础上进行小幅调整） models on data exhibiting specific character-level dispositions induces substantially stronger and more transferable misalignment than incorrect-advice 微调（在预训练模型基础上进行小幅调整）, while largely preserving general capabilities. This indicates that emergent misalignment arises from stable shifts in model behavior rather than from capability degradation or corrupted knowledge. We further show that such behavioral dispositions can be conditionally activated by both training-time triggers and inference-time persona-aligned prompts, revealing shared structure across emergent misalignment, backdoor activation, and jailbreak susceptibility. Overall, our results identify character formation as a central and underexplored alignment risk, suggesting that 鲁棒的（对噪声和扰动不敏感） alignment must address behavioral dispositions rather than isolated errors or prompt-level defenses.",
      "oneSentenceSummary": "【cs.CL】Yanghao Su等Character as a Latent Variable in Large Language Models，在cs.CL取得新进展。",
      "authors": [
        {
          "original": "Yanghao Su",
          "chinese": null
        },
        {
          "original": "Wenbo Zhou",
          "chinese": null
        },
        {
          "original": "Tianwei Zhang",
          "chinese": null
        },
        {
          "original": "Qiu Han",
          "chinese": null
        },
        {
          "original": "Weiming Zhang",
          "chinese": null
        },
        {
          "original": "Nenghai Yu",
          "chinese": null
        },
        {
          "original": "Jie Zhang",
          "chinese": null
        }
      ],
      "published": "2026-01-30T15:28:42Z",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primaryCategory": "cs.CL",
      "pdfUrl": "https://arxiv.org/pdf/2601.23081v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23081v1",
      "keyInfo": {
        "contributions": [],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23080v1",
      "title": "鲁棒的（对噪声和扰动不敏感） and Generalized Humanoid Motion Tracking",
      "originalTitle": "Robust and Generalized Humanoid Motion Tracking",
      "summary": "Learning a general humanoid whole-body controller is challenging because practical reference motions can exhibit noise and inconsistencies after being transferred to the robot domain, and local defects may be amplified by closed-loop execution, causing drift or failure in highly dynamic and contact-rich behaviors. We propose a dynamics-conditioned command aggregation 框架（提供结构的基础代码库） that uses a cau...",
      "plainSummary": "Learning a general humanoid whole-body controller is challenging because practical reference motions can exhibit noise and inconsistencies after being transferred to the robot domain, and local defects may be amplified by closed-loop execution, causing drift or failure in highly dynamic and contact-rich behaviors. 我们提出 a dynamics-conditioned command aggregation 框架（提供结构的基础代码库） that uses a causal temporal encoder to summarize recent proprioception and a multi-head cross-attention command encoder to selectively aggregate a context window based on the current dynamics. We further integrate a fall recovery curriculum with random unstable initialization and an annealed upward assistance force to improve robustness and disturbance rejection. The resulting policy requires only about 3.5 hours of motion data and supports single-stage end-to-end training without distillation. The proposed method is evaluated under diverse reference inputs and challenging motion regimes, demonstrating zero-shot transfer to unseen motions as well as 鲁棒的（对噪声和扰动不敏感） sim-to-real transfer on a physical humanoid robot.",
      "oneSentenceSummary": "【cs.RO】Yubiao Ma等Robust and Generalized Humanoid Motion Tracking，使用Learning a general humanoid wh...，在cs.RO取得新进展。",
      "authors": [
        {
          "original": "Yubiao Ma",
          "chinese": null
        },
        {
          "original": "Han Yu",
          "chinese": null
        },
        {
          "original": "Jiayin Xie",
          "chinese": null
        },
        {
          "original": "Changtai Lv",
          "chinese": null
        },
        {
          "original": "Qiang Luo",
          "chinese": null
        },
        {
          "original": "Chi Zhang",
          "chinese": null
        },
        {
          "original": "Yunpeng Yin",
          "chinese": null
        },
        {
          "original": "Boyang Xing",
          "chinese": null
        },
        {
          "original": "Xuemei Ren",
          "chinese": null
        },
        {
          "original": "Dongdong Zheng",
          "chinese": null
        }
      ],
      "published": "2026-01-30T15:27:43Z",
      "categories": [
        "cs.RO"
      ],
      "primaryCategory": "cs.RO",
      "pdfUrl": "https://arxiv.org/pdf/2601.23080v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23080v1",
      "keyInfo": {
        "contributions": [
          "We propose a dynamics-conditioned command aggregation 框架（提供结构的基础代码库） that uses a causal temporal encoder to summarize recent proprioception and a multi-head cross-attention command encoder to selectively aggregate a context window based on the current dynamics",
          "The proposed method is evaluated under diverse reference inputs and challenging motion regimes, demonstrating zero-shot transfer to unseen motions as well as 鲁棒的（对噪声和扰动不敏感） sim-to-real transfer on a physical humanoid robot"
        ],
        "methods": [
          "Learning a general humanoid whole-body controller is challenging because practical reference motions can exhibit noise and inconsistencies after being transferred to the robot domain, and local defects may be amplified by closed-loop execution, causing drift or failure in highly dynamic and contact-rich behaviors",
          "We propose a dynamics-conditioned command aggregation 框架（提供结构的基础代码库） that uses a causal temporal encoder to summarize recent proprioception and a multi-head cross-attention command encoder to selectively aggregate a context window based on the current dynamics"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23075v1",
      "title": "RN-D: Discretized Categorical Actors with Regularized Networks for On-Policy 强化学习（通过试错学习最佳策略的机器学习方法）",
      "originalTitle": "RN-D: Discretized Categorical Actors with Regularized Networks for On-Policy Reinforcement Learning",
      "summary": "On-policy deep 强化学习（通过试错学习最佳策略的机器学习方法） remains a dominant paradigm for continuous control, yet standard implementations rely on Gaussian actors and relatively shallow MLP policies, often leading to brittle 优化（寻找最佳参数或解决方案的过程） when gradients are noisy and policy updates must be conservative. In this paper, we revisit policy representation as a first-class design choice for on-policy 优化（寻找最佳参数或解决方案的过...",
      "plainSummary": "On-policy deep 强化学习（通过试错学习最佳策略的机器学习方法） remains a dominant paradigm for continuous control, yet standard implementations rely on Gaussian actors and relatively shallow MLP policies, often leading to brittle 优化（寻找最佳参数或解决方案的过程） when gradients are noisy and policy updates must be conservative. In this paper, we revisit policy representation as a first-class design choice for on-policy 优化（寻找最佳参数或解决方案的过程）. We study discretized categorical actors that represent each action dimension with a distribution over bins, yielding a policy objective that resembles a 交叉熵（比较两个概率分布的差异） loss. Building on architectural advances from 监督学习（使用标注数据训练模型）, we further propose regularized actor networks, while keeping critic design fixed. Our results show that simply replacing the standard actor network with our discretized regularized actor yields consistent gains and achieve the 最先进（当前最好的、领先的方法） performance across diverse continuous-control benchmarks.",
      "oneSentenceSummary": "【cs.LG】Yuexin Bian等RN-D，在cs.LG取得新进展。",
      "authors": [
        {
          "original": "Yuexin Bian",
          "chinese": null
        },
        {
          "original": "Jie Feng",
          "chinese": null
        },
        {
          "original": "Tao Wang",
          "chinese": null
        },
        {
          "original": "Yijiang Li",
          "chinese": null
        },
        {
          "original": "Sicun Gao",
          "chinese": null
        },
        {
          "original": "Yuanyuan Shi",
          "chinese": null
        }
      ],
      "published": "2026-01-30T15:24:34Z",
      "categories": [
        "cs.LG",
        "cs.RO"
      ],
      "primaryCategory": "cs.LG",
      "pdfUrl": "https://arxiv.org/pdf/2601.23075v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23075v1",
      "keyInfo": {
        "contributions": [
          "In this paper, we revisit policy representation as a first-class design choice for on-policy 优化（寻找最佳参数或解决方案的过程）",
          "We study discretized categorical actors that represent each action dimension with a distribution over bins, yielding a policy objective that resembles a 交叉熵（比较两个概率分布的差异） loss"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23065v1",
      "title": "EAG-PT: Emission-Aware Gaussians and Path Tracing for Indoor Scene Reconstruction and Editing",
      "originalTitle": "EAG-PT: Emission-Aware Gaussians and Path Tracing for Indoor Scene Reconstruction and Editing",
      "summary": "Recent reconstruction methods based on radiance field such as NeRF and 3DGS reproduce indoor scenes with high visual fidelity, but break down under scene editing due to baked illumination and the lack of explicit light transport. In contrast, physically based inverse rendering relies on mesh representations and path tracing, which enforce correct light transport but place strong requirements on ge...",
      "plainSummary": "Recent reconstruction methods based on radiance field such as NeRF and 3DGS reproduce indoor scenes with high visual fidelity, but break down under scene editing due to baked illumination and the lack of explicit light transport. In contrast, physically based inverse rendering relies on mesh representations and path tracing, which enforce correct light transport but place strong requirements on geometric fidelity, becoming a practical bottleneck for real indoor scenes. In this work, 我们提出 Emission-Aware Gaussians and Path Tracing (EAG-PT), aiming for physically based light transport with a unified 2D Gaussian representation. Our design is based on three cores: (1) using 2D Gaussians as a unified scene representation and transport-friendly geometry proxy that avoids reconstructed mesh, (2) explicitly separating emissive and non-emissive components during reconstruction for further scene editing, and (3) decoupling reconstruction from final rendering by using 高效的（速度快、资源消耗少） single-bounce 优化（寻找最佳参数或解决方案的过程） and high-quality multi-bounce path tracing after scene editing. Experiments on synthetic and real indoor scenes show that EAG-PT produces more natural and physically consistent renders after editing than radiant scene reconstructions, while preserving finer geometric detail and avoiding mesh-induced artifacts compared to mesh-based inverse path tracing. These results suggest promising directions for future use in interior design, XR content creation, and embodied AI.",
      "oneSentenceSummary": "【cs.GR】Xijie Yang等EAG-PT，使用Recent reconstruction methods ...，在cs.GR取得新进展。",
      "authors": [
        {
          "original": "Xijie Yang",
          "chinese": null
        },
        {
          "original": "Mulin Yu",
          "chinese": null
        },
        {
          "original": "Changjian Jiang",
          "chinese": null
        },
        {
          "original": "Kerui Ren",
          "chinese": null
        },
        {
          "original": "Tao Lu",
          "chinese": null
        },
        {
          "original": "Jiangmiao Pang",
          "chinese": null
        },
        {
          "original": "Dahua Lin",
          "chinese": null
        },
        {
          "original": "Bo Dai",
          "chinese": null
        },
        {
          "original": "Linning Xu",
          "chinese": null
        }
      ],
      "published": "2026-01-30T15:16:37Z",
      "categories": [
        "cs.GR",
        "cs.CV"
      ],
      "primaryCategory": "cs.GR",
      "pdfUrl": "https://arxiv.org/pdf/2601.23065v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23065v1",
      "keyInfo": {
        "contributions": [
          "In contrast, physically based inverse rendering relies on mesh representations and path tracing, which enforce correct light transport but place strong requirements on geometric fidelity, becoming a practical bottleneck for real indoor scenes",
          "In this work, we propose Emission-Aware Gaussians and Path Tracing (EAG-PT), aiming for physically based light transport with a unified 2D Gaussian representation"
        ],
        "methods": [
          "Recent reconstruction methods based on radiance field such as NeRF and 3DGS reproduce indoor scenes with high visual fidelity, but break down under scene editing due to baked illumination and the lack of explicit light transport",
          "Our design is based on three cores: (1) using 2D Gaussians as a unified scene representation and transport-friendly geometry proxy that avoids reconstructed mesh, (2) explicitly separating emissive and non-emissive components during reconstruction for further scene editing, and (3) decoupling reconstruction from final rendering by using 高效的（速度快、资源消耗少） single-bounce 优化（寻找最佳参数或解决方案的过程） and high-quality multi-bounce path tracing after scene editing"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23064v1",
      "title": "HierLoc: Hyperbolic Entity Embeddings for Hierarchical Visual Geolocation",
      "originalTitle": "HierLoc: Hyperbolic Entity Embeddings for Hierarchical Visual Geolocation",
      "summary": "Visual geolocalization, the task of predicting where an image was taken, remains challenging due to global scale, visual ambiguity, and the inherently hierarchical structure of geography. Existing paradigms rely on either large-scale retrieval, which requires storing a large number of image embeddings, grid-based classifiers that ignore geographic continuity, or generative models that diffuse over...",
      "plainSummary": "Visual geolocalization, the task of predicting where an image was taken, remains challenging due to global scale, visual ambiguity, and the inherently hierarchical structure of geography. Existing paradigms rely on either large-scale retrieval, which requires storing a large number of image embeddings, grid-based classifiers that ignore geographic continuity, or generative models that diffuse over space but struggle with fine detail. We introduce an entity-centric formulation of geolocation that replaces image-to-image retrieval with a compact hierarchy of geographic entities embedded in Hyperbolic space. Images are aligned directly to country, region, subregion, and city entities through Geo-Weighted Hyperbolic contrastive learning by directly incorporating haversine distance into the contrastive objective. This hierarchical design enables 可解释的（能够解释其决策过程） predictions and 高效的（速度快、资源消耗少） inference with 240k entity embeddings instead of over 5 million image embeddings on the OSV5M 基准（用于比较性能的标准数据集或方法）, on which 我们的方法 establishes a new 最先进（当前最好的、领先的方法） performance. Compared to the current methods in the literature, it reduces mean geodesic error by 19.5\\%, while improving the fine-grained subregion 准确率（正确预测占总预测的比例） by 43%. These results demonstrate that geometry-aware hierarchical embeddings provide a 可扩展的（能够处理更大规模数据） and conceptually new alternative for global image geolocation.",
      "oneSentenceSummary": "【cs.CV】Hari Krishna Gadi等HierLoc，在cs.CV取得新进展。",
      "authors": [
        {
          "original": "Hari Krishna Gadi",
          "chinese": null
        },
        {
          "original": "Daniel Matos",
          "chinese": null
        },
        {
          "original": "Hongyi Luo",
          "chinese": null
        },
        {
          "original": "Lu Liu",
          "chinese": null
        },
        {
          "original": "Yongliang Wang",
          "chinese": null
        },
        {
          "original": "Yanfeng Zhang",
          "chinese": null
        },
        {
          "original": "Liqiu Meng",
          "chinese": null
        }
      ],
      "published": "2026-01-30T15:16:07Z",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primaryCategory": "cs.CV",
      "pdfUrl": "https://arxiv.org/pdf/2601.23064v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23064v1",
      "keyInfo": {
        "contributions": [
          "We introduce an entity-centric formulation of geolocation that replaces image-to-image retrieval with a compact hierarchy of geographic entities embedded in Hyperbolic space",
          "This hierarchical design enables 可解释的（能够解释其决策过程） predictions and 高效的（速度快、资源消耗少） inference with 240k entity embeddings instead of over 5 million image embeddings on the OSV5M 基准（用于比较性能的标准数据集或方法）, on which our method establishes a new 最先进（当前最好的、领先的方法） performance"
        ],
        "methods": [],
        "applications": [
          "This hierarchical design enables 可解释的（能够解释其决策过程） predictions and 高效的（速度快、资源消耗少） inference with 240k entity embeddings instead of over 5 million image embeddings on the OSV5M 基准（用于比较性能的标准数据集或方法）, on which our method establishes a new 最先进（当前最好的、领先的方法） performance"
        ]
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23041v1",
      "title": "One-shot Optimized Steering Vector for Hallucination Mitigation for VLMs",
      "originalTitle": "One-shot Optimized Steering Vector for Hallucination Mitigation for VLMs",
      "summary": "Vision Language Models (VLMs) achieve strong performance on multimodal tasks but still suffer from hallucination and safety-related failures that persist even at scale. Steering offers a lightweight technique to improve model performance. However, steering, whether input-dependent or input-independent, achieves a meaningful trade-off between efficiency and effectiveness. In this work, we observe t...",
      "plainSummary": "Vision Language Models (VLMs) achieve strong performance on multimodal tasks but still suffer from hallucination and safety-related failures that persist even at scale. Steering offers a lightweight technique to improve model performance. However, steering, whether input-dependent or input-independent, achieves a meaningful trade-off between efficiency and effectiveness. In this work, we observe that steering vectors can generalize across inputs when tasks share aligned semantic intent. Based on this insight, 我们提出 \\textbf{OSGA} (\\textbf{O}ne-shot \\textbf{S}teering with \\textbf{G}enerative \\textbf{A}nchor), an input-independent 框架（提供结构的基础代码库） that improves model performance with a single 优化（寻找最佳参数或解决方案的过程） instance. OSGA first selects an informative sample via a variance-based data selection strategy and learns a single steering vector with a contrastive objective with generative anchor 正则化（防止过拟合的技术）. The resulting vector can be universally applied at a certain layer during inference time without modifying model parameters. Experiments across multiple benchmarks show that a single OSGA-optimized steering vector consistently improves hallucination mitigation and safety enhancement with negligible overhead, highlighting one-shot steering as a practical and 可扩展的（能够处理更大规模数据） solution for reliable VLMs.",
      "oneSentenceSummary": "【cs.CV】Youxu Shi等One-shot Optimized Steering Vector for Hallucination Mitigation for VLMs，使用Based on this insight, we prop...，在cs.CV取得新进展。",
      "authors": [
        {
          "original": "Youxu Shi",
          "chinese": null
        },
        {
          "original": "Suorong Yang",
          "chinese": null
        },
        {
          "original": "Dong Liu",
          "chinese": null
        }
      ],
      "published": "2026-01-30T14:47:59Z",
      "categories": [
        "cs.CV"
      ],
      "primaryCategory": "cs.CV",
      "pdfUrl": "https://arxiv.org/pdf/2601.23041v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23041v1",
      "keyInfo": {
        "contributions": [
          "Based on this insight, we propose \\textbf{OSGA} (\\textbf{O}ne-shot \\textbf{S}teering with \\textbf{G}enerative \\textbf{A}nchor), an input-independent 框架（提供结构的基础代码库） that improves model performance with a single 优化（寻找最佳参数或解决方案的过程） instance"
        ],
        "methods": [
          "Based on this insight, we propose \\textbf{OSGA} (\\textbf{O}ne-shot \\textbf{S}teering with \\textbf{G}enerative \\textbf{A}nchor), an input-independent 框架（提供结构的基础代码库） that improves model performance with a single 优化（寻找最佳参数或解决方案的过程） instance"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23038v1",
      "title": "MOSAIC: Modular 可扩展的（能够处理更大规模数据） Autonomy for Intelligent Coordination of Heterogeneous Robotic Teams",
      "originalTitle": "MOSAIC: Modular Scalable Autonomy for Intelligent Coordination of Heterogeneous Robotic Teams",
      "summary": "Mobile robots have become indispensable for exploring hostile environments, such as in space or disaster relief scenarios, but often remain limited to teleoperation by a human operator. This restricts the deployment scale and requires near-continuous low-latency communication between the operator and the robot. We present MOSAIC: a 可扩展的（能够处理更大规模数据） autonomy 框架（提供结构的基础代码库） for multi-robot scientifi...",
      "plainSummary": "Mobile robots have become indispensable for exploring hostile environments, such as in space or disaster relief scenarios, but often remain limited to teleoperation by a human operator. This restricts the deployment scale and requires near-continuous low-latency communication between the operator and the robot. We present MOSAIC: a 可扩展的（能够处理更大规模数据） autonomy 框架（提供结构的基础代码库） for multi-robot scientific exploration using a unified mission abstraction based on Points of Interest (POIs) and multiple layers of autonomy, enabling supervision by a single operator. The 框架（提供结构的基础代码库） dynamically allocates exploration and measurement tasks based on each robot's capabilities, leveraging team-level redundancy and specialization to enable continuous operation. We validated the 框架（提供结构的基础代码库） in a space-analog field experiment emulating a lunar prospecting scenario, involving a heterogeneous team of five robots and a single operator. Despite the complete failure of one robot during the mission, the team completed 82.3% of assigned tasks at an Autonomy Ratio of 86%, while the operator workload remained at only 78.2%. These results demonstrate that the proposed 框架（提供结构的基础代码库） enables 鲁棒的（对噪声和扰动不敏感）, 可扩展的（能够处理更大规模数据） multi-robot scientific exploration with limited operator intervention. We further derive practical lessons learned in robot interoperability, networking architecture, team composition, and operator workload management to inform future multi-robot exploration missions.",
      "oneSentenceSummary": "【cs.RO】David Oberacker等MOSAIC，使用We present MOSAIC: a 可扩展的（能够处理...，在cs.RO取得新进展。",
      "authors": [
        {
          "original": "David Oberacker",
          "chinese": null
        },
        {
          "original": "Julia Richer",
          "chinese": null
        },
        {
          "original": "Philip Arm",
          "chinese": null
        },
        {
          "original": "Marvin Grosse Besselmann",
          "chinese": null
        },
        {
          "original": "Lennart Puck",
          "chinese": null
        },
        {
          "original": "William Talbot",
          "chinese": null
        },
        {
          "original": "Maximilian Schik",
          "chinese": null
        },
        {
          "original": "Sabine Bellmann",
          "chinese": null
        },
        {
          "original": "Tristan Schnell",
          "chinese": null
        },
        {
          "original": "Hendrik Kolvenbach",
          "chinese": null
        },
        {
          "original": "Rüdiger Dillmann",
          "chinese": null
        },
        {
          "original": "Marco Hutter",
          "chinese": null
        },
        {
          "original": "Arne Roennau",
          "chinese": null
        }
      ],
      "published": "2026-01-30T14:46:15Z",
      "categories": [
        "cs.RO"
      ],
      "primaryCategory": "cs.RO",
      "pdfUrl": "https://arxiv.org/pdf/2601.23038v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23038v1",
      "keyInfo": {
        "contributions": [
          "We present MOSAIC: a 可扩展的（能够处理更大规模数据） autonomy 框架（提供结构的基础代码库） for multi-robot scientific exploration using a unified mission abstraction based on Points of Interest (POIs) and multiple layers of autonomy, enabling supervision by a single operator",
          "These results demonstrate that the proposed 框架（提供结构的基础代码库） enables 鲁棒的（对噪声和扰动不敏感）, 可扩展的（能够处理更大规模数据） multi-robot scientific exploration with limited operator intervention"
        ],
        "methods": [
          "We present MOSAIC: a 可扩展的（能够处理更大规模数据） autonomy 框架（提供结构的基础代码库） for multi-robot scientific exploration using a unified mission abstraction based on Points of Interest (POIs) and multiple layers of autonomy, enabling supervision by a single operator",
          "The 框架（提供结构的基础代码库） dynamically allocates exploration and measurement tasks based on each robot's capabilities, leveraging team-level redundancy and specialization to enable continuous operation"
        ],
        "applications": [
          "These results demonstrate that the proposed 框架（提供结构的基础代码库） enables 鲁棒的（对噪声和扰动不敏感）, 可扩展的（能够处理更大规模数据） multi-robot scientific exploration with limited operator intervention"
        ]
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23037v1",
      "title": "Scale Equivariance 正则化（防止过拟合的技术） and Feature Lifting in High Dynamic Range Modulo Imaging",
      "originalTitle": "Scale Equivariance Regularization and Feature Lifting in High Dynamic Range Modulo Imaging",
      "summary": "Modulo imaging enables high dynamic range (HDR) acquisition by cyclically wrapping saturated intensities, but accurate reconstruction remains challenging due to ambiguities between natural image edges and artificial wrap discontinuities. This work proposes a learning-based HDR restoration 框架（提供结构的基础代码库） that incorporates two key strategies: (i) a scale-equivariant 正则化（防止过拟合的技术） that enforces consi...",
      "plainSummary": "Modulo imaging enables high dynamic range (HDR) acquisition by cyclically wrapping saturated intensities, but accurate reconstruction remains challenging due to ambiguities between natural image edges and artificial wrap discontinuities. This work proposes a learning-based HDR restoration 框架（提供结构的基础代码库） that incorporates two key strategies: (i) a scale-equivariant 正则化（防止过拟合的技术） that enforces consistency under exposure variations, and (ii) a feature lifting input design combining the raw modulo image, wrapped finite differences, and a closed-form initialization. Together, these components enhance the network's ability to distinguish true structure from wrapping artifacts, yielding 最先进（当前最好的、领先的方法） performance across perceptual and linear HDR quality metrics.",
      "oneSentenceSummary": "【eess.IV】Brayan Monroy等Scale Equivariance Regularization and Feature Lifting in High Dynamic Range Modulo Imaging，在eess.IV取得新进展。",
      "authors": [
        {
          "original": "Brayan Monroy",
          "chinese": null
        },
        {
          "original": "Jorge Bacca",
          "chinese": null
        }
      ],
      "published": "2026-01-30T14:45:29Z",
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "primaryCategory": "eess.IV",
      "pdfUrl": "https://arxiv.org/pdf/2601.23037v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23037v1",
      "keyInfo": {
        "contributions": [
          "This work proposes a learning-based HDR restoration 框架（提供结构的基础代码库） that incorporates two key strategies: (i) a scale-equivariant 正则化（防止过拟合的技术） that enforces consistency under exposure variations, and (ii) a feature lifting input design combining the raw modulo image, wrapped finite differences, and a closed-form initialization"
        ],
        "methods": [],
        "applications": [
          "Modulo imaging enables high dynamic range (HDR) acquisition by cyclically wrapping saturated intensities, but accurate reconstruction remains challenging due to ambiguities between natural image edges and artificial wrap discontinuities"
        ]
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23031v1",
      "title": "Asymptotic Theory of Iterated 经验性的（基于实验和观察的） Risk Minimization, with Applications to Active Learning",
      "originalTitle": "Asymptotic Theory of Iterated Empirical Risk Minimization, with Applications to Active Learning",
      "summary": "We study a class of iterated 经验性的（基于实验和观察的） risk minimization (ERM) procedures in which two successive ERMs are performed on the same dataset, and the predictions of the first estimator enter as an argument in the loss function of the second. This setting, which arises naturally in active learning and reweighting schemes, introduces intricate statistical dependencies across samples and fundamental...",
      "plainSummary": "We study a class of iterated 经验性的（基于实验和观察的） risk minimization (ERM) procedures in which two successive ERMs are performed on the same dataset, and the predictions of the first estimator enter as an argument in the loss function of the second. This setting, which arises naturally in active learning and reweighting schemes, introduces intricate statistical dependencies across samples and fundamentally distinguishes the problem from classical single-stage ERM analyses. For linear models trained with a broad class of convex losses on Gaussian mixture data, we derive a sharp asymptotic characterization of the test error in the high-dimensional regime where the sample size and ambient dimension scale proportionally. Our results provide explicit, fully asymptotic predictions for the performance of the second-stage estimator despite the reuse of data and the presence of prediction-dependent losses. We apply this theory to revisit a well-studied pool-based active learning problem, removing oracle and sample-splitting assumptions made in 先验概率（观察到数据前的概率） work. We uncover a fundamental tradeoff in how the labeling budget should be allocated across stages, and demonstrate a double-descent behavior of the test error driven purely by data selection, rather than model size or sample count.",
      "oneSentenceSummary": "【stat.ML】Hugo Cui等Asymptotic Theory of Iterated Empirical Risk Minimization, with Applications to Active Learning，在stat.ML取得新进展。",
      "authors": [
        {
          "original": "Hugo Cui",
          "chinese": null
        },
        {
          "original": "Yue M. Lu",
          "chinese": null
        }
      ],
      "published": "2026-01-30T14:39:51Z",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primaryCategory": "stat.ML",
      "pdfUrl": "https://arxiv.org/pdf/2601.23031v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23031v1",
      "keyInfo": {
        "contributions": [
          "This setting, which arises naturally in active learning and reweighting schemes, introduces intricate statistical dependencies across samples and fundamentally distinguishes the problem from classical single-stage ERM analyses"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23030v1",
      "title": "Neural Backward Filtering Forward Guiding",
      "originalTitle": "Neural Backward Filtering Forward Guiding",
      "summary": "Inference in non-linear continuous stochastic processes on trees is challenging, particularly when observations are sparse (leaf-only) and the topology is complex. Exact smoothing via Doob's -transform is intractable for general non-linear dynamics, while particle-based methods degrade in high dimensions. We propose Neural Backward Filtering Forward Guiding (NBFFG), a unified 框架（提供结构的基础代码库） for bo...",
      "plainSummary": "Inference in non-linear continuous stochastic processes on trees is challenging, particularly when observations are sparse (leaf-only) and the topology is complex. Exact smoothing via Doob's -transform is intractable for general non-linear dynamics, while particle-based methods degrade in high dimensions. 我们提出 Neural Backward Filtering Forward Guiding (NBFFG), a unified 框架（提供结构的基础代码库） for both discrete transitions and continuous diffusions. 我们的方法 constructs a variational 后验概率（观察到数据后的概率） by leveraging an auxiliary linear-Gaussian process. This auxiliary process yields a closed-form backward filter that serves as a ``guide'', steering the generative path toward high-似然（给定参数下观察到数据的概率） regions. We then learn a neural residual--parameterized as a normalizing flow or a controlled SDE--to capture the non-linear discrepancies. This formulation allows for an unbiased path-wise subsampling scheme, reducing the training complexity from tree-size dependent to path-length dependent. 经验性的（基于实验和观察的） results show that NBFFG outperforms baselines on synthetic benchmarks, and we demonstrate the method on a high-dimensional inference task in phylogenetic analysis with reconstruction of ancestral butterfly wing shapes.",
      "oneSentenceSummary": "【stat.ML】Gefan Yang等Neural Backward Filtering Forward Guiding，在stat.ML取得新进展。",
      "authors": [
        {
          "original": "Gefan Yang",
          "chinese": null
        },
        {
          "original": "Frank van der Meulen",
          "chinese": null
        },
        {
          "original": "Stefan Sommer",
          "chinese": null
        }
      ],
      "published": "2026-01-30T14:39:50Z",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.ME"
      ],
      "primaryCategory": "stat.ML",
      "pdfUrl": "https://arxiv.org/pdf/2601.23030v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23030v1",
      "keyInfo": {
        "contributions": [
          "We propose Neural Backward Filtering Forward Guiding (NBFFG), a unified 框架（提供结构的基础代码库） for both discrete transitions and continuous diffusions"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23022v1",
      "title": "DimABSA: Building Multilingual and Multidomain Datasets for Dimensional Aspect-Based 情感分析（判断文字情感倾向（正面/负面/中性））",
      "originalTitle": "DimABSA: Building Multilingual and Multidomain Datasets for Dimensional Aspect-Based Sentiment Analysis",
      "summary": "Aspect-Based 情感分析（判断文字情感倾向（正面/负面/中性）） (ABSA) focuses on extracting sentiment at a fine-grained aspect level and has been widely applied across real-world domains. However, existing ABSA research relies on coarse-grained categorical labels (e.g., positive, negative), which limits its ability to capture nuanced affective states. To address this limitation, we adopt a dimensional approach that repres...",
      "plainSummary": "Aspect-Based 情感分析（判断文字情感倾向（正面/负面/中性）） (ABSA) focuses on extracting sentiment at a fine-grained aspect level and has been widely applied across real-world domains. However, existing ABSA research relies on coarse-grained categorical labels (e.g., positive, negative), which limits its ability to capture nuanced affective states. To address this limitation, we adopt a dimensional approach that represents sentiment with continuous valence-arousal (VA) scores, enabling fine-grained analysis at both the aspect and sentiment levels. To this end, we introduce DimABSA, the first multilingual, dimensional ABSA resource annotated with both traditional ABSA elements (aspect terms, aspect categories, and opinion terms) and newly introduced VA scores. This resource contains 76,958 aspect instances across 42,590 sentences, spanning six languages and four domains. We further introduce three subtasks that combine VA scores with different ABSA elements, providing a bridge from traditional ABSA to dimensional ABSA. Given that these subtasks involve both categorical and continuous outputs, 我们提出 a new unified metric, continuous F1 (cF1), which incorporates VA prediction error into standard F1. We provide a 全面的（覆盖广泛的、详细的） 基准（用于比较性能的标准数据集或方法） using both prompted and fine-tuned large language models across all subtasks. Our results show that DimABSA is a challenging 基准（用于比较性能的标准数据集或方法） and provides a foundation for advancing multilingual dimensional ABSA.",
      "oneSentenceSummary": "【cs.CL】Lung-Hao Lee等DimABSA，使用We provide a 全面的（覆盖广泛的、详细的） 基准...，在cs.CL取得新进展。",
      "authors": [
        {
          "original": "Lung-Hao Lee",
          "chinese": null
        },
        {
          "original": "Liang-Chih Yu",
          "chinese": null
        },
        {
          "original": "Natalia Loukashevich",
          "chinese": null
        },
        {
          "original": "Ilseyar Alimova",
          "chinese": null
        },
        {
          "original": "Alexander Panchenko",
          "chinese": null
        },
        {
          "original": "Tzu-Mi Lin",
          "chinese": null
        },
        {
          "original": "Zhe-Yu Xu",
          "chinese": null
        },
        {
          "original": "Jian-Yu Zhou",
          "chinese": null
        },
        {
          "original": "Guangmin Zheng",
          "chinese": null
        },
        {
          "original": "Jin Wang",
          "chinese": null
        },
        {
          "original": "Sharanya Awasthi",
          "chinese": null
        },
        {
          "original": "Jonas Becker",
          "chinese": null
        },
        {
          "original": "Jan Philip Wahle",
          "chinese": null
        },
        {
          "original": "Terry Ruas",
          "chinese": null
        },
        {
          "original": "Shamsuddeen Hassan Muhammad",
          "chinese": null
        },
        {
          "original": "Saif M. Mohammed",
          "chinese": null
        }
      ],
      "published": "2026-01-30T14:30:35Z",
      "categories": [
        "cs.CL"
      ],
      "primaryCategory": "cs.CL",
      "pdfUrl": "https://arxiv.org/pdf/2601.23022v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23022v1",
      "keyInfo": {
        "contributions": [
          "To address this limitation, we adopt a dimensional approach that represents sentiment with continuous valence-arousal (VA) scores, enabling fine-grained analysis at both the aspect and sentiment levels",
          "To this end, we introduce DimABSA, the first multilingual, dimensional ABSA resource annotated with both traditional ABSA elements (aspect terms, aspect categories, and opinion terms) and newly introduced VA scores"
        ],
        "methods": [
          "We provide a 全面的（覆盖广泛的、详细的） 基准（用于比较性能的标准数据集或方法） using both prompted and fine-tuned large language models across all subtasks"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23014v1",
      "title": "Mem-T: Densifying Rewards for Long-Horizon Memory Agents",
      "originalTitle": "Mem-T: Densifying Rewards for Long-Horizon Memory Agents",
      "summary": "Memory agents, which depart from predefined memory-processing pipelines by endogenously managing the processing, storage, and retrieval of memories, have garnered increasing attention for their autonomy and adaptability. However, existing training paradigms remain constrained: agents often traverse long-horizon sequences of memory operations before receiving sparse and delayed rewards, which hinde...",
      "plainSummary": "Memory agents, which depart from predefined memory-processing pipelines by endogenously managing the processing, storage, and retrieval of memories, have garnered increasing attention for their autonomy and adaptability. However, existing training paradigms remain constrained: agents often traverse long-horizon sequences of memory operations before receiving sparse and delayed rewards, which hinders truly end-to-end 优化（寻找最佳参数或解决方案的过程） of memory management policies. To address this limitation, we introduce Mem-T, an autonomous memory agent that interfaces with a lightweight hierarchical memory database to perform dynamic updates and multi-turn retrieval over streaming inputs. To effectively train long-horizon memory management capabilities, we further propose MoT-GRPO, a tree-guided 强化学习（通过试错学习最佳策略的机器学习方法） 框架（提供结构的基础代码库） that transforms sparse terminal feedback into dense, step-wise supervision via memory operation tree 反向传播（训练神经网络时计算梯度的算法） and hindsight credit assignment, thereby enabling the joint 优化（寻找最佳参数或解决方案的过程） of memory construction and retrieval. 大量实验 demonstrate that Mem-T is (1) high-performing, surpassing frameworks such as A-Mem and Mem0 by up to , and (2) economical, operating on a favorable 准确率（正确预测占总预测的比例）-efficiency Pareto frontier and reducing inference tokens per query by relative to GAM without sacrificing performance.",
      "oneSentenceSummary": "【cs.LG】Yanwei Yue等Mem-T，在cs.LG取得新进展。",
      "authors": [
        {
          "original": "Yanwei Yue",
          "chinese": null
        },
        {
          "original": "Guibin Zhang",
          "chinese": null
        },
        {
          "original": "Boci Peng",
          "chinese": null
        },
        {
          "original": "Xuanbo Fan",
          "chinese": null
        },
        {
          "original": "Jiaxin Guo",
          "chinese": null
        },
        {
          "original": "Qiankun Li",
          "chinese": null
        },
        {
          "original": "Yan Zhang",
          "chinese": null
        }
      ],
      "published": "2026-01-30T14:23:33Z",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "primaryCategory": "cs.LG",
      "pdfUrl": "https://arxiv.org/pdf/2601.23014v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23014v1",
      "keyInfo": {
        "contributions": [
          "To address this limitation, we introduce Mem-T, an autonomous memory agent that interfaces with a lightweight hierarchical memory database to perform dynamic updates and multi-turn retrieval over streaming inputs",
          "To effectively train long-horizon memory management capabilities, we further propose MoT-GRPO, a tree-guided 强化学习（通过试错学习最佳策略的机器学习方法） 框架（提供结构的基础代码库） that transforms sparse terminal feedback into dense, step-wise supervision via memory operation tree 反向传播（训练神经网络时计算梯度的算法） and hindsight credit assignment, thereby enabling the joint 优化（寻找最佳参数或解决方案的过程） of memory construction and retrieval"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23006v1",
      "title": "InstructDiff: Domain-Adaptive Data Selection via Differential 熵（信息不确定性的度量） for 高效的（速度快、资源消耗少） LLM 微调（在预训练模型基础上进行小幅调整）",
      "originalTitle": "InstructDiff: Domain-Adaptive Data Selection via Differential Entropy for Efficient LLM Fine-Tuning",
      "summary": "Supervised 微调（在预训练模型基础上进行小幅调整） (SFT) is fundamental to adapting large language models, yet training on complete datasets incurs prohibitive costs with diminishing returns. Existing data selection methods suffer from severe domain specificity: techniques optimized for general instruction-following fail on reasoning tasks, and vice versa. We observe that measuring 熵（信息不确定性的度量） differences between ba...",
      "plainSummary": "Supervised 微调（在预训练模型基础上进行小幅调整） (SFT) is fundamental to adapting large language models, yet training on complete datasets incurs prohibitive costs with diminishing returns. Existing data selection methods suffer from severe domain specificity: techniques optimized for general instruction-following fail on reasoning tasks, and vice versa. We observe that measuring 熵（信息不确定性的度量） differences between base models and minimally instruction-tuned calibrated models reveals a pattern -- samples with the lowest differential 熵（信息不确定性的度量） consistently yield optimal performance across domains, yet this principle manifests domain-adaptively: reasoning tasks favor 熵（信息不确定性的度量） increase (cognitive expansion), while general tasks favor 熵（信息不确定性的度量） decrease (cognitive compression). We introduce InstructDiff, a unified 框架（提供结构的基础代码库） that operationalizes differential 熵（信息不确定性的度量） as a domain-adaptive selection criterion through warmup calibration, bi-directional NLL filtering, and 熵（信息不确定性的度量）-based ranking. 大量实验 show that InstructDiff achieves 17\\% relative improvement over full data training on mathematical reasoning and 52\\% for general instruction-following, outperforming 先验概率（观察到数据前的概率） baselines while using only 10\\% of the data.",
      "oneSentenceSummary": "【cs.CL】Junyou Su等InstructDiff，使用Extensive experiments show tha...，在cs.CL取得新进展。",
      "authors": [
        {
          "original": "Junyou Su",
          "chinese": null
        },
        {
          "original": "He Zhu",
          "chinese": null
        },
        {
          "original": "Xiao Luo",
          "chinese": null
        },
        {
          "original": "Liyu Zhang",
          "chinese": null
        },
        {
          "original": "Hong-Yu Zhou",
          "chinese": null
        },
        {
          "original": "Yun Chen",
          "chinese": null
        },
        {
          "original": "Peng Li",
          "chinese": null
        },
        {
          "original": "Yang Liu",
          "chinese": null
        },
        {
          "original": "Guanhua Chen",
          "chinese": null
        }
      ],
      "published": "2026-01-30T14:15:44Z",
      "categories": [
        "cs.CL"
      ],
      "primaryCategory": "cs.CL",
      "pdfUrl": "https://arxiv.org/pdf/2601.23006v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23006v1",
      "keyInfo": {
        "contributions": [
          "We introduce InstructDiff, a unified 框架（提供结构的基础代码库） that operationalizes differential 熵（信息不确定性的度量） as a domain-adaptive selection criterion through warmup calibration, bi-directional NLL filtering, and 熵（信息不确定性的度量）-based ranking"
        ],
        "methods": [
          "Extensive experiments show that InstructDiff achieves 17\\% relative improvement over full data training on mathematical reasoning and 52\\% for general instruction-following, outperforming 先验概率（观察到数据前的概率） baselines while using only 10\\% of the data"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.23001v1",
      "title": "Bias Beyond Borders: Political Ideology Evaluation and Steering in Multilingual LLMs",
      "originalTitle": "Bias Beyond Borders: Political Ideology Evaluation and Steering in Multilingual LLMs",
      "summary": "Large Language Models (LLMs) increasingly shape global discourse, making fairness and ideological neutrality essential for responsible AI deployment. Despite growing attention to political bias in LLMs, 先验概率（观察到数据前的概率） work largely focuses on high-resource, Western languages or narrow multilingual settings, leaving cross-lingual consistency and safe post-hoc mitigation underexplored. To address th...",
      "plainSummary": "Large Language Models (LLMs) increasingly shape global discourse, making fairness and ideological neutrality essential for responsible AI deployment. Despite growing attention to political bias in LLMs, 先验概率（观察到数据前的概率） work largely focuses on high-resource, Western languages or narrow multilingual settings, leaving cross-lingual consistency and safe post-hoc mitigation underexplored. To address this gap, we present a large-scale multilingual evaluation of political bias spanning 50 countries and 33 languages. We introduce a complementary post-hoc mitigation 框架（提供结构的基础代码库）, Cross-Lingual Alignment Steering (CLAS), designed to augment existing steering methods by aligning ideological representations across languages and dynamically regulating intervention strength. This method aligns latent ideological representations induced by political prompts into a shared ideological subspace, ensuring cross lingual consistency, with the adaptive mechanism prevents over correction and preserves coherence. Experiments demonstrate substantial bias reduction along both economic and social axes with minimal degradation in response quality. The proposed 框架（提供结构的基础代码库） establishes a 可扩展的（能够处理更大规模数据） and 可解释的（能够解释其决策过程） paradigm for fairness-aware multilingual LLM governance, balancing ideological neutrality with linguistic and cultural diversity.",
      "oneSentenceSummary": "【cs.CL】Afrozah Nadeem等Bias Beyond Borders，在cs.CL取得新进展。",
      "authors": [
        {
          "original": "Afrozah Nadeem",
          "chinese": null
        },
        {
          "original": "Agrima",
          "chinese": null
        },
        {
          "original": "Mehwish Nasim",
          "chinese": null
        },
        {
          "original": "Usman Naseem",
          "chinese": null
        }
      ],
      "published": "2026-01-30T14:07:25Z",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primaryCategory": "cs.CL",
      "pdfUrl": "https://arxiv.org/pdf/2601.23001v1",
      "abstractUrl": "https://arxiv.org/abs/2601.23001v1",
      "keyInfo": {
        "contributions": [
          "To address this gap, we present a large-scale multilingual evaluation of political bias spanning 50 countries and 33 languages",
          "We introduce a complementary post-hoc mitigation 框架（提供结构的基础代码库）, Cross-Lingual Alignment Steering (CLAS), designed to augment existing steering methods by aligning ideological representations across languages and dynamically regulating intervention strength"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22993v1",
      "title": "Value-at-Risk Constrained Policy 优化（寻找最佳参数或解决方案的过程）",
      "originalTitle": "Value-at-Risk Constrained Policy Optimization",
      "summary": "We introduce the Value-at-Risk Constrained Policy 优化（寻找最佳参数或解决方案的过程） algorithm (VaR-CPO), a sample 高效的（速度快、资源消耗少） and conservative method designed to optimize Value-at-Risk (VaR) constraints directly. Empirically, we demonstrate that VaR-CPO is capable of safe exploration, achieving zero constraint violations during training in feasible environments, a critical property that 基线（用于对比的基准方法） methods ...",
      "plainSummary": "We introduce the Value-at-Risk Constrained Policy 优化（寻找最佳参数或解决方案的过程） algorithm (VaR-CPO), a sample 高效的（速度快、资源消耗少） and conservative method designed to optimize Value-at-Risk (VaR) constraints directly. Empirically, we demonstrate that VaR-CPO is capable of safe exploration, achieving zero constraint violations during training in feasible environments, a critical property that 基线（用于对比的基准方法） methods fail to uphold. To overcome the inherent non-differentiability of the VaR constraint, we employ the one-sided Chebyshev inequality to obtain a tractable surrogate based on the first two moments of the cost return. Additionally, by extending the trust-region 框架（提供结构的基础代码库） of the Constrained Policy 优化（寻找最佳参数或解决方案的过程） (CPO) method, we provide rigorous worst-case bounds for both policy improvement and constraint violation during the training process.",
      "oneSentenceSummary": "【cs.LG】Rohan Tangri等Value-at-Risk Constrained Policy Optimization，使用To overcome the inherent non-d...，在cs.LG取得新进展。",
      "authors": [
        {
          "original": "Rohan Tangri",
          "chinese": null
        },
        {
          "original": "Jan-Peter Calliess",
          "chinese": null
        }
      ],
      "published": "2026-01-30T13:57:47Z",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "primaryCategory": "cs.LG",
      "pdfUrl": "https://arxiv.org/pdf/2601.22993v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22993v1",
      "keyInfo": {
        "contributions": [
          "We introduce the Value-at-Risk Constrained Policy 优化（寻找最佳参数或解决方案的过程） algorithm (VaR-CPO), a sample 高效的（速度快、资源消耗少） and conservative method designed to optimize Value-at-Risk (VaR) constraints directly"
        ],
        "methods": [
          "To overcome the inherent non-differentiability of the VaR constraint, we employ the one-sided Chebyshev inequality to obtain a tractable surrogate based on the first two moments of the cost return"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22988v1",
      "title": "Learning Geometrically-Grounded 3D Visual Representations for View-可泛化的（能够适用于新场景） Robotic Manipulation",
      "originalTitle": "Learning Geometrically-Grounded 3D Visual Representations for View-Generalizable Robotic Manipulation",
      "summary": "Real-world robotic manipulation demands visuomotor policies capable of 鲁棒的（对噪声和扰动不敏感） spatial scene understanding and strong generalization across diverse camera viewpoints. While recent advances in 3D-aware visual representations have shown promise, they still suffer from several key limitations, including reliance on multi-view observations during inference which is impractical in single-view re...",
      "plainSummary": "Real-world robotic manipulation demands visuomotor policies capable of 鲁棒的（对噪声和扰动不敏感） spatial scene understanding and strong generalization across diverse camera viewpoints. While recent advances in 3D-aware visual representations have shown promise, they still suffer from several key limitations, including reliance on multi-view observations during inference which is impractical in single-view restricted scenarios, incomplete scene modeling that fails to capture holistic and fine-grained geometric structures essential for precise manipulation, and lack of effective policy training strategies to retain and exploit the acquired 3D knowledge. To address these challenges, we present MethodName, a unified representation-policy learning 框架（提供结构的基础代码库） for view-可泛化的（能够适用于新场景） robotic manipulation. MethodName introduces a single-view 3D pretraining paradigm that leverages point cloud reconstruction and feed-forward gaussian splatting under multi-view supervision to learn holistic geometric representations. During policy learning, MethodName performs multi-step distillation to preserve the pretrained geometric understanding and effectively transfer it to manipulation skills. We conduct experiments on 12 RLBench tasks, where our approach outperforms the previous 最先进（当前最好的、领先的方法） method by 12.7% in average success rate. Further evaluation on six representative tasks demonstrates strong zero-shot view generalization, with success rate drops of only 22.0% and 29.7% under moderate and large viewpoint shifts respectively, whereas the 最先进（当前最好的、领先的方法） method suffers larger decreases of 41.6% and 51.5%.",
      "oneSentenceSummary": "【cs.RO】Di Zhang等Learning Geometrically-Grounded 3D Visual Representations for View-Generalizable Robotic Manipulation，使用MethodName introduces a single...，在cs.RO取得新进展。",
      "authors": [
        {
          "original": "Di Zhang",
          "chinese": null
        },
        {
          "original": "Weicheng Duan",
          "chinese": null
        },
        {
          "original": "Dasen Gu",
          "chinese": null
        },
        {
          "original": "Hongye Lu",
          "chinese": null
        },
        {
          "original": "Hai Zhang",
          "chinese": null
        },
        {
          "original": "Hang Yu",
          "chinese": null
        },
        {
          "original": "Junqiao Zhao",
          "chinese": null
        },
        {
          "original": "Guang Chen",
          "chinese": null
        }
      ],
      "published": "2026-01-30T13:53:53Z",
      "categories": [
        "cs.RO"
      ],
      "primaryCategory": "cs.RO",
      "pdfUrl": "https://arxiv.org/pdf/2601.22988v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22988v1",
      "keyInfo": {
        "contributions": [
          "While recent advances in 3D-aware visual representations have shown promise, they still suffer from several key limitations, including reliance on multi-view observations during inference which is impractical in single-view restricted scenarios, incomplete scene modeling that fails to capture holistic and fine-grained geometric structures essential for precise manipulation, and lack of effective policy training strategies to retain and exploit the acquired 3D knowledge",
          "To address these challenges, we present MethodName, a unified representation-policy learning 框架（提供结构的基础代码库） for view-可泛化的（能够适用于新场景） robotic manipulation"
        ],
        "methods": [
          "MethodName introduces a single-view 3D pretraining paradigm that leverages point cloud reconstruction and feed-forward gaussian splatting under multi-view supervision to learn holistic geometric representations"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22982v1",
      "title": "About an Automating Annotation Method for Robot Markers",
      "originalTitle": "About an Automating Annotation Method for Robot Markers",
      "summary": "Factory automation has become increasingly important due to labor shortages, leading to the introduction of autonomous mobile robots for tasks such as material transportation. Markers are commonly used for robot self-localization and object identification. In the RoboCup Logistics League (RCLL), ArUco markers are employed both for robot localization and for identifying processing modules. Conventi...",
      "plainSummary": "Factory automation has become increasingly important due to labor shortages, leading to the introduction of autonomous mobile robots for tasks such as material transportation. Markers are commonly used for robot self-localization and object identification. In the RoboCup Logistics League (RCLL), ArUco markers are employed both for robot localization and for identifying processing modules. Conventional recognition relies on OpenCV-based image processing, which detects black-and-white marker patterns. However, these methods often fail under noise, motion blur, defocus, or varying illumination conditions. Deep-learning-based recognition offers improved robustness under such conditions, but requires large amounts of annotated data. Annotation must typically be done manually, as the type and position of objects cannot be detected automatically, making dataset preparation a major bottleneck. In contrast, ArUco markers include built-in recognition modules that provide both ID and positional information, enabling automatic annotation. This paper proposes an automated annotation method for training deep-learning models on ArUco marker images. By leveraging marker detection results obtained from the ArUco module, the proposed approach eliminates the need for manual labeling. A YOLO-based model is trained using the automatically annotated dataset, and its performance is evaluated under various conditions. Experimental results demonstrate that the proposed method improves recognition performance compared with conventional image-processing techniques, particularly for images affected by blur or defocus. Automatic annotation also reduces human effort and ensures consistent labeling quality. Future work will investigate the relationship between confidence thresholds and recognition performance.",
      "oneSentenceSummary": "【cs.CV】Wataru Uemura等About an Automating Annotation Method for Robot Markers，使用A YOLO-based model is trained ...，在cs.CV取得新进展。",
      "authors": [
        {
          "original": "Wataru Uemura",
          "chinese": null
        },
        {
          "original": "Takeru Nagashima",
          "chinese": null
        }
      ],
      "published": "2026-01-30T13:44:56Z",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primaryCategory": "cs.CV",
      "pdfUrl": "https://arxiv.org/pdf/2601.22982v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22982v1",
      "keyInfo": {
        "contributions": [
          "This paper proposes an automated annotation method for training deep-learning models on ArUco marker images",
          "By leveraging marker detection results obtained from the ArUco module, the proposed approach eliminates the need for manual labeling"
        ],
        "methods": [
          "A YOLO-based model is trained using the automatically annotated dataset, and its performance is evaluated under various conditions"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22965v1",
      "title": "Self-Imitated Diffusion Policy for 高效的（速度快、资源消耗少） and 鲁棒的（对噪声和扰动不敏感） Visual Navigation",
      "originalTitle": "Self-Imitated Diffusion Policy for Efficient and Robust Visual Navigation",
      "summary": "Diffusion policies (DP) have demonstrated significant potential in visual navigation by capturing diverse multi-modal trajectory distributions. However, standard imitation learning (IL), which most DP methods rely on for training, often inherits sub-optimality and redundancy from expert demonstrations, thereby necessitating a computationally intensive \"generate-then-filter\" 流程（数据处理或模型训练的完整流程） that...",
      "plainSummary": "Diffusion policies (DP) have demonstrated significant potential in visual navigation by capturing diverse multi-modal trajectory distributions. However, standard imitation learning (IL), which most DP methods rely on for training, often inherits sub-optimality and redundancy from expert demonstrations, thereby necessitating a computationally intensive \"generate-then-filter\" 流程（数据处理或模型训练的完整流程） that relies on auxiliary selectors during inference. To address these challenges, 我们提出 Self-Imitated Diffusion Policy (SIDP), a 新颖的（创新的、前人未做过的） 框架（提供结构的基础代码库） that learns improved planning by selectively imitating a set of trajectories sampled from itself. Specifically, SIDP introduces a reward-guided self-imitation mechanism that encourages the policy to consistently produce high-quality trajectories efficiently, rather than outputs of inconsistent quality, thereby reducing reliance on extensive sampling and post-filtering. During training, we employ a reward-driven curriculum learning paradigm to mitigate inefficient data utility, and goal-agnostic exploration for trajectory augmentation to improve planning robustness. Extensive evaluations on a 全面的（覆盖广泛的、详细的） simulation 基准（用于比较性能的标准数据集或方法） show that SIDP 显著优于 previous methods, with real-world experiments confirming its effectiveness across multiple robotic platforms. On Jetson Orin Nano, SIDP delivers a 2.5 faster inference than the 基线（用于对比的基准方法） NavDP, i.e., 110ms VS 273ms, enabling 高效的（速度快、资源消耗少） real-time deployment.",
      "oneSentenceSummary": "【cs.RO】Runhua Zhang等Self-Imitated Diffusion Policy for Efficient and Robust Visual Navigation，在cs.RO取得新进展。",
      "authors": [
        {
          "original": "Runhua Zhang",
          "chinese": null
        },
        {
          "original": "Junyi Hou",
          "chinese": null
        },
        {
          "original": "Changxu Cheng",
          "chinese": null
        },
        {
          "original": "Qiyi Chen",
          "chinese": null
        },
        {
          "original": "Tao Wang",
          "chinese": null
        },
        {
          "original": "Wuyue Zhao",
          "chinese": null
        }
      ],
      "published": "2026-01-30T13:27:59Z",
      "categories": [
        "cs.RO"
      ],
      "primaryCategory": "cs.RO",
      "pdfUrl": "https://arxiv.org/pdf/2601.22965v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22965v1",
      "keyInfo": {
        "contributions": [
          "To address these challenges, we propose Self-Imitated Diffusion Policy (SIDP), a 新颖的（创新的、前人未做过的） 框架（提供结构的基础代码库） that learns improved planning by selectively imitating a set of trajectories sampled from itself",
          "Specifically, SIDP introduces a reward-guided self-imitation mechanism that encourages the policy to consistently produce high-quality trajectories efficiently, rather than outputs of inconsistent quality, thereby reducing reliance on extensive sampling and post-filtering"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22951v1",
      "title": "OneFlowSBI: One Model, Many Queries for Simulation-Based Inference",
      "originalTitle": "OneFlowSBI: One Model, Many Queries for Simulation-Based Inference",
      "summary": "We introduce \\textit{OneFlowSBI}, a unified 框架（提供结构的基础代码库） for simulation-based inference that learns a single flow-matching 生成模型（能够创建新数据的AI模型） over the joint distribution of parameters and observations. Leveraging a query-aware masking distribution during training, the same model supports multiple inference tasks, including 后验概率（观察到数据后的概率） sampling, 似然（给定参数下观察到数据的概率） estimation, and arbitrary con...",
      "plainSummary": "We introduce \\textit{OneFlowSBI}, a unified 框架（提供结构的基础代码库） for simulation-based inference that learns a single flow-matching 生成模型（能够创建新数据的AI模型） over the joint distribution of parameters and observations. Leveraging a query-aware masking distribution during training, the same model supports multiple inference tasks, including 后验概率（观察到数据后的概率） sampling, 似然（给定参数下观察到数据的概率） estimation, and arbitrary conditional distributions, without task-specific retraining. We evaluate \\textit{OneFlowSBI} on ten 基准（用于比较性能的标准数据集或方法） inference problems and two high-dimensional real-world inverse problems across multiple simulation budgets. \\textit{OneFlowSBI} is shown to deliver competitive performance against 最先进（当前最好的、领先的方法） generalized inference solvers and specialized 后验概率（观察到数据后的概率） estimators, while enabling 高效的（速度快、资源消耗少） sampling with few ODE integration steps and remaining 鲁棒的（对噪声和扰动不敏感） under noisy and partially observed data.",
      "oneSentenceSummary": "【stat.ML】Mayank Nautiyal等创建新数据的AI模型） over the joint distribution of parameter的OneFlowSBI，在stat.ML取得新进展。",
      "authors": [
        {
          "original": "Mayank Nautiyal",
          "chinese": null
        },
        {
          "original": "Li Ju",
          "chinese": null
        },
        {
          "original": "Melker Ernfors",
          "chinese": null
        },
        {
          "original": "Klara Hagland",
          "chinese": null
        },
        {
          "original": "Ville Holma",
          "chinese": null
        },
        {
          "original": "Maximilian Werkö Söderholm",
          "chinese": null
        },
        {
          "original": "Andreas Hellander",
          "chinese": null
        },
        {
          "original": "Prashant Singh",
          "chinese": null
        }
      ],
      "published": "2026-01-30T13:14:44Z",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primaryCategory": "stat.ML",
      "pdfUrl": "https://arxiv.org/pdf/2601.22951v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22951v1",
      "keyInfo": {
        "contributions": [
          "We introduce \\textit{OneFlowSBI}, a unified 框架（提供结构的基础代码库） for simulation-based inference that learns a single flow-matching 生成模型（能够创建新数据的AI模型） over the joint distribution of parameters and observations"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22950v1",
      "title": "困惑度（语言模型预测能力的度量，越低越好） Cannot Always Tell Right from Wrong",
      "originalTitle": "Perplexity Cannot Always Tell Right from Wrong",
      "summary": "困惑度（语言模型预测能力的度量，越低越好） -- a function measuring a model's overall level of \"surprise\" when encountering a particular output -- has gained significant traction in recent years, both as a loss function and as a simple-to-compute metric of model quality. 先验概率（观察到数据前的概率） studies have pointed out several limitations of 困惑度（语言模型预测能力的度量，越低越好）, often from an 经验性的（基于实验和观察的） manner. Here we leverage recent re...",
      "plainSummary": "困惑度（语言模型预测能力的度量，越低越好） -- a function measuring a model's overall level of \"surprise\" when encountering a particular output -- has gained significant traction in recent years, both as a loss function and as a simple-to-compute metric of model quality. 先验概率（观察到数据前的概率） studies have pointed out several limitations of 困惑度（语言模型预测能力的度量，越低越好）, often from an 经验性的（基于实验和观察的） manner. Here we leverage recent results on Transformer模型（一种处理序列数据的神经网络架构，特别擅长处理语言） continuity to show in a rigorous manner how 困惑度（语言模型预测能力的度量，越低越好） may be an unsuitable metric for model selection. Specifically, we prove that, if there is any sequence that a compact decoder-only Transformer模型（一种处理序列数据的神经网络架构，特别擅长处理语言） model predicts accurately and confidently -- a necessary pre-requisite for strong generalisation -- it must imply existence of another sequence with very low 困惑度（语言模型预测能力的度量，越低越好）, but not predicted correctly by that same model. Further, by analytically studying iso-困惑度（语言模型预测能力的度量，越低越好） plots, we find that 困惑度（语言模型预测能力的度量，越低越好） will not always select for the more accurate model -- rather, any increase in model confidence must be accompanied by a commensurate rise in 准确率（正确预测占总预测的比例） for the new model to be selected.",
      "oneSentenceSummary": "【cs.LG】Petar Veličković等Perplexity Cannot Always Tell Right from Wrong，在cs.LG取得新进展。",
      "authors": [
        {
          "original": "Petar Veličković",
          "chinese": null
        },
        {
          "original": "Federico Barbero",
          "chinese": null
        },
        {
          "original": "Christos Perivolaropoulos",
          "chinese": null
        },
        {
          "original": "Simon Osindero",
          "chinese": null
        },
        {
          "original": "Razvan Pascanu",
          "chinese": null
        }
      ],
      "published": "2026-01-30T13:13:10Z",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primaryCategory": "cs.LG",
      "pdfUrl": "https://arxiv.org/pdf/2601.22950v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22950v1",
      "keyInfo": {
        "contributions": [],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22930v1",
      "title": "MTDrive: Multi-turn Interactive 强化学习（通过试错学习最佳策略的机器学习方法） for Autonomous Driving",
      "originalTitle": "MTDrive: Multi-turn Interactive Reinforcement Learning for Autonomous Driving",
      "summary": "Trajectory planning is a core task in autonomous driving, requiring the prediction of safe and comfortable paths across diverse scenarios. Integrating Multi-modal Large Language Models (MLLMs) with 强化学习（通过试错学习最佳策略的机器学习方法） (RL) has shown promise in addressing \"long-tail\" scenarios. However, existing methods are constrained to single-turn reasoning, limiting their ability to handle complex tasks req...",
      "plainSummary": "Trajectory planning is a core task in autonomous driving, requiring the prediction of safe and comfortable paths across diverse scenarios. Integrating Multi-modal Large Language Models (MLLMs) with 强化学习（通过试错学习最佳策略的机器学习方法） (RL) has shown promise in addressing \"long-tail\" scenarios. However, existing methods are constrained to single-turn reasoning, limiting their ability to handle complex tasks requiring iterative refinement. To overcome this limitation, we present MTDrive, a multi-turn 框架（提供结构的基础代码库） that enables MLLMs to iteratively refine trajectories based on environmental feedback. MTDrive introduces Multi-Turn Group Relative Policy 优化（寻找最佳参数或解决方案的过程） (mtGRPO), which mitigates reward sparsity by computing relative advantages across turns. We further construct an interactive trajectory understanding dataset from closed-loop simulation to support multi-turn training. Experiments on the NAVSIM 基准（用于比较性能的标准数据集或方法） demonstrate superior performance compared to existing methods, validating the effectiveness of our multi-turn reasoning paradigm. Additionally, we implement system-level optimizations to reduce data transfer overhead caused by high-resolution images and multi-turn sequences, achieving 2.5x training throughput. Our data, models, and code will be made available soon.",
      "oneSentenceSummary": "【cs.RO】Xidong Li等MTDrive，使用To overcome this limitation, w...，在cs.RO取得新进展。",
      "authors": [
        {
          "original": "Xidong Li",
          "chinese": null
        },
        {
          "original": "Mingyu Guo",
          "chinese": null
        },
        {
          "original": "Chenchao Xu",
          "chinese": null
        },
        {
          "original": "Bailin Li",
          "chinese": null
        },
        {
          "original": "Wenjing Zhu",
          "chinese": null
        },
        {
          "original": "Yangang Zou",
          "chinese": null
        },
        {
          "original": "Rui Chen",
          "chinese": null
        },
        {
          "original": "Zehuan Wang",
          "chinese": null
        }
      ],
      "published": "2026-01-30T12:47:55Z",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primaryCategory": "cs.RO",
      "pdfUrl": "https://arxiv.org/pdf/2601.22930v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22930v1",
      "keyInfo": {
        "contributions": [
          "To overcome this limitation, we present MTDrive, a multi-turn 框架（提供结构的基础代码库） that enables MLLMs to iteratively refine trajectories based on environmental feedback",
          "MTDrive introduces Multi-Turn Group Relative Policy 优化（寻找最佳参数或解决方案的过程） (mtGRPO), which mitigates reward sparsity by computing relative advantages across turns"
        ],
        "methods": [
          "To overcome this limitation, we present MTDrive, a multi-turn 框架（提供结构的基础代码库） that enables MLLMs to iteratively refine trajectories based on environmental feedback"
        ],
        "applications": [
          "To overcome this limitation, we present MTDrive, a multi-turn 框架（提供结构的基础代码库） that enables MLLMs to iteratively refine trajectories based on environmental feedback"
        ]
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22927v1",
      "title": "Toward Fully Autonomous Driving: AI, Challenges, Opportunities, and Needs",
      "originalTitle": "Toward Fully Autonomous Driving: AI, Challenges, Opportunities, and Needs",
      "summary": "Automated driving (AD) is promising, but the transition to fully autonomous driving is, among other things, subject to the real, ever-changing open world and the resulting challenges. However, research in the field of AD demonstrates the ability of 人工智能（让机器模拟人类智能的技术） (AI) to outperform classical approaches, handle higher complexities, and reach a new level of autonomy. At the same time, the use of...",
      "plainSummary": "Automated driving (AD) is promising, but the transition to fully autonomous driving is, among other things, subject to the real, ever-changing open world and the resulting challenges. However, research in the field of AD demonstrates the ability of 人工智能（让机器模拟人类智能的技术） (AI) to outperform classical approaches, handle higher complexities, and reach a new level of autonomy. At the same time, the use of AI raises further questions of safety and transferability. To identify the challenges and opportunities arising from AI concerning autonomous driving functionalities, we have analyzed the current state of AD, outlined limitations, and identified foreseeable technological possibilities. Thereby, various further challenges are examined in the context of prospective developments. In this way, this article reconsiders fully autonomous driving with respect to advancements in the field of AI and carves out the respective needs and resulting research questions.",
      "oneSentenceSummary": "【cs.RO】Lars Ullrich等Toward Fully Autonomous Driving，在cs.RO取得新进展。",
      "authors": [
        {
          "original": "Lars Ullrich",
          "chinese": null
        },
        {
          "original": "Michael Buchholz",
          "chinese": null
        },
        {
          "original": "Klaus Dietmayer",
          "chinese": null
        },
        {
          "original": "Knut Graichen",
          "chinese": null
        }
      ],
      "published": "2026-01-30T12:45:44Z",
      "categories": [
        "cs.RO",
        "cs.ET"
      ],
      "primaryCategory": "cs.RO",
      "pdfUrl": "https://arxiv.org/pdf/2601.22927v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22927v1",
      "keyInfo": {
        "contributions": [
          "Thereby, various further challenges are examined in the context of prospective developments"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22849v1",
      "title": "鲁棒的（对噪声和扰动不敏感） Rigid Body Assembly via Contact-Implicit Optimal Control with Exact Second-Order Derivatives",
      "originalTitle": "Robust Rigid Body Assembly via Contact-Implicit Optimal Control with Exact Second-Order Derivatives",
      "summary": "高效的（速度快、资源消耗少） planning of assembly motions is a long standing challenge in the field of robotics that has been primarily tackled with 强化学习（通过试错学习最佳策略的机器学习方法） and sampling-based methods by using extensive physics simulations. This paper proposes a sample-高效的（速度快、资源消耗少） 鲁棒的（对噪声和扰动不敏感） optimal control approach for the determination of assembly motions, which requires significantly less physics simul...",
      "plainSummary": "高效的（速度快、资源消耗少） planning of assembly motions is a long standing challenge in the field of robotics that has been primarily tackled with 强化学习（通过试错学习最佳策略的机器学习方法） and sampling-based methods by using extensive physics simulations. This paper proposes a sample-高效的（速度快、资源消耗少） 鲁棒的（对噪声和扰动不敏感） optimal control approach for the determination of assembly motions, which requires significantly less physics simulation steps during planning through the 高效的（速度快、资源消耗少） use of derivative information. To this end, a differentiable physics simulation is constructed that provides second-order analytic derivatives to the numerical solver and allows one to traverse seamlessly from informative derivatives to accurate contact simulation. The solution of the physics simulation problem is made differentiable by using smoothing inspired by interior-point methods applied to both the collision detection as well as the contact resolution problem. 我们提出 a modified variant of an 优化（寻找最佳参数或解决方案的过程）-based formulation of collision detection formulated as a linear program and present an 高效的（速度快、资源消耗少） implementation for the nominal evaluation and corresponding first- and second-order derivatives. Moreover, a multi-scenario-based trajectory 优化（寻找最佳参数或解决方案的过程） problem that ensures robustness with respect to sim-to-real mismatches is derived. The capability of the considered formulation is illustrated by results where over 99\\% successful executions are achieved in real-world experiments. Thereby, we carefully investigate the effect of smooth approximations of the contact dynamics and 鲁棒的（对噪声和扰动不敏感） modeling on the success rates. Furthermore, the method's capability is tested on different peg-in-hole problems in simulation to show the benefit of using exact Hessians over commonly used Hessian approximations.",
      "oneSentenceSummary": "【cs.RO】Christian Dietz等Robust Rigid Body Assembly via Contact-Implicit Optimal Control with Exact Second-Order Derivatives，使用高效的（速度快、资源消耗少） planning of ass...，在cs.RO取得新进展。",
      "authors": [
        {
          "original": "Christian Dietz",
          "chinese": null
        },
        {
          "original": "Sebastian Albrecht",
          "chinese": null
        },
        {
          "original": "Gianluca Frison",
          "chinese": null
        },
        {
          "original": "Moritz Diehl",
          "chinese": null
        },
        {
          "original": "Armin Nurkanović",
          "chinese": null
        }
      ],
      "published": "2026-01-30T11:21:20Z",
      "categories": [
        "cs.RO",
        "math.OC"
      ],
      "primaryCategory": "cs.RO",
      "pdfUrl": "https://arxiv.org/pdf/2601.22849v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22849v1",
      "keyInfo": {
        "contributions": [
          "This paper proposes a sample-高效的（速度快、资源消耗少） 鲁棒的（对噪声和扰动不敏感） optimal control approach for the determination of assembly motions, which requires significantly less physics simulation steps during planning through the 高效的（速度快、资源消耗少） use of derivative information",
          "We propose a modified variant of an 优化（寻找最佳参数或解决方案的过程）-based formulation of collision detection formulated as a linear program and present an 高效的（速度快、资源消耗少） implementation for the nominal evaluation and corresponding first- and second-order derivatives"
        ],
        "methods": [
          "高效的（速度快、资源消耗少） planning of assembly motions is a long standing challenge in the field of robotics that has been primarily tackled with 强化学习（通过试错学习最佳策略的机器学习方法） and sampling-based methods by using extensive physics simulations",
          "The solution of the physics simulation problem is made differentiable by using smoothing inspired by interior-point methods applied to both the collision detection as well as the contact resolution problem"
        ],
        "applications": [
          "The solution of the physics simulation problem is made differentiable by using smoothing inspired by interior-point methods applied to both the collision detection as well as the contact resolution problem"
        ]
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22830v1",
      "title": "A Comparative Evaluation of Large Vision-Language Models for 2D 目标检测（在图像中识别和定位特定物体） under SOTIF Conditions",
      "originalTitle": "A Comparative Evaluation of Large Vision-Language Models for 2D Object Detection under SOTIF Conditions",
      "summary": "Reliable environmental perception remains one of the main obstacles for safe operation of automated vehicles. Safety of the Intended Functionality (SOTIF) concerns safety risks from perception insufficiencies, particularly under adverse conditions where conventional detectors often falter. While Large Vision-Language Models (LVLMs) demonstrate promising semantic reasoning, their quantitative effec...",
      "plainSummary": "Reliable environmental perception remains one of the main obstacles for safe operation of automated vehicles. Safety of the Intended Functionality (SOTIF) concerns safety risks from perception insufficiencies, particularly under adverse conditions where conventional detectors often falter. While Large Vision-Language Models (LVLMs) demonstrate promising semantic reasoning, their quantitative effectiveness for safety-critical 2D 目标检测（在图像中识别和定位特定物体） is underexplored. This paper presents a systematic evaluation of ten representative LVLMs using the PeSOTIF dataset, a 基准（用于比较性能的标准数据集或方法） specifically curated for long-tail traffic scenarios and environmental degradations. Performance is quantitatively compared against the classical perception approach, a YOLO-based detector. Experimental results reveal a critical trade-off: top-performing LVLMs (e.g., Gemini 3, Doubao) surpass the YOLO 基线（用于对比的基准方法） in 召回率（真正正例中被正确预测的比例） by over 25% in complex natural scenarios, exhibiting superior robustness to visual degradation. Conversely, the 基线（用于对比的基准方法） retains an advantage in geometric 精确率（预测为正例中真正正例的比例） for synthetic perturbations. These findings highlight the complementary strengths of semantic reasoning versus geometric regression, supporting the use of LVLMs as high-level safety validators in SOTIF-oriented automated driving systems.",
      "oneSentenceSummary": "【cs.CV】Ji Zhou等A Comparative Evaluation of Large Vision-Language Models for 2D Object Detection under SOTIF Conditions，使用This paper presents a systemat...，在cs.CV取得新进展。",
      "authors": [
        {
          "original": "Ji Zhou",
          "chinese": null
        },
        {
          "original": "Yilin Ding",
          "chinese": null
        },
        {
          "original": "Yongqi Zhao",
          "chinese": null
        },
        {
          "original": "Jiachen Xu",
          "chinese": null
        },
        {
          "original": "Arno Eichberger",
          "chinese": null
        }
      ],
      "published": "2026-01-30T10:58:24Z",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "primaryCategory": "cs.CV",
      "pdfUrl": "https://arxiv.org/pdf/2601.22830v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22830v1",
      "keyInfo": {
        "contributions": [
          "This paper presents a systematic evaluation of ten representative LVLMs using the PeSOTIF dataset, a 基准（用于比较性能的标准数据集或方法） specifically curated for long-tail traffic scenarios and environmental degradations"
        ],
        "methods": [
          "This paper presents a systematic evaluation of ten representative LVLMs using the PeSOTIF dataset, a 基准（用于比较性能的标准数据集或方法） specifically curated for long-tail traffic scenarios and environmental degradations"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22823v1",
      "title": "Offline 强化学习（通过试错学习最佳策略的机器学习方法） of High-Quality Behaviors Under 鲁棒的（对噪声和扰动不敏感） Style Alignment",
      "originalTitle": "Offline Reinforcement Learning of High-Quality Behaviors Under Robust Style Alignment",
      "summary": "We study offline 强化学习（通过试错学习最佳策略的机器学习方法） of style-conditioned policies using explicit style supervision via subtrajectory labeling functions. In this setting, aligning style with high task performance is particularly challenging due to distribution shift and inherent conflicts between style and reward. Existing methods, despite introducing numerous definitions of style, often fail to reconcile the...",
      "plainSummary": "We study offline 强化学习（通过试错学习最佳策略的机器学习方法） of style-conditioned policies using explicit style supervision via subtrajectory labeling functions. In this setting, aligning style with high task performance is particularly challenging due to distribution shift and inherent conflicts between style and reward. Existing methods, despite introducing numerous definitions of style, often fail to reconcile these objectives effectively. To address these challenges, 我们提出 a unified definition of behavior style and instantiate it into a practical 框架（提供结构的基础代码库）. Building on this, we introduce Style-Conditioned Implicit Q-Learning (SCIQL), which leverages offline goal-conditioned RL techniques, such as hindsight relabeling and value learning, and combine it with a new Gated Advantage Weighted Regression mechanism to efficiently optimize task performance while preserving style alignment. Experiments demonstrate that SCIQL achieves superior performance on both objectives compared to 先验概率（观察到数据前的概率） offline methods. Code, datasets and visuals are available in: https://sciql-iclr-2026.github.io/.",
      "oneSentenceSummary": "【cs.LG】Mathieu Petitbois等Offline Reinforcement Learning of High-Quality Behaviors Under Robust Style Alignment，使用We study offline 强化学习（通过试错学习最佳...，在cs.LG取得新进展。",
      "authors": [
        {
          "original": "Mathieu Petitbois",
          "chinese": null
        },
        {
          "original": "Rémy Portelas",
          "chinese": null
        },
        {
          "original": "Sylvain Lamprier",
          "chinese": null
        }
      ],
      "published": "2026-01-30T10:49:22Z",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primaryCategory": "cs.LG",
      "pdfUrl": "https://arxiv.org/pdf/2601.22823v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22823v1",
      "keyInfo": {
        "contributions": [
          "To address these challenges, we propose a unified definition of behavior style and instantiate it into a practical 框架（提供结构的基础代码库）",
          "Building on this, we introduce Style-Conditioned Implicit Q-Learning (SCIQL), which leverages offline goal-conditioned RL techniques, such as hindsight relabeling and value learning, and combine it with a new Gated Advantage Weighted Regression mechanism to efficiently optimize task performance while preserving style alignment"
        ],
        "methods": [
          "We study offline 强化学习（通过试错学习最佳策略的机器学习方法） of style-conditioned policies using explicit style supervision via subtrajectory labeling functions",
          "Building on this, we introduce Style-Conditioned Implicit Q-Learning (SCIQL), which leverages offline goal-conditioned RL techniques, such as hindsight relabeling and value learning, and combine it with a new Gated Advantage Weighted Regression mechanism to efficiently optimize task performance while preserving style alignment"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22816v1",
      "title": "Cascaded Flow Matching for Heterogeneous Tabular Data with Mixed-Type Features",
      "originalTitle": "Cascaded Flow Matching for Heterogeneous Tabular Data with Mixed-Type Features",
      "summary": "Advances in generative modeling have recently been adapted to tabular data containing discrete and continuous features. However, generating mixed-type features that combine discrete states with an otherwise continuous distribution in a single feature remains challenging. We advance the 最先进（当前最好的、领先的方法） in diffusion models for tabular data with a cascaded approach. We first generate a low-resolutio...",
      "plainSummary": "Advances in generative modeling have recently been adapted to tabular data containing discrete and continuous features. However, generating mixed-type features that combine discrete states with an otherwise continuous distribution in a single feature remains challenging. We advance the 最先进（当前最好的、领先的方法） in diffusion models for tabular data with a cascaded approach. We first generate a low-resolution version of a tabular data row, that is, the collection of the purely categorical features and a coarse categorical representation of numerical features. Next, this information is leveraged in the high-resolution flow matching model via a 新颖的（创新的、前人未做过的） guided conditional probability path and data-dependent coupling. The low-resolution representation of numerical features explicitly accounts for discrete outcomes, such as missing or inflated values, and therewith enables a more faithful generation of mixed-type features. We formally prove that this cascade tightens the transport cost bound. The results indicate that our model generates significantly more realistic samples and captures distributional details more accurately, for example, the detection score increases by 40%.",
      "oneSentenceSummary": "【cs.LG】Markus Mueller等Cascaded Flow Matching for Heterogeneous Tabular Data with Mixed-Type Features，在cs.LG取得新进展。",
      "authors": [
        {
          "original": "Markus Mueller",
          "chinese": null
        },
        {
          "original": "Kathrin Gruber",
          "chinese": null
        },
        {
          "original": "Dennis Fok",
          "chinese": null
        }
      ],
      "published": "2026-01-30T10:42:10Z",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "primaryCategory": "cs.LG",
      "pdfUrl": "https://arxiv.org/pdf/2601.22816v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22816v1",
      "keyInfo": {
        "contributions": [
          "We first generate a low-resolution version of a tabular data row, that is, the collection of the purely categorical features and a coarse categorical representation of numerical features",
          "The low-resolution representation of numerical features explicitly accounts for discrete outcomes, such as missing or inflated values, and therewith enables a more faithful generation of mixed-type features"
        ],
        "methods": [],
        "applications": [
          "The low-resolution representation of numerical features explicitly accounts for discrete outcomes, such as missing or inflated values, and therewith enables a more faithful generation of mixed-type features"
        ]
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22784v1",
      "title": "Approximating $f$-Divergences with Rank Statistics",
      "originalTitle": "Approximating $f$-Divergences with Rank Statistics",
      "summary": "We introduce a rank-statistic approximation of -divergences that avoids explicit density-ratio estimation by working directly with the distribution of ranks. For a resolution parameter , we map the mismatch between two univariate distributions and to a rank histogram on and measure its deviation from uniformity via a discrete -divergence, yielding a rank-statistic divergence estimator. We prove th...",
      "plainSummary": "We introduce a rank-statistic approximation of -divergences that avoids explicit density-ratio estimation by working directly with the distribution of ranks. For a resolution parameter , we map the mismatch between two univariate distributions and to a rank histogram on and measure its deviation from uniformity via a discrete -divergence, yielding a rank-statistic divergence estimator. We prove that the resulting estimator of the divergence is monotone in , is always a lower bound of the true -divergence, and we establish quantitative convergence rates for under mild regularity of the quantile-domain density ratio. To handle high-dimensional data, we define the sliced rank-statistic -divergence by averaging the univariate construction over random projections, and we provide convergence results for the sliced limit as well. We also derive finite-sample deviation bounds along with asymptotic normality results for the estimator. Finally, we empirically validate the approach by benchmarking against neural baselines and illustrating its use as a learning objective in generative modelling experiments.",
      "oneSentenceSummary": "【stat.ML】Viktor Stein等Approximating $f$-Divergences with Rank Statistics，在stat.ML取得新进展。",
      "authors": [
        {
          "original": "Viktor Stein",
          "chinese": null
        },
        {
          "original": "José Manuel de Frutos",
          "chinese": null
        }
      ],
      "published": "2026-01-30T10:05:33Z",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primaryCategory": "stat.ML",
      "pdfUrl": "https://arxiv.org/pdf/2601.22784v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22784v1",
      "keyInfo": {
        "contributions": [
          "We introduce a rank-statistic approximation of $f$-divergences that avoids explicit density-ratio estimation by working directly with the distribution of ranks"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22771v1",
      "title": "GRANITE: A Generalized Regional 框架（提供结构的基础代码库） for Identifying Agreement in Feature-Based Explanations",
      "originalTitle": "GRANITE: A Generalized Regional Framework for Identifying Agreement in Feature-Based Explanations",
      "summary": "Feature-based explanation methods aim to quantify how features influence the model's behavior, either locally or globally, but different methods often disagree, producing conflicting explanations. This disagreement arises primarily from two sources: how feature interactions are handled and how feature dependencies are incorporated. We propose GRANITE, a generalized regional explanation 框架（提供结构的基础代...",
      "plainSummary": "Feature-based explanation methods aim to quantify how features influence the model's behavior, either locally or globally, but different methods often disagree, producing conflicting explanations. This disagreement arises primarily from two sources: how feature interactions are handled and how feature dependencies are incorporated. 我们提出 GRANITE, a generalized regional explanation 框架（提供结构的基础代码库） that partitions the feature space into regions where interaction and distribution influences are minimized. This approach aligns different explanation methods, yielding more consistent and 可解释的（能够解释其决策过程） explanations. GRANITE unifies existing regional approaches, extends them to feature groups, and introduces a recursive partitioning algorithm to estimate such regions. We demonstrate its effectiveness on real-world datasets, providing a practical tool for consistent and 可解释的（能够解释其决策过程） feature explanations.",
      "oneSentenceSummary": "【stat.ML】Julia Herbinger等GRANITE，在stat.ML取得新进展。",
      "authors": [
        {
          "original": "Julia Herbinger",
          "chinese": null
        },
        {
          "original": "Gabriel Laberge",
          "chinese": null
        },
        {
          "original": "Maximilian Muschalik",
          "chinese": null
        },
        {
          "original": "Yann Pequignot",
          "chinese": null
        },
        {
          "original": "Marvin N. Wright",
          "chinese": null
        },
        {
          "original": "Fabian Fumagalli",
          "chinese": null
        }
      ],
      "published": "2026-01-30T09:49:26Z",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primaryCategory": "stat.ML",
      "pdfUrl": "https://arxiv.org/pdf/2601.22771v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22771v1",
      "keyInfo": {
        "contributions": [
          "We propose GRANITE, a generalized regional explanation 框架（提供结构的基础代码库） that partitions the feature space into regions where interaction and distribution influences are minimized",
          "GRANITE unifies existing regional approaches, extends them to feature groups, and introduces a recursive partitioning algorithm to estimate such regions"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22689v1",
      "title": "Assistive Robots and Reasonable Work Assignment Reduce Perceived Stigma toward Persons with Disabilities",
      "originalTitle": "Assistive Robots and Reasonable Work Assignment Reduce Perceived Stigma toward Persons with Disabilities",
      "summary": "Robots are becoming more prominent in assisting persons with disabilities (PwD). Whilst there is broad consensus that robots can assist in mitigating physical impairments, the extent to which they can facilitate social inclusion remains equivocal. In fact, the exposed status of assisted workers could likewise lead to reduced or increased perceived stigma by other workers. We present a vignette stu...",
      "plainSummary": "Robots are becoming more prominent in assisting persons with disabilities (PwD). Whilst there is broad consensus that robots can assist in mitigating physical impairments, the extent to which they can facilitate social inclusion remains equivocal. In fact, the exposed status of assisted workers could likewise lead to reduced or increased perceived stigma by other workers. We present a vignette study on the perceived cognitive and behavioral stigma toward PwD in the workplace. We designed four experimental conditions depicting a coworker with an impairment in work scenarios: overburdened work, suitable work, and robot-assisted work only for the coworker, and an offer of robot-assisted work for everyone. Our results show that cognitive stigma is significantly reduced when the work task is adapted to the person's abilities or augmented by an assistive robot. In addition, offering robot-assisted work for everyone, in the sense of universal design, further reduces perceived cognitive stigma. Thus, we conclude that assistive robots reduce perceived cognitive stigma, thereby supporting the use of collaborative robots in work scenarios involving PwDs.",
      "oneSentenceSummary": "【cs.HC】Stina Klein等Assistive Robots and Reasonable Work Assignment Reduce Perceived Stigma toward Persons with Disabilities，在cs.HC取得新进展。",
      "authors": [
        {
          "original": "Stina Klein",
          "chinese": null
        },
        {
          "original": "Birgit Prodinger",
          "chinese": null
        },
        {
          "original": "Elisabeth André",
          "chinese": null
        },
        {
          "original": "Lars Mikelsons",
          "chinese": null
        },
        {
          "original": "Nils Mandischer",
          "chinese": null
        }
      ],
      "published": "2026-01-30T08:08:38Z",
      "categories": [
        "cs.HC",
        "cs.RO"
      ],
      "primaryCategory": "cs.HC",
      "pdfUrl": "https://arxiv.org/pdf/2601.22689v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22689v1",
      "keyInfo": {
        "contributions": [
          "We present a vignette study on the perceived cognitive and behavioral stigma toward PwD in the workplace",
          "We designed four experimental conditions depicting a coworker with an impairment in work scenarios: overburdened work, suitable work, and robot-assisted work only for the coworker, and an offer of robot-assisted work for everyone"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22686v1",
      "title": "FlyAware: Inertia-Aware Aerial Manipulation via Vision-Based Estimation and Post-Grasp Adaptation",
      "originalTitle": "FlyAware: Inertia-Aware Aerial Manipulation via Vision-Based Estimation and Post-Grasp Adaptation",
      "summary": "Aerial manipulators (AMs) are gaining increasing attention in automated transportation and emergency services due to their superior dexterity compared to conventional multirotor drones. However, their practical deployment is challenged by the complexity of time-varying inertial parameters, which are highly sensitive to payload variations and manipulator configurations. Inspired by human strategies...",
      "plainSummary": "Aerial manipulators (AMs) are gaining increasing attention in automated transportation and emergency services due to their superior dexterity compared to conventional multirotor drones. However, their practical deployment is challenged by the complexity of time-varying inertial parameters, which are highly sensitive to payload variations and manipulator configurations. Inspired by human strategies for interacting with unknown objects, this letter presents a 新颖的（创新的、前人未做过的） onboard 框架（提供结构的基础代码库） for 鲁棒的（对噪声和扰动不敏感） aerial manipulation. The proposed system integrates a vision-based pre-grasp inertia estimation module with a post-grasp adaptation mechanism, enabling real-time estimation and adaptation of inertial dynamics. For control, we develop an inertia-aware adaptive control strategy based on gain scheduling, and assess its robustness via frequency-domain system identification. Our study provides new insights into post-grasp control for AMs, and real-world experiments validate the effectiveness and feasibility of the proposed 框架（提供结构的基础代码库）.",
      "oneSentenceSummary": "【cs.RO】Biyu Ye等FlyAware，使用For control, we develop an ine...，在cs.RO取得新进展。",
      "authors": [
        {
          "original": "Biyu Ye",
          "chinese": null
        },
        {
          "original": "Na Fan",
          "chinese": null
        },
        {
          "original": "Zhengping Fan",
          "chinese": null
        },
        {
          "original": "Weiliang Deng",
          "chinese": null
        },
        {
          "original": "Hongming Chen",
          "chinese": null
        },
        {
          "original": "Qifeng Chen",
          "chinese": null
        },
        {
          "original": "Ximin Lyu",
          "chinese": null
        }
      ],
      "published": "2026-01-30T08:02:33Z",
      "categories": [
        "cs.RO"
      ],
      "primaryCategory": "cs.RO",
      "pdfUrl": "https://arxiv.org/pdf/2601.22686v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22686v1",
      "keyInfo": {
        "contributions": [
          "Inspired by human strategies for interacting with unknown objects, this letter presents a 新颖的（创新的、前人未做过的） onboard 框架（提供结构的基础代码库） for 鲁棒的（对噪声和扰动不敏感） aerial manipulation",
          "The proposed system integrates a vision-based pre-grasp inertia estimation module with a post-grasp adaptation mechanism, enabling real-time estimation and adaptation of inertial dynamics"
        ],
        "methods": [
          "For control, we develop an inertia-aware adaptive control strategy based on gain scheduling, and assess its robustness via frequency-domain system identification"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22672v1",
      "title": "Postural Virtual Fixtures for Ergonomic Physical Interactions with Supernumerary Robotic Bodies",
      "originalTitle": "Postural Virtual Fixtures for Ergonomic Physical Interactions with Supernumerary Robotic Bodies",
      "summary": "Conjoined collaborative robots, functioning as supernumerary robotic bodies (SRBs), can enhance human load tolerance abilities. However, in tasks involving physical interaction with humans, users may still adopt awkward, non-ergonomic postures, which can lead to discomfort or injury over time. In this paper, we propose a 新颖的（创新的、前人未做过的） control 框架（提供结构的基础代码库） that provides kinesthetic feedback to ...",
      "plainSummary": "Conjoined collaborative robots, functioning as supernumerary robotic bodies (SRBs), can enhance human load tolerance abilities. However, in tasks involving physical interaction with humans, users may still adopt awkward, non-ergonomic postures, which can lead to discomfort or injury over time. In this paper, 我们提出 a 新颖的（创新的、前人未做过的） control 框架（提供结构的基础代码库） that provides kinesthetic feedback to SRB users when a non-ergonomic posture is detected, offering resistance to discourage such behaviors. This approach aims to foster long-term learning of ergonomic habits and promote proper posture during physical interactions. To achieve this, a virtual fixture method is developed, integrated with a continuous, online ergonomic posture assessment 框架（提供结构的基础代码库）. Additionally, to improve coordination between the operator and the SRB, which consists of a robotic arm mounted on a floating base, the position of the floating base is adjusted as needed. Experimental results demonstrate the functionality and efficacy of the ergonomics-driven control 框架（提供结构的基础代码库）, including two user studies involving practical loco-manipulation tasks with 14 subjects, comparing the proposed 框架（提供结构的基础代码库） with a 基线（用于对比的基准方法） control 框架（提供结构的基础代码库） that does not account for human ergonomics.",
      "oneSentenceSummary": "【cs.RO】Theodora Kastritsi等Postural Virtual Fixtures for Ergonomic Physical Interactions with Supernumerary Robotic Bodies，在cs.RO取得新进展。",
      "authors": [
        {
          "original": "Theodora Kastritsi",
          "chinese": null
        },
        {
          "original": "Marta Lagomarsino",
          "chinese": null
        },
        {
          "original": "Arash Ajoudani",
          "chinese": null
        }
      ],
      "published": "2026-01-30T07:44:41Z",
      "categories": [
        "cs.RO"
      ],
      "primaryCategory": "cs.RO",
      "pdfUrl": "https://arxiv.org/pdf/2601.22672v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22672v1",
      "keyInfo": {
        "contributions": [
          "In this paper, we propose a 新颖的（创新的、前人未做过的） control 框架（提供结构的基础代码库） that provides kinesthetic feedback to SRB users when a non-ergonomic posture is detected, offering resistance to discourage such behaviors",
          "To achieve this, a virtual fixture method is developed, integrated with a continuous, online ergonomic posture assessment 框架（提供结构的基础代码库）"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22652v1",
      "title": "Spectral 梯度下降（通过计算梯度来最小化损失函数的优化方法） Mitigates Anisotropy-Driven Misalignment: A Case Study in Phase Retrieval",
      "originalTitle": "Spectral Gradient Descent Mitigates Anisotropy-Driven Misalignment: A Case Study in Phase Retrieval",
      "summary": "Spectral gradient methods, such as the Muon optimizer, modify gradient updates by preserving directional information while discarding scale, and have shown strong 经验性的（基于实验和观察的） performance in 深度学习（使用多层神经网络来处理复杂模式的技术）. We investigate the mechanisms underlying these gains through a dynamical analysis of a nonlinear phase retrieval model with anisotropic Gaussian inputs, equivalent to training a two...",
      "plainSummary": "Spectral gradient methods, such as the Muon optimizer, modify gradient updates by preserving directional information while discarding scale, and have shown strong 经验性的（基于实验和观察的） performance in 深度学习（使用多层神经网络来处理复杂模式的技术）. We investigate the mechanisms underlying these gains through a dynamical analysis of a nonlinear phase retrieval model with anisotropic Gaussian inputs, equivalent to training a two-layer 神经网络（一种受人脑启发的计算模型，由许多互相连接的节点组成） with the quadratic activation and fixed second-layer weights. Focusing on a spiked covariance setting where the dominant variance direction is orthogonal to the signal, we show that 梯度下降（通过计算梯度来最小化损失函数的优化方法） (GD) suffers from a variance-induced misalignment: during the early escaping stage, the high-variance but uninformative spike direction is multiplicatively amplified, degrading alignment with the true signal under strong anisotropy. In contrast, spectral 梯度下降（通过计算梯度来最小化损失函数的优化方法） (SpecGD) removes this spike amplification effect, leading to stable alignment and accelerated noise contraction. Numerical experiments confirm the theory and show that these phenomena persist under broader anisotropic covariances.",
      "oneSentenceSummary": "【stat.ML】Guillaume Braun等Spectral Gradient Descent Mitigates Anisotropy-Driven Misalignment，使用Focusing on a spiked covarianc...，在stat.ML取得新进展。",
      "authors": [
        {
          "original": "Guillaume Braun",
          "chinese": null
        },
        {
          "original": "Han Bao",
          "chinese": null
        },
        {
          "original": "Wei Huang",
          "chinese": null
        },
        {
          "original": "Masaaki Imaizumi",
          "chinese": null
        }
      ],
      "published": "2026-01-30T07:12:58Z",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primaryCategory": "stat.ML",
      "pdfUrl": "https://arxiv.org/pdf/2601.22652v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22652v1",
      "keyInfo": {
        "contributions": [],
        "methods": [
          "Focusing on a spiked covariance setting where the dominant variance direction is orthogonal to the signal, we show that 梯度下降（通过计算梯度来最小化损失函数的优化方法） (GD) suffers from a variance-induced misalignment: during the early escaping stage, the high-variance but uninformative spike direction is multiplicatively amplified, degrading alignment with the true signal under strong anisotropy"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22650v1",
      "title": "Generative and Nonparametric Approaches for Conditional Distribution Estimation: Methods, Perspectives, and Comparative Evaluations",
      "originalTitle": "Generative and Nonparametric Approaches for Conditional Distribution Estimation: Methods, Perspectives, and Comparative Evaluations",
      "summary": "The inference of conditional distributions is a fundamental problem in statistics, essential for prediction, uncertainty quantification, and probabilistic modeling. A wide range of methodologies have been developed for this task. This article reviews and compares several representative approaches spanning classical nonparametric methods and modern generative models. We begin with the single-index ...",
      "plainSummary": "The inference of conditional distributions is a fundamental problem in statistics, essential for prediction, uncertainty quantification, and probabilistic modeling. A wide range of methodologies have been developed for this task. This article reviews and compares several representative approaches spanning classical nonparametric methods and modern generative models. We begin with the single-index method of Hall and Yao (2005), which estimates the conditional distribution through a dimension-reducing index and nonparametric smoothing of the resulting one-dimensional cumulative conditional distribution function. We then examine the basis-expansion approaches, including FlexCode (Izbicki and Lee, 2017) and DeepCDE (Dalmasso et al., 2020), which convert conditional density estimation into a set of nonparametric regression problems. In addition, we discuss two recent generative simulation-based methods that leverage modern deep generative architectures: the generative conditional distribution sampler (Zhou et al., 2023) and the conditional denoising diffusion probabilistic model (Fu et al., 2024; Yang et al., 2025). A systematic numerical comparison of these approaches is provided using a unified evaluation 框架（提供结构的基础代码库） that ensures fairness and reproducibility. The performance metrics used for the estimated conditional distribution include the mean-squared errors of conditional mean and standard deviation, as well as the Wasserstein distance. We also discuss their flexibility and computational costs, highlighting the distinct advantages and limitations of each approach.",
      "oneSentenceSummary": "【stat.ML】Yen-Shiu Chin等Generative and Nonparametric Approaches for Conditional Distribution Estimation，使用A systematic numerical compari...，在stat.ML取得新进展。",
      "authors": [
        {
          "original": "Yen-Shiu Chin",
          "chinese": null
        },
        {
          "original": "Zhi-Yu Jou",
          "chinese": null
        },
        {
          "original": "Toshinari Morimoto",
          "chinese": null
        },
        {
          "original": "Chia-Tse Wang",
          "chinese": null
        },
        {
          "original": "Ming-Chung Chang",
          "chinese": null
        },
        {
          "original": "Tso-Jung Yen",
          "chinese": null
        },
        {
          "original": "Su-Yun Huang",
          "chinese": null
        },
        {
          "original": "Tailen Hsing",
          "chinese": null
        }
      ],
      "published": "2026-01-30T07:10:36Z",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primaryCategory": "stat.ML",
      "pdfUrl": "https://arxiv.org/pdf/2601.22650v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22650v1",
      "keyInfo": {
        "contributions": [
          "A wide range of methodologies have been developed for this task",
          "This article reviews and compares several representative approaches spanning classical nonparametric methods and modern generative models"
        ],
        "methods": [
          "A systematic numerical comparison of these approaches is provided using a unified evaluation 框架（提供结构的基础代码库） that ensures fairness and reproducibility"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22625v1",
      "title": "RPWithPrior: Label Differential Privacy in Regression",
      "originalTitle": "RPWithPrior: Label Differential Privacy in Regression",
      "summary": "With the wide application of 机器学习（让计算机通过数据自动学习和改进的技术） techniques in practice, privacy preservation has gained increasing attention. Protecting user privacy with minimal 准确率（正确预测占总预测的比例） loss is a fundamental task in the data analysis and mining community. In this paper, we focus on regression tasks under -label differential privacy guarantees. Some existing methods for regression with -label diffe...",
      "plainSummary": "With the wide application of 机器学习（让计算机通过数据自动学习和改进的技术） techniques in practice, privacy preservation has gained increasing attention. Protecting user privacy with minimal 准确率（正确预测占总预测的比例） loss is a fundamental task in the data analysis and mining community. In this paper, we focus on regression tasks under -label differential privacy guarantees. Some existing methods for regression with -label differential privacy, such as the RR-On-Bins mechanism, discretized the output space into finite bins and then applied RR algorithm. To efficiently determine these finite bins, the authors rounded the original responses down to integer values. However, such operations does not align well with real-world scenarios. To overcome these limitations, we model both original and randomized responses as continuous random variables, avoiding discretization entirely. Our 新颖的（创新的、前人未做过的） approach estimates an optimal interval for randomized responses and introduces new algorithms designed for scenarios where a 先验概率（观察到数据前的概率） is either known or unknown. Additionally, we prove that our algorithm, RPWithPrior, guarantees -label differential privacy. Numerical results demonstrate that our approach gets better performance compared with the Gaussian, Laplace, Staircase, and RRonBins, Unbiased mechanisms on the Communities and Crime, Criteo Sponsored Search Conversion Log, California Housing datasets.",
      "oneSentenceSummary": "【stat.ML】Haixia Liu等RPWithPrior，使用Numerical results demonstrate ...，在stat.ML取得新进展。",
      "authors": [
        {
          "original": "Haixia Liu",
          "chinese": null
        },
        {
          "original": "Ruifan Huang",
          "chinese": null
        }
      ],
      "published": "2026-01-30T06:27:13Z",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primaryCategory": "stat.ML",
      "pdfUrl": "https://arxiv.org/pdf/2601.22625v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22625v1",
      "keyInfo": {
        "contributions": [
          "Our 新颖的（创新的、前人未做过的） approach estimates an optimal interval for randomized responses and introduces new algorithms designed for scenarios where a 先验概率（观察到数据前的概率） is either known or unknown"
        ],
        "methods": [
          "Numerical results demonstrate that our approach gets better performance compared with the Gaussian, Laplace, Staircase, and RRonBins, Unbiased mechanisms on the Communities and Crime, Criteo Sponsored Search Conversion Log, California Housing datasets"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22624v1",
      "title": "COBRA++: Enhanced COBRA Optimizer with Augmented Surrogate Pool and Reinforced Surrogate Selection",
      "originalTitle": "COBRA++: Enhanced COBRA Optimizer with Augmented Surrogate Pool and Reinforced Surrogate Selection",
      "summary": "The 优化（寻找最佳参数或解决方案的过程） problems in realistic world present significant challenges onto 优化（寻找最佳参数或解决方案的过程） algorithms, such as the expensive evaluation issue and complex constraint conditions. COBRA optimizer (including its up-to-date variants) is a representative and effective tool for addressing such 优化（寻找最佳参数或解决方案的过程） problems, which introduces 1) RBF surrogate to reduce online evaluation and 2)...",
      "plainSummary": "The 优化（寻找最佳参数或解决方案的过程） problems in realistic world present significant challenges onto 优化（寻找最佳参数或解决方案的过程） algorithms, such as the expensive evaluation issue and complex constraint conditions. COBRA optimizer (including its up-to-date variants) is a representative and effective tool for addressing such 优化（寻找最佳参数或解决方案的过程） problems, which introduces 1) RBF surrogate to reduce online evaluation and 2) bi-stage 优化（寻找最佳参数或解决方案的过程） process to alternate search for feasible solution and optimal solution. Though promising, its design space, i.e., surrogate model pool and selection standard, is still manually decided by human expert, resulting in labor-intensive 微调（在预训练模型基础上进行小幅调整） for 新颖的（创新的、前人未做过的） tasks. In this paper, 我们提出 a learning-based adaptive strategy (COBRA++) that enhances COBRA in two aspects: 1) An augmented surrogate pool to break the tie with RBF-like surrogate and hence enhances model diversity and approximation capability; 2) A 强化学习（通过试错学习最佳策略的机器学习方法）-based online model selection policy that empowers 高效的（速度快、资源消耗少） and accurate 优化（寻找最佳参数或解决方案的过程） process. The model selection policy is trained to maximize overall performance of COBRA++ across a distribution of constrained 优化（寻找最佳参数或解决方案的过程） problems with diverse properties. We have conducted multi-dimensional validation experiments and demonstrate that COBRA++ achieves substantial performance improvement against vanilla COBRA and its adaptive variant. Ablation studies are provided to support correctness of each design component in COBRA++.",
      "oneSentenceSummary": "【cs.NE】Zepei Yu等COBRA++，使用In this paper, we propose a le...，在cs.NE取得新进展。",
      "authors": [
        {
          "original": "Zepei Yu",
          "chinese": null
        },
        {
          "original": "Zhiyang Huang",
          "chinese": null
        },
        {
          "original": "Hongshu Guo",
          "chinese": null
        },
        {
          "original": "Yue-Jiao Gong",
          "chinese": null
        },
        {
          "original": "Zeyuan Ma",
          "chinese": null
        }
      ],
      "published": "2026-01-30T06:27:10Z",
      "categories": [
        "cs.NE"
      ],
      "primaryCategory": "cs.NE",
      "pdfUrl": "https://arxiv.org/pdf/2601.22624v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22624v1",
      "keyInfo": {
        "contributions": [
          "The 优化（寻找最佳参数或解决方案的过程） problems in realistic world present significant challenges onto 优化（寻找最佳参数或解决方案的过程） algorithms, such as the expensive evaluation issue and complex constraint conditions",
          "COBRA optimizer (including its up-to-date variants) is a representative and effective tool for addressing such 优化（寻找最佳参数或解决方案的过程） problems, which introduces 1) RBF surrogate to reduce online evaluation and 2) bi-stage 优化（寻找最佳参数或解决方案的过程） process to alternate search for feasible solution and optimal solution"
        ],
        "methods": [
          "In this paper, we propose a learning-based adaptive strategy (COBRA++) that enhances COBRA in two aspects: 1) An augmented surrogate pool to break the tie with RBF-like surrogate and hence enhances model diversity and approximation capability; 2) A 强化学习（通过试错学习最佳策略的机器学习方法）-based online model selection policy that empowers 高效的（速度快、资源消耗少） and accurate 优化（寻找最佳参数或解决方案的过程） process"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22600v1",
      "title": "An 高效的（速度快、资源消耗少） Algorithm for Thresholding Monte Carlo Tree Search",
      "originalTitle": "An Efficient Algorithm for Thresholding Monte Carlo Tree Search",
      "summary": "We introduce the Thresholding Monte Carlo Tree Search problem, in which, given a tree and a threshold , a player must answer whether the root node value of is at least or not. In the given tree, `MAX' or `MIN' is labeled on each internal node, and the value of a `MAX'-labeled (`MIN'-labeled) internal node is the maximum (minimum) of its child values. The value of a leaf node is the mean reward of ...",
      "plainSummary": "We introduce the Thresholding Monte Carlo Tree Search problem, in which, given a tree and a threshold , a player must answer whether the root node value of is at least or not. In the given tree, `MAX' or `MIN' is labeled on each internal node, and the value of a `MAX'-labeled (`MIN'-labeled) internal node is the maximum (minimum) of its child values. The value of a leaf node is the mean reward of an unknown distribution, from which the player can sample rewards. For this problem, we develop a -correct sequential sampling algorithm based on the Track-and-Stop strategy that has asymptotically optimal sample complexity. We show that a ratio-based modification of the D-Tracking arm-pulling strategy leads to a substantial improvement in 经验性的（基于实验和观察的） sample complexity, as well as reducing the per-round computational cost from linear to logarithmic in the number of arms.",
      "oneSentenceSummary": "【stat.ML】Shoma Nameki等An Efficient Algorithm for Thresholding Monte Carlo Tree Search，使用For this problem, we develop a...，在stat.ML取得新进展。",
      "authors": [
        {
          "original": "Shoma Nameki",
          "chinese": null
        },
        {
          "original": "Atsuyoshi Nakamura",
          "chinese": null
        },
        {
          "original": "Junpei Komiyama",
          "chinese": null
        },
        {
          "original": "Koji Tabata",
          "chinese": null
        }
      ],
      "published": "2026-01-30T05:50:04Z",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primaryCategory": "stat.ML",
      "pdfUrl": "https://arxiv.org/pdf/2601.22600v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22600v1",
      "keyInfo": {
        "contributions": [
          "We introduce the Thresholding Monte Carlo Tree Search problem, in which, given a tree $\\mathcal{T}$ and a threshold $θ$, a player must answer whether the root node value of $\\mathcal{T}$ is at least $θ$ or not",
          "For this problem, we develop a $δ$-correct sequential sampling algorithm based on the Track-and-Stop strategy that has asymptotically optimal sample complexity"
        ],
        "methods": [
          "For this problem, we develop a $δ$-correct sequential sampling algorithm based on the Track-and-Stop strategy that has asymptotically optimal sample complexity"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22550v1",
      "title": "Exo-Plore: Exploring Exoskeleton Control Space through Human-aligned Simulation",
      "originalTitle": "Exo-Plore: Exploring Exoskeleton Control Space through Human-aligned Simulation",
      "summary": "Exoskeletons show great promise for enhancing mobility, but providing appropriate assistance remains challenging due to the complexity of human adaptation to external forces. Current 最先进（当前最好的、领先的方法） approaches for optimizing exoskeleton controllers require extensive human experiments in which participants must walk for hours, creating a paradox: those who could benefit most from exoskeleton assis...",
      "plainSummary": "Exoskeletons show great promise for enhancing mobility, but providing appropriate assistance remains challenging due to the complexity of human adaptation to external forces. Current 最先进（当前最好的、领先的方法） approaches for optimizing exoskeleton controllers require extensive human experiments in which participants must walk for hours, creating a paradox: those who could benefit most from exoskeleton assistance, such as individuals with mobility impairments, are rarely able to participate in such demanding procedures. We present Exo-plore, a simulation 框架（提供结构的基础代码库） that combines neuromechanical simulation with deep 强化学习（通过试错学习最佳策略的机器学习方法） to optimize hip exoskeleton assistance without requiring real human experiments. Exo-plore can (1) generate realistic gait data that captures human adaptation to assistive forces, (2) produce reliable 优化（寻找最佳参数或解决方案的过程） results despite the stochastic nature of human gait, and (3) generalize to pathological gaits, showing strong linear relationships between pathology severity and optimal assistance.",
      "oneSentenceSummary": "【cs.RO】Geonho Leem等Exo-Plore，在cs.RO取得新进展。",
      "authors": [
        {
          "original": "Geonho Leem",
          "chinese": null
        },
        {
          "original": "Jaedong Lee",
          "chinese": null
        },
        {
          "original": "Jehee Lee",
          "chinese": null
        },
        {
          "original": "Seungmoon Song",
          "chinese": null
        },
        {
          "original": "Jungdam Won",
          "chinese": null
        }
      ],
      "published": "2026-01-30T04:45:35Z",
      "categories": [
        "cs.RO",
        "cs.GR",
        "cs.LG"
      ],
      "primaryCategory": "cs.RO",
      "pdfUrl": "https://arxiv.org/pdf/2601.22550v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22550v1",
      "keyInfo": {
        "contributions": [
          "We present Exo-plore, a simulation 框架（提供结构的基础代码库） that combines neuromechanical simulation with deep 强化学习（通过试错学习最佳策略的机器学习方法） to optimize hip exoskeleton assistance without requiring real human experiments"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22545v1",
      "title": "Adapting 强化学习（通过试错学习最佳策略的机器学习方法） for Path Planning in Constrained Parking Scenarios",
      "originalTitle": "Adapting Reinforcement Learning for Path Planning in Constrained Parking Scenarios",
      "summary": "Real-time path planning in constrained environments remains a fundamental challenge for autonomous systems. Traditional classical planners, while effective under perfect perception assumptions, are often sensitive to real-world perception constraints and rely on online search procedures that incur high computational costs. In complex surroundings, this renders real-time deployment prohibitive. To ...",
      "plainSummary": "Real-time path planning in constrained environments remains a fundamental challenge for autonomous systems. Traditional classical planners, while effective under perfect perception assumptions, are often sensitive to real-world perception constraints and rely on online search procedures that incur high computational costs. In complex surroundings, this renders real-time deployment prohibitive. To overcome these limitations, we introduce a Deep 强化学习（通过试错学习最佳策略的机器学习方法） (DRL) 框架（提供结构的基础代码库） for real-time path planning in parking scenarios. In particular, we focus on challenging scenes with tight spaces that require a high number of reversal maneuvers and adjustments. Unlike classical planners, our solution does not require ideal and structured perception, and in principle, could avoid the need for additional modules such as localization and tracking, resulting in a simpler and more practical implementation. Also, at test time, the policy generates actions through a single forward pass at each step, which is lightweight enough for real-time deployment. The task is formulated as a sequential decision-making problem grounded in a bicycle model dynamics, enabling the agent to directly learn navigation policies that respect vehicle kinematics and environmental constraints in the closed-loop setting. A new 基准（用于比较性能的标准数据集或方法） is developed to support both training and evaluation, capturing diverse and challenging scenarios. Our approach achieves 最先进（当前最好的、领先的方法） success rates and efficiency, surpassing classical planner baselines by +96% in success rate and +52% in efficiency. Furthermore, we release our 基准（用于比较性能的标准数据集或方法） as an open-source resource for the community to foster future research in autonomous systems. The 基准（用于比较性能的标准数据集或方法） and accompanying tools are available at https://github.com/dqm5rtfg9b-collab/Constrained_Parking_Scenarios.",
      "oneSentenceSummary": "【cs.RO】Feng Tao等Adapting Reinforcement Learning for Path Planning in Constrained Parking Scenarios，在cs.RO取得新进展。",
      "authors": [
        {
          "original": "Feng Tao",
          "chinese": null
        },
        {
          "original": "Luca Paparusso",
          "chinese": null
        },
        {
          "original": "Chenyi Gu",
          "chinese": null
        },
        {
          "original": "Robin Koehler",
          "chinese": null
        },
        {
          "original": "Chenxu Wu",
          "chinese": null
        },
        {
          "original": "Xinyu Huang",
          "chinese": null
        },
        {
          "original": "Christian Juette",
          "chinese": null
        },
        {
          "original": "David Paz",
          "chinese": null
        },
        {
          "original": "Ren Liu",
          "chinese": null
        }
      ],
      "published": "2026-01-30T04:35:49Z",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primaryCategory": "cs.RO",
      "pdfUrl": "https://arxiv.org/pdf/2601.22545v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22545v1",
      "keyInfo": {
        "contributions": [
          "To overcome these limitations, we introduce a Deep 强化学习（通过试错学习最佳策略的机器学习方法） (DRL) 框架（提供结构的基础代码库） for real-time path planning in parking scenarios",
          "A new 基准（用于比较性能的标准数据集或方法） is developed to support both training and evaluation, capturing diverse and challenging scenarios"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22542v1",
      "title": "Detect and Act: Automated Dynamic Optimizer through Meta-Black-Box 优化（寻找最佳参数或解决方案的过程）",
      "originalTitle": "Detect and Act: Automated Dynamic Optimizer through Meta-Black-Box Optimization",
      "summary": "Dynamic 优化（寻找最佳参数或解决方案的过程） Problems (DOPs) are challenging to address due to their complex nature, i.e., dynamic environment variation. Evolutionary Computation methods are generally advantaged in solving DOPs since they resemble dynamic biological evolution. However, existing evolutionary dynamic 优化（寻找最佳参数或解决方案的过程） methods rely heavily on human-crafted adaptive strategy to detect environment vari...",
      "plainSummary": "Dynamic 优化（寻找最佳参数或解决方案的过程） Problems (DOPs) are challenging to address due to their complex nature, i.e., dynamic environment variation. Evolutionary Computation methods are generally advantaged in solving DOPs since they resemble dynamic biological evolution. However, existing evolutionary dynamic 优化（寻找最佳参数或解决方案的过程） methods rely heavily on human-crafted adaptive strategy to detect environment variation in DOPs, and then adapt the searching strategy accordingly. These hand-crafted strategies may perform ineffectively at out-of-box scenarios. In this paper, 我们提出 a 强化学习（通过试错学习最佳策略的机器学习方法）-assisted approach to enable automated variation detection and self-adaption in evolutionary algorithms. This is achieved by borrowing the bi-level learning-to-optimize idea from recent Meta-Black-Box 优化（寻找最佳参数或解决方案的过程） works. We use a deep Q-network as 优化（寻找最佳参数或解决方案的过程） dynamics detector and searching strategy adapter: It is fed as input with current-step 优化（寻找最佳参数或解决方案的过程） state and then dictates desired control parameters to underlying evolutionary algorithms for next-step 优化（寻找最佳参数或解决方案的过程）. The learning objective is to maximize the expected performance gain across a problem distribution. Once trained, our approach could generalize toward unseen DOPs with automated environment variation detection and self-adaption. To facilitate 全面的（覆盖广泛的、详细的） validation, we further construct an easy-to-difficult DOPs testbed with diverse synthetic instances. Extensive 基准（用于比较性能的标准数据集或方法） results demonstrate flexible searching behavior and superior performance of our approach in solving DOPs, compared to 最先进（当前最好的、领先的方法） baselines.",
      "oneSentenceSummary": "【cs.NE】Zijian Gao等Detect and Act，在cs.NE取得新进展。",
      "authors": [
        {
          "original": "Zijian Gao",
          "chinese": null
        },
        {
          "original": "Yuanting Zhong",
          "chinese": null
        },
        {
          "original": "Zeyuan Ma",
          "chinese": null
        },
        {
          "original": "Yue-Jiao Gong",
          "chinese": null
        },
        {
          "original": "Hongshu Guo",
          "chinese": null
        }
      ],
      "published": "2026-01-30T04:28:27Z",
      "categories": [
        "cs.NE",
        "cs.LG"
      ],
      "primaryCategory": "cs.NE",
      "pdfUrl": "https://arxiv.org/pdf/2601.22542v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22542v1",
      "keyInfo": {
        "contributions": [
          "In this paper, we propose a 强化学习（通过试错学习最佳策略的机器学习方法）-assisted approach to enable automated variation detection and self-adaption in evolutionary algorithms"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22539v1",
      "title": "Neural-Inspired 后验概率（观察到数据后的概率） Approximation (NIPA)",
      "originalTitle": "Neural-Inspired Posterior Approximation (NIPA)",
      "summary": "Humans learn efficiently from their environment by engaging multiple interacting neural systems that support distinct yet complementary forms of control, including model-based (goal-directed) planning, model-free (habitual) responding, and episodic memory-based learning. Model-based mechanisms compute prospective action values using an internal model of the environment, supporting flexible but com...",
      "plainSummary": "Humans learn efficiently from their environment by engaging multiple interacting neural systems that support distinct yet complementary forms of control, including model-based (goal-directed) planning, model-free (habitual) responding, and episodic memory-based learning. Model-based mechanisms compute prospective action values using an internal model of the environment, supporting flexible but computationally costly planning; model-free mechanisms cache value estimates and build heuristics that enable fast, 高效的（速度快、资源消耗少） habitual responding; and memory-based mechanisms allow rapid adaptation from individual experience. In this work, we aim to elucidate the computational principles underlying this biological efficiency and translate them into a sampling algorithm for 可扩展的（能够处理更大规模数据） Bayesian inference through effective exploration of the 后验概率（观察到数据后的概率） distribution. More specifically, our proposed algorithm comprises three components: a model-based module that uses the target distribution for guided but computationally slow sampling; a model-free module that uses previous samples to learn patterns in the parameter space, enabling fast, reflexive sampling without directly evaluating the expensive target distribution; and an episodic-control module that supports rapid sampling by recalling specific past events (i.e., samples). We show that this approach advances Bayesian methods and facilitates their application to large-scale statistical 机器学习（让计算机通过数据自动学习和改进的技术） problems. In particular, we apply our proposed 框架（提供结构的基础代码库） to Bayesian 深度学习（使用多层神经网络来处理复杂模式的技术）, with an emphasis on proper and principled uncertainty quantification.",
      "oneSentenceSummary": "【cs.LG】Babak Shahbaba等Neural-Inspired Posterior Approximation (NIPA)，使用Model-based mechanisms compute...，在cs.LG取得新进展。",
      "authors": [
        {
          "original": "Babak Shahbaba",
          "chinese": null
        },
        {
          "original": "Zahra Moslemi",
          "chinese": null
        }
      ],
      "published": "2026-01-30T04:19:26Z",
      "categories": [
        "cs.LG",
        "stat.CO",
        "stat.ML"
      ],
      "primaryCategory": "cs.LG",
      "pdfUrl": "https://arxiv.org/pdf/2601.22539v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22539v1",
      "keyInfo": {
        "contributions": [
          "More specifically, our proposed algorithm comprises three components: a model-based module that uses the target distribution for guided but computationally slow sampling; a model-free module that uses previous samples to learn patterns in the parameter space, enabling fast, reflexive sampling without directly evaluating the expensive target distribution; and an episodic-control module that supports rapid sampling by recalling specific past events (i",
          "In particular, we apply our proposed 框架（提供结构的基础代码库） to Bayesian 深度学习（使用多层神经网络来处理复杂模式的技术）, with an emphasis on proper and principled uncertainty quantification"
        ],
        "methods": [
          "Model-based mechanisms compute prospective action values using an internal model of the environment, supporting flexible but computationally costly planning; model-free mechanisms cache value estimates and build heuristics that enable fast, 高效的（速度快、资源消耗少） habitual responding; and memory-based mechanisms allow rapid adaptation from individual experience"
        ],
        "applications": [
          "We show that this approach advances Bayesian methods and facilitates their application to large-scale statistical 机器学习（让计算机通过数据自动学习和改进的技术） problems"
        ]
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22519v1",
      "title": "Corrected Samplers for Discrete Flow Models",
      "originalTitle": "Corrected Samplers for Discrete Flow Models",
      "summary": "Discrete flow models (DFMs) have been proposed to learn the data distribution on a finite state space, offering a flexible 框架（提供结构的基础代码库） as an alternative to discrete diffusion models. A line of recent work has studied samplers for discrete diffusion models, such as tau-leaping and Euler solver. However, these samplers require a large number of iterations to control discretization error, since th...",
      "plainSummary": "Discrete flow models (DFMs) have been proposed to learn the data distribution on a finite state space, offering a flexible 框架（提供结构的基础代码库） as an alternative to discrete diffusion models. A line of recent work has studied samplers for discrete diffusion models, such as tau-leaping and Euler solver. However, these samplers require a large number of iterations to control discretization error, since the transition rates are frozen in time and evaluated at the initial state within each time interval. Moreover, 理论性的（基于数学推导的） results for these samplers often require boundedness conditions of the transition rate or they focus on a specific type of source distributions. To address those limitations, we establish non-asymptotic discretization error bounds for those samplers without any restriction on transition rates and source distributions, under the 框架（提供结构的基础代码库） of discrete flow models. Furthermore, by analyzing a one-step lower bound of the Euler sampler, 我们提出 two corrected samplers: \\textit{time-corrected sampler} and \\textit{location-corrected sampler}, which can reduce the discretization error of tau-leaping and Euler solver with almost no additional computational cost. We rigorously show that the location-corrected sampler has a lower iteration complexity than existing parallel samplers. We validate the effectiveness of the proposed method by demonstrating improved generation quality and reduced inference time on both simulation and text-to-image generation tasks. Code can be found in https://github.com/WanZhengyan/Corrected-Samplers-for-Discrete-Flow-Models.",
      "oneSentenceSummary": "【stat.ML】Zhengyan Wan等Corrected Samplers for Discrete Flow Models，在stat.ML取得新进展。",
      "authors": [
        {
          "original": "Zhengyan Wan",
          "chinese": null
        },
        {
          "original": "Yidong Ouyang",
          "chinese": null
        },
        {
          "original": "Liyan Xie",
          "chinese": null
        },
        {
          "original": "Fang Fang",
          "chinese": null
        },
        {
          "original": "Hongyuan Zha",
          "chinese": null
        },
        {
          "original": "Guang Cheng",
          "chinese": null
        }
      ],
      "published": "2026-01-30T03:53:22Z",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primaryCategory": "stat.ML",
      "pdfUrl": "https://arxiv.org/pdf/2601.22519v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22519v1",
      "keyInfo": {
        "contributions": [
          "Discrete flow models (DFMs) have been proposed to learn the data distribution on a finite state space, offering a flexible 框架（提供结构的基础代码库） as an alternative to discrete diffusion models",
          "Furthermore, by analyzing a one-step lower bound of the Euler sampler, we propose two corrected samplers: \\textit{time-corrected sampler} and \\textit{location-corrected sampler}, which can reduce the discretization error of tau-leaping and Euler solver with almost no additional computational cost"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22497v1",
      "title": "Fairness-Aware Performance Evaluation for Multi-Party Multi-Objective 优化（寻找最佳参数或解决方案的过程）",
      "originalTitle": "Fairness-Aware Performance Evaluation for Multi-Party Multi-Objective Optimization",
      "summary": "In multiparty multiobjective 优化（寻找最佳参数或解决方案的过程） problems, solution sets are usually evaluated using classical performance metrics, aggregated across DMs. However, such mean-based evaluations may be unfair by favoring certain parties, as they assume identical geometric approximation quality to each party's PF carries comparable evaluative significance. Moreover, prevailing notions of MPMOP optimal ...",
      "plainSummary": "In multiparty multiobjective 优化（寻找最佳参数或解决方案的过程） problems, solution sets are usually evaluated using classical performance metrics, aggregated across DMs. However, such mean-based evaluations may be unfair by favoring certain parties, as they assume identical geometric approximation quality to each party's PF carries comparable evaluative significance. Moreover, prevailing notions of MPMOP optimal solutions are restricted to strictly common Pareto optimal solutions, representing a narrow form of cooperation in multiparty decision making scenarios. These limitations obscure whether a solution set reflects balanced relative gains or meaningful consensus among heterogeneous DMs. To address these issues, this paper develops a fairness-aware performance evaluation 框架（提供结构的基础代码库） grounded in a generalized notion of consensus solutions. From a cooperative game-theoretic perspective, we formalize four axioms that a fairness-aware evaluation function for MPMOPs should satisfy. By introducing a concession rate vector to quantify acceptable compromises by individual DMs, we generalize the classical definition of MPMOP optimal solutions and embed classical performance metrics into a Nash-product-based evaluation 框架（提供结构的基础代码库）, which is theoretically shown to satisfy all axioms. To support 经验性的（基于实验和观察的） validation, we further construct 基准（用于比较性能的标准数据集或方法） problems that extend existing MPMOP suites by incorporating consensus-deficient negotiation structures. Experimental results demonstrate that the proposed evaluation 框架（提供结构的基础代码库） is able to distinguish algorithmic performance in a manner consistent with consensus-aware fairness considerations. Specifically, algorithms converging toward strictly common solutions are assigned higher evaluation scores when such solutions exist, whereas in the absence of strictly common solutions, algorithms that effectively cover the commonly acceptable region are more favorably evaluated.",
      "oneSentenceSummary": "【cs.NE】Zifan Zhao等Fairness-Aware Performance Evaluation for Multi-Party Multi-Objective Optimization，使用In multiparty multiobjective 优...，在cs.NE取得新进展。",
      "authors": [
        {
          "original": "Zifan Zhao",
          "chinese": null
        },
        {
          "original": "Peilan Xu",
          "chinese": null
        },
        {
          "original": "Wenjian Luo",
          "chinese": null
        }
      ],
      "published": "2026-01-30T03:09:58Z",
      "categories": [
        "cs.NE"
      ],
      "primaryCategory": "cs.NE",
      "pdfUrl": "https://arxiv.org/pdf/2601.22497v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22497v1",
      "keyInfo": {
        "contributions": [
          "Moreover, prevailing notions of MPMOP optimal solutions are restricted to strictly common Pareto optimal solutions, representing a narrow form of cooperation in multiparty decision making scenarios",
          "To address these issues, this paper develops a fairness-aware performance evaluation 框架（提供结构的基础代码库） grounded in a generalized notion of consensus solutions"
        ],
        "methods": [
          "In multiparty multiobjective 优化（寻找最佳参数或解决方案的过程） problems, solution sets are usually evaluated using classical performance metrics, aggregated across DMs"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22481v1",
      "title": "Changepoint Detection As Model Selection: A General 框架（提供结构的基础代码库）",
      "originalTitle": "Changepoint Detection As Model Selection: A General Framework",
      "summary": "This dissertation presents a general 框架（提供结构的基础代码库） for changepoint detection based on L0 model selection. The core method, Iteratively Reweighted Fused Lasso (IRFL), improves upon the generalized lasso by adaptively reweighting penalties to enhance support recovery and minimize criteria such as the Bayesian Information Criterion (BIC). The approach allows for flexible modeling of seasonal pattern...",
      "plainSummary": "This dissertation presents a general 框架（提供结构的基础代码库） for changepoint detection based on L0 model selection. The core method, Iteratively Reweighted Fused Lasso (IRFL), improves upon the generalized lasso by adaptively reweighting penalties to enhance support recovery and minimize criteria such as the Bayesian Information Criterion (BIC). The approach allows for flexible modeling of seasonal patterns, linear and quadratic trends, and autoregressive dependence in the presence of changepoints. Simulation studies demonstrate that IRFL achieves accurate changepoint detection across a wide range of challenging scenarios, including those involving nuisance factors such as trends, seasonal patterns, and serially correlated errors. The 框架（提供结构的基础代码库） is further extended to image data, where it enables edge-preserving denoising and segmentation, with applications spanning medical imaging and high-throughput plant phenotyping. Applications to real-world data demonstrate IRFL's utility. In particular, analysis of the Mauna Loa CO2 time series reveals changepoints that align with volcanic eruptions and ENSO events, yielding a more accurate trend decomposition than ordinary least squares. Overall, IRFL provides a 鲁棒的（对噪声和扰动不敏感）, extensible tool for detecting structural change in complex data.",
      "oneSentenceSummary": "【stat.ME】Michael Grantham等Changepoint Detection As Model Selection，使用This dissertation presents a g...，在stat.ME取得新进展。",
      "authors": [
        {
          "original": "Michael Grantham",
          "chinese": null
        },
        {
          "original": "Xueheng Shi",
          "chinese": null
        },
        {
          "original": "Bertrand Clarke",
          "chinese": null
        }
      ],
      "published": "2026-01-30T02:44:34Z",
      "categories": [
        "stat.ME",
        "stat.AP",
        "stat.ML"
      ],
      "primaryCategory": "stat.ME",
      "pdfUrl": "https://arxiv.org/pdf/2601.22481v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22481v1",
      "keyInfo": {
        "contributions": [
          "This dissertation presents a general 框架（提供结构的基础代码库） for changepoint detection based on L0 model selection"
        ],
        "methods": [
          "This dissertation presents a general 框架（提供结构的基础代码库） for changepoint detection based on L0 model selection"
        ],
        "applications": [
          "The 框架（提供结构的基础代码库） is further extended to image data, where it enables edge-preserving denoising and segmentation, with applications spanning medical imaging and high-throughput plant phenotyping"
        ]
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22443v1",
      "title": "Weak Diffusion Priors Can Still Achieve Strong Inverse-Problem Performance",
      "originalTitle": "Weak Diffusion Priors Can Still Achieve Strong Inverse-Problem Performance",
      "summary": "Can a diffusion model trained on bedrooms recover human faces? Diffusion models are widely used as priors for inverse problems, but standard approaches usually assume a high-fidelity model trained on data that closely match the unknown signal. In practice, one often must use a mismatched or low-fidelity diffusion 先验概率（观察到数据前的概率）. Surprisingly, these weak priors often perform nearly as well as full...",
      "plainSummary": "Can a diffusion model trained on bedrooms recover human faces? Diffusion models are widely used as priors for inverse problems, but standard approaches usually assume a high-fidelity model trained on data that closely match the unknown signal. In practice, one often must use a mismatched or low-fidelity diffusion 先验概率（观察到数据前的概率）. Surprisingly, these weak priors often perform nearly as well as full-strength, in-domain baselines. We study when and why inverse solvers are 鲁棒的（对噪声和扰动不敏感） to weak diffusion priors. Through 大量实验, we find that weak priors succeed when measurements are highly informative (e.g., many observed pixels), and we identify regimes where they fail. Our theory, based on Bayesian consistency, gives conditions under which high-dimensional measurements make the 后验概率（观察到数据后的概率） concentrate near the true signal. These results provide a principled justification on when weak diffusion priors can be used reliably.",
      "oneSentenceSummary": "【cs.LG】Jing Jia等Weak Diffusion Priors Can Still Achieve Strong Inverse-Problem Performance，使用Our theory, based on Bayesian ...，在cs.LG取得新进展。",
      "authors": [
        {
          "original": "Jing Jia",
          "chinese": null
        },
        {
          "original": "Wei Yuan",
          "chinese": null
        },
        {
          "original": "Sifan Liu",
          "chinese": null
        },
        {
          "original": "Liyue Shen",
          "chinese": null
        },
        {
          "original": "Guanyang Wang",
          "chinese": null
        }
      ],
      "published": "2026-01-30T01:25:54Z",
      "categories": [
        "cs.LG",
        "cs.CV",
        "stat.CO",
        "stat.ML"
      ],
      "primaryCategory": "cs.LG",
      "pdfUrl": "https://arxiv.org/pdf/2601.22443v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22443v1",
      "keyInfo": {
        "contributions": [],
        "methods": [
          "Our theory, based on Bayesian consistency, gives conditions under which high-dimensional measurements make the 后验概率（观察到数据后的概率） concentrate near the true signal"
        ],
        "applications": [
          "These results provide a principled justification on when weak diffusion priors can be used reliably"
        ]
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22241v1",
      "title": "Investigating the Interplay of Parameterization and Optimizer in Gradient-Free Topology 优化（寻找最佳参数或解决方案的过程）: A Cantilever Beam Case Study",
      "originalTitle": "Investigating the Interplay of Parameterization and Optimizer in Gradient-Free Topology Optimization: A Cantilever Beam Case Study",
      "summary": "Gradient-free black-box 优化（寻找最佳参数或解决方案的过程） (BBO) is widely used in engineering design and provides a flexible 框架（提供结构的基础代码库） for topology 优化（寻找最佳参数或解决方案的过程） (TO), enabling the discovery of high-performing structural designs without requiring gradient information from simulations. Yet, its success depends on two key choices: the geometric parameterization defining the search space and the optimizer...",
      "plainSummary": "Gradient-free black-box 优化（寻找最佳参数或解决方案的过程） (BBO) is widely used in engineering design and provides a flexible 框架（提供结构的基础代码库） for topology 优化（寻找最佳参数或解决方案的过程） (TO), enabling the discovery of high-performing structural designs without requiring gradient information from simulations. Yet, its success depends on two key choices: the geometric parameterization defining the search space and the optimizer exploring it. This study investigates this interplay through a compliance minimization problem for a cantilever beam subject to a connectivity constraint. We 基准（用于比较性能的标准数据集或方法） three geometric parameterizations, each combined with three representative BBO algorithms: differential evolution, covariance matrix adaptation evolution strategy, and heteroscedastic evolutionary Bayesian 优化（寻找最佳参数或解决方案的过程）, across 10D, 20D, and 50D design spaces. Results reveal that parameterization quality has a stronger influence on 优化（寻找最佳参数或解决方案的过程） performance than optimizer choice: a well-structured parameterization enables 鲁棒的（对噪声和扰动不敏感） and competitive performance across algorithms, whereas weaker representations increase optimizer dependency. Overall, this study highlights the dominant role of geometric parameterization in practical BBO-based TO and shows that algorithm performance and selection cannot be fairly assessed without accounting for the induced design space.",
      "oneSentenceSummary": "【cs.NE】Jelle Westra等Investigating the Interplay of Parameterization and Optimizer in Gradient-Free Topology Optimization，在cs.NE取得新进展。",
      "authors": [
        {
          "original": "Jelle Westra",
          "chinese": null
        },
        {
          "original": "Iván Olarte Rodríguez",
          "chinese": null
        },
        {
          "original": "Niki van Stein",
          "chinese": null
        },
        {
          "original": "Thomas Bäck",
          "chinese": null
        },
        {
          "original": "Elena Raponi",
          "chinese": null
        }
      ],
      "published": "2026-01-29T19:09:05Z",
      "categories": [
        "cs.NE",
        "cs.CE"
      ],
      "primaryCategory": "cs.NE",
      "pdfUrl": "https://arxiv.org/pdf/2601.22241v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22241v1",
      "keyInfo": {
        "contributions": [
          "Gradient-free black-box 优化（寻找最佳参数或解决方案的过程） (BBO) is widely used in engineering design and provides a flexible 框架（提供结构的基础代码库） for topology 优化（寻找最佳参数或解决方案的过程） (TO), enabling the discovery of high-performing structural designs without requiring gradient information from simulations",
          "We 基准（用于比较性能的标准数据集或方法） three geometric parameterizations, each combined with three representative BBO algorithms: differential evolution, covariance matrix adaptation evolution strategy, and heteroscedastic evolutionary Bayesian 优化（寻找最佳参数或解决方案的过程）, across 10D, 20D, and 50D design spaces"
        ],
        "methods": [],
        "applications": [
          "Results reveal that parameterization quality has a stronger influence on 优化（寻找最佳参数或解决方案的过程） performance than optimizer choice: a well-structured parameterization enables 鲁棒的（对噪声和扰动不敏感） and competitive performance across algorithms, whereas weaker representations increase optimizer dependency"
        ]
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.22075v1",
      "title": "Lens-descriptor guided evolutionary algorithm for 优化（寻找最佳参数或解决方案的过程） of complex optical systems with glass choice",
      "originalTitle": "Lens-descriptor guided evolutionary algorithm for optimization of complex optical systems with glass choice",
      "summary": "Designing high-performance optical lenses entails exploring a high-dimensional, tightly constrained space of surface curvatures, glass choices, element thicknesses, and spacings. In practice, standard optimizers (e.g., gradient-based local search and evolutionary strategies) often converge to a single local optimum, overlooking many comparably good alternatives that matter for downstream engineeri...",
      "plainSummary": "Designing high-performance optical lenses entails exploring a high-dimensional, tightly constrained space of surface curvatures, glass choices, element thicknesses, and spacings. In practice, standard optimizers (e.g., gradient-based local search and evolutionary strategies) often converge to a single local optimum, overlooking many comparably good alternatives that matter for downstream engineering decisions. 我们提出 the Lens Descriptor-Guided Evolutionary Algorithm (LDG-EA), a two-stage 框架（提供结构的基础代码库） for multimodal lens 优化（寻找最佳参数或解决方案的过程）. LDG-EA first partitions the design space into behavior descriptors defined by curvature-sign patterns and material indices, then learns a probabilistic model over descriptors to allocate evaluations toward promising regions. Within each descriptor, LDG-EA applies the Hill-Valley Evolutionary Algorithm with covariance-matrix self-adaptation to recover multiple distinct local minima, optionally followed by gradient-based refinement. On a 24-variable (18 continuous and 6 integer), six-element Double-Gauss topology, LDG-EA generates on average around 14500 candidate minima spanning 636 unique descriptors, an order of magnitude more than a CMA-ES 基线（用于对比的基准方法）, while keeping wall-clock time at one hour scale. Although the best LDG-EA design is slightly worse than a fine-tuned reference lens, it remains in the same performance range. Overall, the proposed LDG-EA produces a diverse set of solutions while maintaining competitive quality within practical computational budgets and wall-clock time.",
      "oneSentenceSummary": "【cs.NE】Kirill Antonov等Lens-descriptor guided evolutionary algorithm for optimization of complex optical systems with glass choice，使用Within each descriptor, LDG-EA...，在cs.NE取得新进展。",
      "authors": [
        {
          "original": "Kirill Antonov",
          "chinese": null
        },
        {
          "original": "Teus Tukker",
          "chinese": null
        },
        {
          "original": "Tiago Botari",
          "chinese": null
        },
        {
          "original": "Thomas H. W. Bäck",
          "chinese": null
        },
        {
          "original": "Anna V. Kononova",
          "chinese": null
        },
        {
          "original": "Niki van Stein",
          "chinese": null
        }
      ],
      "published": "2026-01-29T18:13:24Z",
      "categories": [
        "cs.NE"
      ],
      "primaryCategory": "cs.NE",
      "pdfUrl": "https://arxiv.org/pdf/2601.22075v1",
      "abstractUrl": "https://arxiv.org/abs/2601.22075v1",
      "keyInfo": {
        "contributions": [
          "Designing high-performance optical lenses entails exploring a high-dimensional, tightly constrained space of surface curvatures, glass choices, element thicknesses, and spacings",
          "We propose the Lens Descriptor-Guided Evolutionary Algorithm (LDG-EA), a two-stage 框架（提供结构的基础代码库） for multimodal lens 优化（寻找最佳参数或解决方案的过程）"
        ],
        "methods": [
          "Within each descriptor, LDG-EA applies the Hill-Valley Evolutionary Algorithm with covariance-matrix self-adaptation to recover multiple distinct local minima, optionally followed by gradient-based refinement"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.21945v1",
      "title": "Dependence of Equilibrium Propagation Training Success on Network Architecture",
      "originalTitle": "Dependence of Equilibrium Propagation Training Success on Network Architecture",
      "summary": "The rapid rise of 人工智能（让机器模拟人类智能的技术） has led to an unsustainable growth in energy consumption. This has motivated progress in neuromorphic computing and physics-based training of learning machines as alternatives to digital neural networks. Many 理论性的（基于数学推导的） studies focus on simple architectures like all-to-all or densely connected layered networks. However, these may be challenging to realize ex...",
      "plainSummary": "The rapid rise of 人工智能（让机器模拟人类智能的技术） has led to an unsustainable growth in energy consumption. This has motivated progress in neuromorphic computing and physics-based training of learning machines as alternatives to digital neural networks. Many 理论性的（基于数学推导的） studies focus on simple architectures like all-to-all or densely connected layered networks. However, these may be challenging to realize experimentally, e.g. due to connectivity constraints. In this work, we investigate the performance of the widespread physics-based training method of equilibrium propagation for more realistic architectural choices, specifically, locally connected lattices. We train an XY model and explore the influence of architecture on various 基准（用于比较性能的标准数据集或方法） tasks, tracking the evolution of spatially distributed responses and couplings during training. Our results show that sparse networks with only local connections can achieve performance comparable to dense networks. Our findings provide guidelines for further scaling up architectures based on equilibrium propagation in realistic settings.",
      "oneSentenceSummary": "【cs.LG】Qingshan Wang等Dependence of Equilibrium Propagation Training Success on Network Architecture，使用Our findings provide guideline...，在cs.LG取得新进展。",
      "authors": [
        {
          "original": "Qingshan Wang",
          "chinese": null
        },
        {
          "original": "Clara C. Wanjura",
          "chinese": null
        },
        {
          "original": "Florian Marquardt",
          "chinese": null
        }
      ],
      "published": "2026-01-29T16:29:31Z",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cs.ET",
        "cs.NE"
      ],
      "primaryCategory": "cs.LG",
      "pdfUrl": "https://arxiv.org/pdf/2601.21945v1",
      "abstractUrl": "https://arxiv.org/abs/2601.21945v1",
      "keyInfo": {
        "contributions": [],
        "methods": [
          "Our findings provide guidelines for further scaling up architectures based on equilibrium propagation in realistic settings"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.21885v1",
      "title": "Adaptive Surrogate-Based Strategy for Accelerating Convergence Speed when Solving Expensive Unconstrained Multi-Objective Optimisation Problems",
      "originalTitle": "Adaptive Surrogate-Based Strategy for Accelerating Convergence Speed when Solving Expensive Unconstrained Multi-Objective Optimisation Problems",
      "summary": "Multi-Objective Evolutionary Algorithms (MOEAs) have proven effective at solving Multi-Objective Optimisation Problems (MOOPs). However, their performance can be significantly hindered when applied to computationally intensive industrial problems. To address this limitation, we propose an adaptive surrogate modelling approach designed to accelerate the early-stage convergence speed of 最先进（当前最好的、领先...",
      "plainSummary": "Multi-Objective Evolutionary Algorithms (MOEAs) have proven effective at solving Multi-Objective Optimisation Problems (MOOPs). However, their performance can be significantly hindered when applied to computationally intensive industrial problems. To address this limitation, 我们提出 an adaptive surrogate modelling approach designed to accelerate the early-stage convergence speed of 最先进（当前最好的、领先的方法） MOEAs. This is important because it ensures that a solver can identify optimal or near-optimal solutions with relatively few fitness function evaluations, thereby saving both time and computational resources. 我们的方法 employs a two-loop architecture. The outer loop runs a (基线（用于对比的基准方法）) host MOEA which carries out true fitness evaluations. The inner loop contains an Adaptive Accelerator that leverages data-driven 机器学习（让计算机通过数据自动学习和改进的技术） (ML) surrogate models to approximate fitness functions. Integrated with NSGA-II and MOEA/D, our approach was tested on 31 widely known 基准（用于比较性能的标准数据集或方法） problems and a real-world North Sea fish abundance modelling case study. The results demonstrate that by incorporating Gaussian Process Regression, one-dimensional Convolutional Neural Networks, and Random Forest Regression, our proposed approach significantly accelerates the convergence speed of MOEAs in the early phases of optimisation.",
      "oneSentenceSummary": "【cs.NE】Tiwonge Msulira Banda等Adaptive Surrogate-Based Strategy for Accelerating Convergence Speed when Solving Expensive Unconstrained Multi-Objective Optimisation Problems，使用Our method employs a two-loop ...，在cs.NE取得新进展。",
      "authors": [
        {
          "original": "Tiwonge Msulira Banda",
          "chinese": null
        },
        {
          "original": "Alexandru-Ciprian Zăvoianu",
          "chinese": null
        }
      ],
      "published": "2026-01-29T15:46:52Z",
      "categories": [
        "cs.NE"
      ],
      "primaryCategory": "cs.NE",
      "pdfUrl": "https://arxiv.org/pdf/2601.21885v1",
      "abstractUrl": "https://arxiv.org/abs/2601.21885v1",
      "keyInfo": {
        "contributions": [
          "To address this limitation, we propose an adaptive surrogate modelling approach designed to accelerate the early-stage convergence speed of 最先进（当前最好的、领先的方法） MOEAs",
          "The results demonstrate that by incorporating Gaussian Process Regression, one-dimensional Convolutional Neural Networks, and Random Forest Regression, our proposed approach significantly accelerates the convergence speed of MOEAs in the early phases of optimisation"
        ],
        "methods": [
          "Our method employs a two-loop architecture",
          "The inner loop contains an Adaptive Accelerator that leverages data-driven 机器学习（让计算机通过数据自动学习和改进的技术） (ML) surrogate models to approximate fitness functions"
        ],
        "applications": [
          "However, their performance can be significantly hindered when applied to computationally intensive industrial problems"
        ]
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.21877v1",
      "title": "Evolution of 基准（用于比较性能的标准数据集或方法）: Black-Box 优化（寻找最佳参数或解决方案的过程） 基准（用于比较性能的标准数据集或方法） Design through 大语言模型（基于海量文本训练的语言模型，如GPT）",
      "originalTitle": "Evolution of Benchmark: Black-Box Optimization Benchmark Design through Large Language Model",
      "summary": "基准（用于比较性能的标准数据集或方法） Design in Black-Box 优化（寻找最佳参数或解决方案的过程） (BBO) is a fundamental yet open-ended topic. Early BBO benchmarks are predominantly human-crafted, introducing expert bias and constraining diversity. Automating this design process can relieve the human-in-the-loop burden while enhancing diversity and objectivity. We propose Evolution of 基准（用于比较性能的标准数据集或方法） (EoB), an automated BBO 基准（用于比较...",
      "plainSummary": "基准（用于比较性能的标准数据集或方法） Design in Black-Box 优化（寻找最佳参数或解决方案的过程） (BBO) is a fundamental yet open-ended topic. Early BBO benchmarks are predominantly human-crafted, introducing expert bias and constraining diversity. Automating this design process can relieve the human-in-the-loop burden while enhancing diversity and objectivity. 我们提出 Evolution of 基准（用于比较性能的标准数据集或方法） (EoB), an automated BBO 基准（用于比较性能的标准数据集或方法） designer empowered by the 大语言模型（基于海量文本训练的语言模型，如GPT） (LLM) and its program evolution capability. Specifically, we formulate 基准（用于比较性能的标准数据集或方法） design as a bi-objective 优化（寻找最佳参数或解决方案的过程） problem towards maximizing (i) landscape diversity and (ii) algorithm-differentiation ability across a portfolio of BBO solvers. Under this paradigm, EoB iteratively prompts LLM to evolve a population of 基准（用于比较性能的标准数据集或方法） programs and employs a reflection-based scheme to co-evolve the landscape and its corresponding program. 全面的（覆盖广泛的、详细的） experiments validate our EoB is a competitive candidate in multi-dimensional usages: 1) Benchmarking BBO algorithms; 2) Training and testing learning-assisted BBO algorithms; 3) Extending proxy for expensive real-world problems.",
      "oneSentenceSummary": "【cs.NE】Chen Wang等Evolution of Benchmark，使用Under this paradigm, EoB itera...，在cs.NE取得新进展。",
      "authors": [
        {
          "original": "Chen Wang",
          "chinese": null
        },
        {
          "original": "Sijie Ma",
          "chinese": null
        },
        {
          "original": "Zeyuan Ma",
          "chinese": null
        },
        {
          "original": "Yue-Jiao Gong",
          "chinese": null
        }
      ],
      "published": "2026-01-29T15:45:11Z",
      "categories": [
        "cs.NE"
      ],
      "primaryCategory": "cs.NE",
      "pdfUrl": "https://arxiv.org/pdf/2601.21877v1",
      "abstractUrl": "https://arxiv.org/abs/2601.21877v1",
      "keyInfo": {
        "contributions": [
          "基准（用于比较性能的标准数据集或方法） Design in Black-Box 优化（寻找最佳参数或解决方案的过程） (BBO) is a fundamental yet open-ended topic",
          "Automating this design process can relieve the human-in-the-loop burden while enhancing diversity and objectivity"
        ],
        "methods": [
          "Under this paradigm, EoB iteratively prompts LLM to evolve a population of 基准（用于比较性能的标准数据集或方法） programs and employs a reflection-based scheme to co-evolve the landscape and its corresponding program"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.21847v1",
      "title": "READY: Reward Discovery for Meta-Black-Box 优化（寻找最佳参数或解决方案的过程）",
      "originalTitle": "READY: Reward Discovery for Meta-Black-Box Optimization",
      "summary": "Meta-Black-Box 优化（寻找最佳参数或解决方案的过程） (MetaBBO) is an emerging avenue within 优化（寻找最佳参数或解决方案的过程） community, where algorithm design policy could be meta-learned by 强化学习（通过试错学习最佳策略的机器学习方法） to enhance 优化（寻找最佳参数或解决方案的过程） performance. So far, the reward functions in existing MetaBBO works are designed by human experts, introducing certain design bias and risks of reward hacking. In this paper, we use 大语言模型（...",
      "plainSummary": "Meta-Black-Box 优化（寻找最佳参数或解决方案的过程） (MetaBBO) is an emerging avenue within 优化（寻找最佳参数或解决方案的过程） community, where algorithm design policy could be meta-learned by 强化学习（通过试错学习最佳策略的机器学习方法） to enhance 优化（寻找最佳参数或解决方案的过程） performance. So far, the reward functions in existing MetaBBO works are designed by human experts, introducing certain design bias and risks of reward hacking. In this paper, we use 大语言模型（基于海量文本训练的语言模型，如GPT）~(LLM) as an automated reward discovery tool for MetaBBO. Specifically, we consider both effectiveness and efficiency sides. On effectiveness side, we borrow the idea of evolution of heuristics, introducing tailored evolution paradigm in the iterative LLM-based program search process, which ensures continuous improvement. On efficiency side, we additionally introduce multi-task evolution architecture to support parallel reward discovery for diverse MetaBBO approaches. Such parallel process also benefits from knowledge sharing across tasks to accelerate convergence. 经验性的（基于实验和观察的） results demonstrate that the reward functions discovered by our approach could be helpful for boosting existing MetaBBO works, underscoring the importance of reward design in MetaBBO. We provide READY's project at https://anonymous.4open.science/r/ICML_READY-747F.",
      "oneSentenceSummary": "【cs.LG】Zechuan Huang等READY，在cs.LG取得新进展。",
      "authors": [
        {
          "original": "Zechuan Huang",
          "chinese": null
        },
        {
          "original": "Zhiguang Cao",
          "chinese": null
        },
        {
          "original": "Hongshu Guo",
          "chinese": null
        },
        {
          "original": "Yue-Jiao Gong",
          "chinese": null
        },
        {
          "original": "Zeyuan Ma",
          "chinese": null
        }
      ],
      "published": "2026-01-29T15:23:18Z",
      "categories": [
        "cs.LG",
        "cs.NE"
      ],
      "primaryCategory": "cs.LG",
      "pdfUrl": "https://arxiv.org/pdf/2601.21847v1",
      "abstractUrl": "https://arxiv.org/abs/2601.21847v1",
      "keyInfo": {
        "contributions": [
          "Meta-Black-Box 优化（寻找最佳参数或解决方案的过程） (MetaBBO) is an emerging avenue within 优化（寻找最佳参数或解决方案的过程） community, where algorithm design policy could be meta-learned by 强化学习（通过试错学习最佳策略的机器学习方法） to enhance 优化（寻找最佳参数或解决方案的过程） performance",
          "So far, the reward functions in existing MetaBBO works are designed by human experts, introducing certain design bias and risks of reward hacking"
        ],
        "methods": [],
        "applications": [
          "Such parallel process also benefits from knowledge sharing across tasks to accelerate convergence"
        ]
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.21823v1",
      "title": "General Self-Prediction Enhancement for Spiking Neurons",
      "originalTitle": "General Self-Prediction Enhancement for Spiking Neurons",
      "summary": "Spiking Neural Networks (SNNs) are highly energy-高效的（速度快、资源消耗少） due to event-driven, sparse computation, but their training is challenged by spike non-differentiability and trade-offs among performance, efficiency, and biological plausibility. Crucially, mainstream SNNs ignore predictive coding, a core cortical mechanism where the brain predicts inputs and encodes errors for 高效的（速度快、资源消耗少） percept...",
      "plainSummary": "Spiking Neural Networks (SNNs) are highly energy-高效的（速度快、资源消耗少） due to event-driven, sparse computation, but their training is challenged by spike non-differentiability and trade-offs among performance, efficiency, and biological plausibility. Crucially, mainstream SNNs ignore predictive coding, a core cortical mechanism where the brain predicts inputs and encodes errors for 高效的（速度快、资源消耗少） perception. Inspired by this, 我们提出 a self-prediction enhanced spiking neuron method that generates an internal prediction current from its input-output history to modulate membrane potential. This design offers dual advantages, it creates a continuous gradient path that alleviates vanishing gradients and boosts training stability and 准确率（正确预测占总预测的比例）, while also aligning with biological principles, which resembles distal dendritic modulation and error-driven synaptic plasticity. Experiments show consistent performance gains across diverse architectures, neuron types, time steps, and tasks demonstrating broad applicability for enhancing SNNs.",
      "oneSentenceSummary": "【cs.NE】Zihan Huang等General Self-Prediction Enhancement for Spiking Neurons，在cs.NE取得新进展。",
      "authors": [
        {
          "original": "Zihan Huang",
          "chinese": null
        },
        {
          "original": "Zijie Xu",
          "chinese": null
        },
        {
          "original": "Yihan Huang",
          "chinese": null
        },
        {
          "original": "Shanshan Jia",
          "chinese": null
        },
        {
          "original": "Tong Bu",
          "chinese": null
        },
        {
          "original": "Yiting Dong",
          "chinese": null
        },
        {
          "original": "Wenxuan Liu",
          "chinese": null
        },
        {
          "original": "Jianhao Ding",
          "chinese": null
        },
        {
          "original": "Zhaofei Yu",
          "chinese": null
        },
        {
          "original": "Tiejun Huang",
          "chinese": null
        }
      ],
      "published": "2026-01-29T15:08:48Z",
      "categories": [
        "cs.NE"
      ],
      "primaryCategory": "cs.NE",
      "pdfUrl": "https://arxiv.org/pdf/2601.21823v1",
      "abstractUrl": "https://arxiv.org/abs/2601.21823v1",
      "keyInfo": {
        "contributions": [
          "Inspired by this, we propose a self-prediction enhanced spiking neuron method that generates an internal prediction current from its input-output history to modulate membrane potential",
          "This design offers dual advantages, it creates a continuous gradient path that alleviates vanishing gradients and boosts training stability and 准确率（正确预测占总预测的比例）, while also aligning with biological principles, which resembles distal dendritic modulation and error-driven synaptic plasticity"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.21778v1",
      "title": "Error Amplification Limits ANN-to-SNN Conversion in Continuous Control",
      "originalTitle": "Error Amplification Limits ANN-to-SNN Conversion in Continuous Control",
      "summary": "Spiking Neural Networks (SNNs) can achieve competitive performance by converting already existing well-trained Artificial Neural Networks (ANNs), avoiding further costly training. This property is particularly attractive in 强化学习（通过试错学习最佳策略的机器学习方法） (RL), where training through environment interaction is expensive and potentially unsafe. However, existing conversion methods perform poorly in continu...",
      "plainSummary": "Spiking Neural Networks (SNNs) can achieve competitive performance by converting already existing well-trained Artificial Neural Networks (ANNs), avoiding further costly training. This property is particularly attractive in 强化学习（通过试错学习最佳策略的机器学习方法） (RL), where training through environment interaction is expensive and potentially unsafe. However, existing conversion methods perform poorly in continuous control, where suitable baselines are largely absent. We identify error amplification as the key cause: small action approximation errors become temporally correlated across decision steps, inducing cumulative state distribution shift and severe performance degradation. To address this issue, 我们提出 Cross-Step Residual Potential Initialization (CRPI), a lightweight training-free mechanism that carries over residual membrane potentials across decision steps to suppress temporally correlated errors. Experiments on continuous control benchmarks with both vector and visual observations demonstrate that CRPI can be integrated into existing conversion pipelines and substantially recovers lost performance. Our results highlight continuous control as a critical and challenging 基准（用于比较性能的标准数据集或方法） for ANN-to-SNN conversion, where small errors can be strongly amplified and impact performance.",
      "oneSentenceSummary": "【cs.NE】Zijie Xu等Error Amplification Limits ANN-to-SNN Conversion in Continuous Control，在cs.NE取得新进展。",
      "authors": [
        {
          "original": "Zijie Xu",
          "chinese": null
        },
        {
          "original": "Zihan Huang",
          "chinese": null
        },
        {
          "original": "Yiting Dong",
          "chinese": null
        },
        {
          "original": "Kang Chen",
          "chinese": null
        },
        {
          "original": "Wenxuan Liu",
          "chinese": null
        },
        {
          "original": "Zhaofei Yu",
          "chinese": null
        }
      ],
      "published": "2026-01-29T14:28:00Z",
      "categories": [
        "cs.NE",
        "cs.LG"
      ],
      "primaryCategory": "cs.NE",
      "pdfUrl": "https://arxiv.org/pdf/2601.21778v1",
      "abstractUrl": "https://arxiv.org/abs/2601.21778v1",
      "keyInfo": {
        "contributions": [
          "To address this issue, we propose Cross-Step Residual Potential Initialization (CRPI), a lightweight training-free mechanism that carries over residual membrane potentials across decision steps to suppress temporally correlated errors"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.21557v1",
      "title": "Meta Context Engineering via Agentic Skill Evolution",
      "originalTitle": "Meta Context Engineering via Agentic Skill Evolution",
      "summary": "The operational efficacy of large language models relies heavily on their inference-time context. This has established Context Engineering (CE) as a formal discipline for optimizing these inputs. Current CE methods rely on manually crafted harnesses, such as rigid generation-reflection workflows and predefined context schemas. They impose structural biases and restrict context 优化（寻找最佳参数或解决方案的过程） t...",
      "plainSummary": "The operational efficacy of large language models relies heavily on their inference-time context. This has established Context Engineering (CE) as a formal discipline for optimizing these inputs. Current CE methods rely on manually crafted harnesses, such as rigid generation-reflection workflows and predefined context schemas. They impose structural biases and restrict context 优化（寻找最佳参数或解决方案的过程） to a narrow, intuition-bound design space. To address this, we introduce Meta Context Engineering (MCE), a bi-level 框架（提供结构的基础代码库） that supersedes static CE heuristics by co-evolving CE skills and context artifacts. In MCE iterations, a meta-level agent refines engineering skills via agentic crossover, a deliberative search over the history of skills, their executions, and evaluations. A base-level agent executes these skills, learns from training rollouts, and optimizes context as flexible files and code. We evaluate MCE across five disparate domains under offline and online settings. MCE demonstrates consistent performance gains, achieving 5.6--53.8% relative improvement over 最先进（当前最好的、领先的方法） agentic CE methods (mean of 16.9%), while maintaining superior context adaptability, transferability, and efficiency in both context usage and training.",
      "oneSentenceSummary": "【cs.AI】Haoran Ye等Meta Context Engineering via Agentic Skill Evolution，在cs.AI取得新进展。",
      "authors": [
        {
          "original": "Haoran Ye",
          "chinese": null
        },
        {
          "original": "Xuning He",
          "chinese": null
        },
        {
          "original": "Vincent Arak",
          "chinese": null
        },
        {
          "original": "Haonan Dong",
          "chinese": null
        },
        {
          "original": "Guojie Song",
          "chinese": null
        }
      ],
      "published": "2026-01-29T11:22:02Z",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primaryCategory": "cs.AI",
      "pdfUrl": "https://arxiv.org/pdf/2601.21557v1",
      "abstractUrl": "https://arxiv.org/abs/2601.21557v1",
      "keyInfo": {
        "contributions": [
          "They impose structural biases and restrict context 优化（寻找最佳参数或解决方案的过程） to a narrow, intuition-bound design space",
          "To address this, we introduce Meta Context Engineering (MCE), a bi-level 框架（提供结构的基础代码库） that supersedes static CE heuristics by co-evolving CE skills and context artifacts"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.21511v1",
      "title": "LLaMEA-SAGE: Guiding Automated Algorithm Design with Structural Feedback from Explainable AI",
      "originalTitle": "LLaMEA-SAGE: Guiding Automated Algorithm Design with Structural Feedback from Explainable AI",
      "summary": "Large language models have enabled automated algorithm design (AAD) by generating 优化（寻找最佳参数或解决方案的过程） algorithms directly from natural-language prompts. While evolutionary frameworks such as LLaMEA demonstrate strong exploratory capabilities across the algorithm design space, their search dynamics are entirely driven by fitness feedback, leaving substantial information about the generated code unus...",
      "plainSummary": "Large language models have enabled automated algorithm design (AAD) by generating 优化（寻找最佳参数或解决方案的过程） algorithms directly from natural-language prompts. While evolutionary frameworks such as LLaMEA demonstrate strong exploratory capabilities across the algorithm design space, their search dynamics are entirely driven by fitness feedback, leaving substantial information about the generated code unused. 我们提出 a mechanism for guiding AAD using feedback constructed from graph-theoretic and complexity features extracted from the abstract syntax trees of the generated algorithms, based on a surrogate model learned over an archive of evaluated solutions. Using explainable AI techniques, we identify features that substantially affect performance and translate them into natural-language mutation instructions that steer subsequent LLM-based code generation without restricting expressivity. 我们提出 LLaMEA-SAGE, which integrates this feature-driven guidance into LLaMEA, and evaluate it across several benchmarks. We show that the proposed structured guidance achieves the same performance faster than vanilla LLaMEA in a small controlled experiment. In a larger-scale experiment using the MA-BBOB suite from the GECCO-MA-BBOB competition, our guided approach achieves superior performance compared to 最先进（当前最好的、领先的方法） AAD methods. These results demonstrate that signals derived from code can effectively bias LLM-driven algorithm evolution, bridging the gap between code structure and human-understandable performance feedback in automated algorithm design.",
      "oneSentenceSummary": "【cs.AI】Niki van Stein等LLaMEA-SAGE，使用We propose a mechanism for gui...，在cs.AI取得新进展。",
      "authors": [
        {
          "original": "Niki van Stein",
          "chinese": null
        },
        {
          "original": "Anna V. Kononova",
          "chinese": null
        },
        {
          "original": "Lars Kotthoff",
          "chinese": null
        },
        {
          "original": "Thomas Bäck",
          "chinese": null
        }
      ],
      "published": "2026-01-29T10:27:29Z",
      "categories": [
        "cs.AI",
        "cs.NE",
        "cs.SE"
      ],
      "primaryCategory": "cs.AI",
      "pdfUrl": "https://arxiv.org/pdf/2601.21511v1",
      "abstractUrl": "https://arxiv.org/abs/2601.21511v1",
      "keyInfo": {
        "contributions": [
          "Large language models have enabled automated algorithm design (AAD) by generating 优化（寻找最佳参数或解决方案的过程） algorithms directly from natural-language prompts",
          "While evolutionary frameworks such as LLaMEA demonstrate strong exploratory capabilities across the algorithm design space, their search dynamics are entirely driven by fitness feedback, leaving substantial information about the generated code unused"
        ],
        "methods": [
          "We propose a mechanism for guiding AAD using feedback constructed from graph-theoretic and complexity features extracted from the abstract syntax trees of the generated algorithms, based on a surrogate model learned over an archive of evaluated solutions",
          "Using explainable AI techniques, we identify features that substantially affect performance and translate them into natural-language mutation instructions that steer subsequent LLM-based code generation without restricting expressivity"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.21503v1",
      "title": "MAR: 高效的（速度快、资源消耗少） Large Language Models via Module-aware Architecture Refinement",
      "originalTitle": "MAR: Efficient Large Language Models via Module-aware Architecture Refinement",
      "summary": "Large Language Models (LLMs) excel across diverse domains but suffer from high energy costs due to quadratic attention and dense Feed-Forward Network (FFN) operations. To address these issues, we propose Module-aware Architecture Refinement (MAR), a two-stage 框架（提供结构的基础代码库） that integrates State Space Models (SSMs) for linear-time sequence modeling and applies activation sparsification to reduce F...",
      "plainSummary": "Large Language Models (LLMs) excel across diverse domains but suffer from high energy costs due to quadratic attention and dense Feed-Forward Network (FFN) operations. To address these issues, 我们提出 Module-aware Architecture Refinement (MAR), a two-stage 框架（提供结构的基础代码库） that integrates State Space Models (SSMs) for linear-time sequence modeling and applies activation sparsification to reduce FFN costs. In addition, to mitigate low information density and temporal mismatch in integrating Spiking Neural Networks (SNNs) with SSMs, we design the Adaptive Ternary Multi-step Neuron (ATMN) and the Spike-aware Bidirectional Distillation Strategy (SBDS). 大量实验 demonstrate that MAR effectively restores the performance of its dense counterpart under constrained resources while substantially reducing inference energy consumption. Furthermore, it outperforms 高效的（速度快、资源消耗少） models of comparable or even larger scale, underscoring its potential for building 高效的（速度快、资源消耗少） and practical LLMs.",
      "oneSentenceSummary": "【cs.AI】Junhong Cai等MAR，使用To address these issues, we pr...，在cs.AI取得新进展。",
      "authors": [
        {
          "original": "Junhong Cai",
          "chinese": null
        },
        {
          "original": "Guiqin Wang",
          "chinese": null
        },
        {
          "original": "Kejie Zhao",
          "chinese": null
        },
        {
          "original": "Jianxiong Tang",
          "chinese": null
        },
        {
          "original": "Xiang Wang",
          "chinese": null
        },
        {
          "original": "Luziwei Leng",
          "chinese": null
        },
        {
          "original": "Ran Cheng",
          "chinese": null
        },
        {
          "original": "Yuxin Ma",
          "chinese": null
        },
        {
          "original": "Qinghai Guo",
          "chinese": null
        }
      ],
      "published": "2026-01-29T10:21:28Z",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.NE"
      ],
      "primaryCategory": "cs.AI",
      "pdfUrl": "https://arxiv.org/pdf/2601.21503v1",
      "abstractUrl": "https://arxiv.org/abs/2601.21503v1",
      "keyInfo": {
        "contributions": [
          "To address these issues, we propose Module-aware Architecture Refinement (MAR), a two-stage 框架（提供结构的基础代码库） that integrates State Space Models (SSMs) for linear-time sequence modeling and applies activation sparsification to reduce FFN costs",
          "In addition, to mitigate low information density and temporal mismatch in integrating Spiking Neural Networks (SNNs) with SSMs, we design the Adaptive Ternary Multi-step Neuron (ATMN) and the Spike-aware Bidirectional Distillation Strategy (SBDS)"
        ],
        "methods": [
          "To address these issues, we propose Module-aware Architecture Refinement (MAR), a two-stage 框架（提供结构的基础代码库） that integrates State Space Models (SSMs) for linear-time sequence modeling and applies activation sparsification to reduce FFN costs"
        ],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.21475v1",
      "title": "Task-free Adaptive Meta Black-box 优化（寻找最佳参数或解决方案的过程）",
      "originalTitle": "Task-free Adaptive Meta Black-box Optimization",
      "summary": "Handcrafted optimizers become prohibitively inefficient for complex black-box 优化（寻找最佳参数或解决方案的过程） (BBO) tasks. MetaBBO addresses this challenge by meta-learning to automatically configure optimizers for low-level BBO tasks, thereby eliminating heuristic dependencies. However, existing methods typically require extensive handcrafted training tasks to learn meta-strategies that generalize to target t...",
      "plainSummary": "Handcrafted optimizers become prohibitively inefficient for complex black-box 优化（寻找最佳参数或解决方案的过程） (BBO) tasks. MetaBBO addresses this challenge by meta-learning to automatically configure optimizers for low-level BBO tasks, thereby eliminating heuristic dependencies. However, existing methods typically require extensive handcrafted training tasks to learn meta-strategies that generalize to target tasks, which poses a critical limitation for realistic applications with unknown task distributions. To overcome the issue, 我们提出 the Adaptive meta Black-box 优化（寻找最佳参数或解决方案的过程） Model (ABOM), which performs online parameter adaptation using solely 优化（寻找最佳参数或解决方案的过程） data from the target task, obviating the need for predefined task distributions. Unlike conventional metaBBO frameworks that decouple meta-training and 优化（寻找最佳参数或解决方案的过程） phases, ABOM introduces a closed-loop adaptive parameter learning mechanism, where parameterized evolutionary operators continuously self-update by leveraging generated populations during 优化（寻找最佳参数或解决方案的过程）. This paradigm shift enables zero-shot 优化（寻找最佳参数或解决方案的过程）: ABOM achieves competitive performance on synthetic BBO benchmarks and realistic unmanned aerial vehicle path planning problems without any handcrafted training tasks. Visualization studies reveal that parameterized evolutionary operators exhibit statistically significant search patterns, including natural selection and genetic recombination.",
      "oneSentenceSummary": "【cs.NE】Chao Wang等Task-free Adaptive Meta Black-box Optimization，使用To overcome the issue, we prop...，在cs.NE取得新进展。",
      "authors": [
        {
          "original": "Chao Wang",
          "chinese": null
        },
        {
          "original": "Licheng Jiao",
          "chinese": null
        },
        {
          "original": "Lingling Li",
          "chinese": null
        },
        {
          "original": "Jiaxuan Zhao",
          "chinese": null
        },
        {
          "original": "Guanchun Wang",
          "chinese": null
        },
        {
          "original": "Fang Liu",
          "chinese": null
        },
        {
          "original": "Shuyuan Yang",
          "chinese": null
        }
      ],
      "published": "2026-01-29T09:54:10Z",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primaryCategory": "cs.NE",
      "pdfUrl": "https://arxiv.org/pdf/2601.21475v1",
      "abstractUrl": "https://arxiv.org/abs/2601.21475v1",
      "keyInfo": {
        "contributions": [
          "To overcome the issue, we propose the Adaptive meta Black-box 优化（寻找最佳参数或解决方案的过程） Model (ABOM), which performs online parameter adaptation using solely 优化（寻找最佳参数或解决方案的过程） data from the target task, obviating the need for predefined task distributions",
          "Unlike conventional metaBBO frameworks that decouple meta-training and 优化（寻找最佳参数或解决方案的过程） phases, ABOM introduces a closed-loop adaptive parameter learning mechanism, where parameterized evolutionary operators continuously self-update by leveraging generated populations during 优化（寻找最佳参数或解决方案的过程）"
        ],
        "methods": [
          "To overcome the issue, we propose the Adaptive meta Black-box 优化（寻找最佳参数或解决方案的过程） Model (ABOM), which performs online parameter adaptation using solely 优化（寻找最佳参数或解决方案的过程） data from the target task, obviating the need for predefined task distributions"
        ],
        "applications": [
          "This paradigm shift enables zero-shot 优化（寻找最佳参数或解决方案的过程）: ABOM achieves competitive performance on synthetic BBO benchmarks and realistic unmanned aerial vehicle path planning problems without any handcrafted training tasks"
        ]
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.21407v1",
      "title": "BrainFuse: a unified infrastructure integrating realistic biological modeling and core AI methodology",
      "originalTitle": "BrainFuse: a unified infrastructure integrating realistic biological modeling and core AI methodology",
      "summary": "Neuroscience and 人工智能（让机器模拟人类智能的技术） represent distinct yet complementary pathways to general intelligence. However, amid the ongoing boom in AI research and applications, the translational synergy between these two fields has grown increasingly elusive-hampered by a widening infrastructural incompatibility: modern AI frameworks lack native support for biophysical realism, while neural simulation t...",
      "plainSummary": "Neuroscience and 人工智能（让机器模拟人类智能的技术） represent distinct yet complementary pathways to general intelligence. However, amid the ongoing boom in AI research and applications, the translational synergy between these two fields has grown increasingly elusive-hampered by a widening infrastructural incompatibility: modern AI frameworks lack native support for biophysical realism, while neural simulation tools are poorly suited for gradient-based 优化（寻找最佳参数或解决方案的过程） and neuromorphic hardware deployment. To bridge this gap, we introduce BrainFuse, a unified infrastructure that provides 全面的（覆盖广泛的、详细的） support for biophysical neural simulation and gradient-based learning. By addressing algorithmic, computational, and deployment challenges, BrainFuse exhibits three core capabilities: (1) algorithmic integration of detailed neuronal dynamics into a differentiable learning 框架（提供结构的基础代码库）; (2) system-level 优化（寻找最佳参数或解决方案的过程） that accelerates customizable ion-channel dynamics by up to 3,000x on GPUs; and (3) 可扩展的（能够处理更大规模数据） computation with highly compatible pipelines for neuromorphic hardware deployment. We demonstrate this full-stack design through both AI and neuroscience tasks, from foundational neuron simulation and functional cylinder modeling to real-world deployment and application scenarios. For neuroscience, BrainFuse supports multiscale biological modeling, enabling the deployment of approximately 38,000 Hodgkin-Huxley neurons with 100 million synapses on a single neuromorphic chip while consuming as low as 1.98 W. For AI, BrainFuse facilitates the synergistic application of realistic biological neuron models, demonstrating enhanced robustness to input noise and improved temporal processing endowed by complex HH dynamics. BrainFuse therefore serves as a foundational engine to facilitate cross-disciplinary research and accelerate the development of next-generation bio-inspired intelligent systems.",
      "oneSentenceSummary": "【cs.NE】Baiyu Chen等BrainFuse，在cs.NE取得新进展。",
      "authors": [
        {
          "original": "Baiyu Chen",
          "chinese": null
        },
        {
          "original": "Yujie Wu",
          "chinese": null
        },
        {
          "original": "Siyuan Xu",
          "chinese": null
        },
        {
          "original": "Peng Qu",
          "chinese": null
        },
        {
          "original": "Dehua Wu",
          "chinese": null
        },
        {
          "original": "Xu Chu",
          "chinese": null
        },
        {
          "original": "Haodong Bian",
          "chinese": null
        },
        {
          "original": "Shuo Zhang",
          "chinese": null
        },
        {
          "original": "Bo Xu",
          "chinese": null
        },
        {
          "original": "Youhui Zhang",
          "chinese": null
        },
        {
          "original": "Zhengyu Ma",
          "chinese": null
        },
        {
          "original": "Guoqi Li",
          "chinese": null
        }
      ],
      "published": "2026-01-29T08:44:01Z",
      "categories": [
        "cs.NE",
        "q-bio.NC"
      ],
      "primaryCategory": "cs.NE",
      "pdfUrl": "https://arxiv.org/pdf/2601.21407v1",
      "abstractUrl": "https://arxiv.org/abs/2601.21407v1",
      "keyInfo": {
        "contributions": [
          "Neuroscience and 人工智能（让机器模拟人类智能的技术） represent distinct yet complementary pathways to general intelligence",
          "To bridge this gap, we introduce BrainFuse, a unified infrastructure that provides 全面的（覆盖广泛的、详细的） support for biophysical neural simulation and gradient-based learning"
        ],
        "methods": [],
        "applications": [
          "For AI, BrainFuse facilitates the synergistic application of realistic biological neuron models, demonstrating enhanced robustness to input noise and improved temporal processing endowed by complex HH dynamics"
        ]
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.21279v2",
      "title": "NEXUS: Bit-Exact ANN-to-SNN Equivalence via Neuromorphic Gate Circuits with Surrogate-Free Training",
      "originalTitle": "NEXUS: Bit-Exact ANN-to-SNN Equivalence via Neuromorphic Gate Circuits with Surrogate-Free Training",
      "summary": "Spiking Neural Networks (SNNs) promise energy-高效的（速度快、资源消耗少） computing through event-driven sparsity, yet all existing approaches sacrifice 准确率（正确预测占总预测的比例） by approximating continuous values with discrete spikes. We propose NEXUS, a 框架（提供结构的基础代码库） that achieves bit-exact ANN-to-SNN equivalence -- not approximate, but mathematically identical outputs. Our key insight is constructing all arithmetic...",
      "plainSummary": "Spiking Neural Networks (SNNs) promise energy-高效的（速度快、资源消耗少） computing through event-driven sparsity, yet all existing approaches sacrifice 准确率（正确预测占总预测的比例） by approximating continuous values with discrete spikes. 我们提出 NEXUS, a 框架（提供结构的基础代码库） that achieves bit-exact ANN-to-SNN equivalence -- not approximate, but mathematically identical outputs. Our key insight is constructing all arithmetic operations, both linear and nonlinear, from pure IF neuron logic gates that implement IEEE-754 compliant floating-point arithmetic. Through spatial bit encoding (zero encoding error by construction), hierarchical neuromorphic gate circuits (from basic logic gates to complete Transformer模型（一种处理序列数据的神经网络架构，特别擅长处理语言） layers), and surrogate-free STE training (exact identity mapping rather than heuristic approximation), NEXUS produces outputs identical to standard ANNs up to machine 精确率（预测为正例中真正正例的比例）. Experiments on models up to LLaMA-2 70B demonstrate identical task 准确率（正确预测占总预测的比例） (0.00% degradation) with mean ULP error of only 6.19, while achieving 27-168,000 energy reduction on neuromorphic hardware. Crucially, spatial bit encoding's single-timestep design renders the 框架（提供结构的基础代码库） inherently immune to membrane potential leakage (100% 准确率（正确预测占总预测的比例） across all decay factors ), while tolerating synaptic noise up to with >98% gate-level 准确率（正确预测占总预测的比例）.",
      "oneSentenceSummary": "【cs.NE】Zhengzheng Tang等NEXUS，在cs.NE取得新进展。",
      "authors": [
        {
          "original": "Zhengzheng Tang",
          "chinese": null
        }
      ],
      "published": "2026-01-29T05:23:56Z",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primaryCategory": "cs.NE",
      "pdfUrl": "https://arxiv.org/pdf/2601.21279v2",
      "abstractUrl": "https://arxiv.org/abs/2601.21279v2",
      "keyInfo": {
        "contributions": [
          "We propose NEXUS, a 框架（提供结构的基础代码库） that achieves bit-exact ANN-to-SNN equivalence -- not approximate, but mathematically identical outputs",
          "Crucially, spatial bit encoding's single-timestep design renders the 框架（提供结构的基础代码库） inherently immune to membrane potential leakage (100% 准确率（正确预测占总预测的比例） across all decay factors $β\\in[0"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.21268v1",
      "title": "强化学习（通过试错学习最佳策略的机器学习方法） from Meta-Evaluation: Aligning Language Models Without Ground-Truth Labels",
      "originalTitle": "Reinforcement Learning from Meta-Evaluation: Aligning Language Models Without Ground-Truth Labels",
      "summary": "Most 强化学习（通过试错学习最佳策略的机器学习方法） (RL) methods for training large language models (LLMs) require ground-truth labels or task-specific verifiers, limiting scalability when correctness is ambiguous or expensive to obtain. We introduce 强化学习（通过试错学习最佳策略的机器学习方法） from Meta-Evaluation (RLME), which optimizes a generator using reward derived from an evaluator's answers to natural-language meta-questions (e.g., ...",
      "plainSummary": "Most 强化学习（通过试错学习最佳策略的机器学习方法） (RL) methods for training large language models (LLMs) require ground-truth labels or task-specific verifiers, limiting scalability when correctness is ambiguous or expensive to obtain. We introduce 强化学习（通过试错学习最佳策略的机器学习方法） from Meta-Evaluation (RLME), which optimizes a generator using reward derived from an evaluator's answers to natural-language meta-questions (e.g., \"Is the answer correct?\" or \"Is the reasoning logically consistent?\"). RLME treats the evaluator's probability of a positive judgment as a reward and updates the generator via group-relative policy 优化（寻找最佳参数或解决方案的过程）, enabling learning without labels. Across a suite of experiments, we show that RLME achieves 准确率（正确预测占总预测的比例） and sample efficiency comparable to label-based training, enables controllable trade-offs among multiple objectives, steers models toward reliable reasoning patterns rather than post-hoc rationalization, and generalizes to open-domain settings where ground-truth labels are unavailable, broadening the domains in which LLMs may be trained with RL.",
      "oneSentenceSummary": "【cs.NE】Micah Rentschler等Reinforcement Learning from Meta-Evaluation，使用We introduce 强化学习（通过试错学习最佳策略的机...，在cs.NE取得新进展。",
      "authors": [
        {
          "original": "Micah Rentschler",
          "chinese": null
        },
        {
          "original": "Jesse Roberts",
          "chinese": null
        }
      ],
      "published": "2026-01-29T05:02:08Z",
      "categories": [
        "cs.NE"
      ],
      "primaryCategory": "cs.NE",
      "pdfUrl": "https://arxiv.org/pdf/2601.21268v1",
      "abstractUrl": "https://arxiv.org/abs/2601.21268v1",
      "keyInfo": {
        "contributions": [
          "We introduce 强化学习（通过试错学习最佳策略的机器学习方法） from Meta-Evaluation (RLME), which optimizes a generator using reward derived from an evaluator's answers to natural-language meta-questions (e"
        ],
        "methods": [
          "We introduce 强化学习（通过试错学习最佳策略的机器学习方法） from Meta-Evaluation (RLME), which optimizes a generator using reward derived from an evaluator's answers to natural-language meta-questions (e"
        ],
        "applications": [
          "Across a suite of experiments, we show that RLME achieves 准确率（正确预测占总预测的比例） and sample efficiency comparable to label-based training, enables controllable trade-offs among multiple objectives, steers models toward reliable reasoning patterns rather than post-hoc rationalization, and generalizes to open-domain settings where ground-truth labels are unavailable, broadening the domains in which LLMs may be trained with RL"
        ]
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.20981v1",
      "title": "Diversifying Toxicity Search in Large Language Models Through Speciation",
      "originalTitle": "Diversifying Toxicity Search in Large Language Models Through Speciation",
      "summary": "Evolutionary prompt search is a practical black-box approach for red teaming large language models (LLMs), but existing methods often collapse onto a small family of high-performing prompts, limiting coverage of distinct failure modes. We present a speciated quality-diversity (QD) extension of ToxSearch that maintains multiple high-toxicity prompt niches in parallel rather than optimizing a single...",
      "plainSummary": "Evolutionary prompt search is a practical black-box approach for red teaming large language models (LLMs), but existing methods often collapse onto a small family of high-performing prompts, limiting coverage of distinct failure modes. We present a speciated quality-diversity (QD) extension of ToxSearch that maintains multiple high-toxicity prompt niches in parallel rather than optimizing a single best prompt. ToxSearch-S introduces unsupervised prompt speciation via a search methodology that maintains capacity-limited species with exemplar leaders, a reserve pool for outliers and emerging niches, and species-aware parent selection that trades off within-niche exploitation and cross-niche exploration. ToxSearch-S is found to reach higher peak toxicity ( vs.\\ ) and a extreme heavier tail (top-10 median vs.\\ ) than the 基线（用于对比的基准方法）, while maintaining comparable performance on moderately toxic prompts. Speciation also yields broader semantic coverage under a topic-as-species analysis (higher effective topic diversity and larger unique topic coverage ). Finally, species formed are well-separated in 嵌入（将离散数据转换为连续向量表示） space (mean separation ratio ) and exhibit distinct toxicity distributions, indicating that speciation partitions the adversarial space into behaviorally differentiated niches rather than superficial lexical variants. This suggests our approach uncovers a wider range of attack strategies.",
      "oneSentenceSummary": "【cs.NE】Onkar Shelar等Diversifying Toxicity Search in Large Language Models Through Speciation，在cs.NE取得新进展。",
      "authors": [
        {
          "original": "Onkar Shelar",
          "chinese": null
        },
        {
          "original": "Travis Desell",
          "chinese": null
        }
      ],
      "published": "2026-01-28T19:29:54Z",
      "categories": [
        "cs.NE",
        "q-bio.PE"
      ],
      "primaryCategory": "cs.NE",
      "pdfUrl": "https://arxiv.org/pdf/2601.20981v1",
      "abstractUrl": "https://arxiv.org/abs/2601.20981v1",
      "keyInfo": {
        "contributions": [
          "We present a speciated quality-diversity (QD) extension of ToxSearch that maintains multiple high-toxicity prompt niches in parallel rather than optimizing a single best prompt",
          "ToxSearch-S introduces unsupervised prompt speciation via a search methodology that maintains capacity-limited species with exemplar leaders, a reserve pool for outliers and emerging niches, and species-aware parent selection that trades off within-niche exploitation and cross-niche exploration"
        ],
        "methods": [],
        "applications": []
      }
    },
    {
      "id": "http://arxiv.org/abs/2601.19562v1",
      "title": "Tournament Informed Adversarial Quality Diversity",
      "originalTitle": "Tournament Informed Adversarial Quality Diversity",
      "summary": "Quality diversity (QD) is a branch of evolutionary computation that seeks high-quality and behaviorally diverse solutions to a problem. While adversarial problems are common, classical QD cannot be easily applied to them, as both the fitness and the behavior depend on the opposing solutions. Recently, Generational Adversarial MAP-Elites (GAME) has been proposed to coevolve both sides of an adversa...",
      "plainSummary": "Quality diversity (QD) is a branch of evolutionary computation that seeks high-quality and behaviorally diverse solutions to a problem. While adversarial problems are common, classical QD cannot be easily applied to them, as both the fitness and the behavior depend on the opposing solutions. Recently, Generational Adversarial MAP-Elites (GAME) has been proposed to coevolve both sides of an adversarial problem by alternating the execution of a multi-task QD algorithm against previous elites, called tasks. The original algorithm selects new tasks based on a behavioral criterion, which may lead to undesired dynamics due to inter-side dependencies. In addition, comparing sets of solutions cannot be done directly using classical QD measures due to side dependencies. In this paper, we (1) use an inter-variants tournament to compare the sets of solutions, ensuring a fair comparison, with 6 measures of quality and diversity, and (2) propose two tournament-informed task selection methods to promote higher quality and diversity at each generation. We evaluate the variants across three adversarial problems: Pong, a Cat-and-mouse game, and a Pursuers-and-evaders game. We show that the tournament-informed task selection method leads to higher adversarial quality and diversity. We hope that this work will help further advance adversarial quality diversity. Code, videos, and supplementary material are available at https://github.com/Timothee-ANNE/GAME_tournament_informed.",
      "oneSentenceSummary": "【cs.NE】Timothée Anne等Tournament Informed Adversarial Quality Diversity，使用The original algorithm selects...，在cs.NE取得新进展。",
      "authors": [
        {
          "original": "Timothée Anne",
          "chinese": null
        },
        {
          "original": "Noah Syrkis",
          "chinese": null
        },
        {
          "original": "Meriem Elhosni",
          "chinese": null
        },
        {
          "original": "Florian Turati",
          "chinese": null
        },
        {
          "original": "Alexandre Manai",
          "chinese": null
        },
        {
          "original": "Franck Legendre",
          "chinese": null
        },
        {
          "original": "Alain Jaquier",
          "chinese": null
        },
        {
          "original": "Sebastian Risi",
          "chinese": null
        }
      ],
      "published": "2026-01-27T12:55:23Z",
      "categories": [
        "cs.NE"
      ],
      "primaryCategory": "cs.NE",
      "pdfUrl": "https://arxiv.org/pdf/2601.19562v1",
      "abstractUrl": "https://arxiv.org/abs/2601.19562v1",
      "keyInfo": {
        "contributions": [
          "Recently, Generational Adversarial MAP-Elites (GAME) has been proposed to coevolve both sides of an adversarial problem by alternating the execution of a multi-task QD algorithm against previous elites, called tasks",
          "In this paper, we (1) use an inter-variants tournament to compare the sets of solutions, ensuring a fair comparison, with 6 measures of quality and diversity, and (2) propose two tournament-informed task selection methods to promote higher quality and diversity at each generation"
        ],
        "methods": [
          "The original algorithm selects new tasks based on a behavioral criterion, which may lead to undesired dynamics due to inter-side dependencies",
          "In addition, comparing sets of solutions cannot be done directly using classical QD measures due to side dependencies"
        ],
        "applications": [
          "While adversarial problems are common, classical QD cannot be easily applied to them, as both the fitness and the behavior depend on the opposing solutions"
        ]
      }
    }
  ]
}